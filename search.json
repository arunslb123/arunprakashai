[
  {
    "objectID": "posts/anthropic-claude3-messages-images-claude3/messages_api_images.html",
    "href": "posts/anthropic-claude3-messages-images-claude3/messages_api_images.html",
    "title": "Anthropic Claude3: Messages API with Images",
    "section": "",
    "text": "Claude Vision\n\nClaude 3 models can understand and analyze images, allowing for conversations that include both text and visuals.\nSupported image formats include JPEG, PNG, GIF, and WebP. For optimal performance, resize images to no more than 1.15 megapixels and 1568 pixels in both dimensions.\nYou can include multiple images in a single request (up to 20 for API requests) for analysis\nEach image counts towards your token usage. Approximate cost per image can be calculated using the formula: tokens = (width px * height px) / 750.\nClaude has some limitations, such as identifying people, spatial reasoning, counting objects, and detecting AI-generated images. Always review and verify Claude’s interpretations.\nClaude does not generate, produce, edit, manipulate or create images; it only interprets and analyzes them.\n\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"You are an expert travel guide\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ]\n)\n\nprint(message.content)\n\n[ContentBlock(text=\"Here are some of the top places to visit in Sydney, Australia:\\n\\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\\n\\n2. Sydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\\n\\n3. Bondi Beach - One of Australia's most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\\n\\n4. The Rocks - A historic neighborhood with cobblestone streets, museums, galleries, and markets.\\n\\n5. Darling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\\n\\n6. Royal Botanic Garden Sydney - A beautiful oasis in the heart of the city, with diverse plant collections and stunning harbor views.\\n\\n7. Taronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\\n\\n8. Sydney Tower Eye - The tallest structure in Sydney, offering 360-degree views of the city from the observation deck and revolving restaurant.\\n\\n9. Manly Beach - A popular beach located a short ferry ride from the city center, known for its laid-back atmosphere and water activities.\\n\\n10. Blue Mountains National Park - A scenic park located about 2 hours from Sydney, known for its dramatic rock formations, waterfalls, and hiking trails.\\n\\nThese are just a few of the many attractions Sydney has to offer, and there are plenty of other neighborhoods, beaches, and cultural experiences to explore in this vibrant city.\", type='text')]\n\n\n\nfrom IPython.display import display, HTML, Markdown\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere are some of the top places to visit in Sydney, Australia:\n\nSydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\nSydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\nBondi Beach - One of Australia’s most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\nThe Rocks - A historic neighborhood with cobblestone streets, museums, galleries, and markets.\nDarling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\nRoyal Botanic Garden Sydney - A beautiful oasis in the heart of the city, with diverse plant collections and stunning harbor views.\nTaronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\nSydney Tower Eye - The tallest structure in Sydney, offering 360-degree views of the city from the observation deck and revolving restaurant.\nManly Beach - A popular beach located a short ferry ride from the city center, known for its laid-back atmosphere and water activities.\nBlue Mountains National Park - A scenic park located about 2 hours from Sydney, known for its dramatic rock formations, waterfalls, and hiking trails.\n\nThese are just a few of the many attractions Sydney has to offer, and there are plenty of other neighborhoods, beaches, and cultural experiences to explore in this vibrant city.\n\n\n\nfrom IPython.display import Image\n\n\nImage('claude_results.jpeg', width=800)\n\n\n\n\n\n# load image and convert to base64\nimport base64\nfrom PIL import Image\nfrom io import BytesIO\n\nimage_data = base64.b64encode(open('claude_results.jpeg', 'rb').read()).decode('utf-8')\n\n\ntype(image_data)\n\nstr\n\n\n\nimage_data[:100]\n\n'/9j/4AAQSkZJRgABAgEASABIAAD/4QDKRXhpZgAATU0AKgAAAAgABgESAAMAAAABAAEAAAEaAAUAAAABAAAAVgEbAAUAAAABAAAA'\n\n\n\n\nDescribe an Image\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": image_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Describe this image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01Xd14cQdncxYH1Cqt7ULGte', content=[ContentBlock(text='This image shows a comparison table of performance metrics across different AI language models.\\n\\nThe models compared include Claude 3 (in its Opus, Sonnet and Haiku variants), GPT-4, GPT-3.5, and two versions of Gemini 1.0.\\n\\nVarious metrics are listed down the left side, including:\\n- Undergraduate level knowledge (MMLU)\\n- Graduate level reasoning (GQPA, Diamond)\\n- Grade school math (GSM8K)  \\n- Math problem-solving (MATH)\\n- Multilingual math (MGSM)\\n- Code generation (HumanEval)\\n- Reasoning over text (DROP, F1 score) \\n- Mixed evaluations (BIG-Bench-Hard)\\n- Knowledge Q&A (ARC-Challenge)\\n- Common Knowledge (HellaSwag)\\n\\nThe cells contain the score each model achieved on the corresponding metric. The score format varies by row, with some showing x-shot scores, others showing raw scores, F1 scores, or number of shots.\\n\\nOverall, this table enables a side-by-side comparison of how well these prominent language models perform across a diverse set of NLP benchmarks and capability assessments. The color coding also helps highlight relative strengths and weaknesses.', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1640, output_tokens=291))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nThis image shows a comparison table of various metrics across different AI language models, including Claude 3 (in Opus, Sonnet and Haiku variants), GPT-4, GPT-3.5, and two versions of Gemini.\nThe metrics compared include: - Undergraduate level knowledge (MMLU) - Graduate level reasoning (GPQA, Diamond) - Grade school math (GSM8K) - Math problem-solving (MATH) - Multilingual math (MGSM) - Code generation (HumanEval) - Reasoning over text (DROP, F1 score) - Mixed evaluations (BIG-Bench-Hard) - Knowledge Q&A (ARC-Challenge) - Common Knowledge (HellaSwag)\nFor each metric, the scores are provided along with the number of “shots” used in the evaluation (e.g. 0-shot, 5-shot, 10-shot etc.). The scores are given as percentages, except for the DROP reasoning metric which uses an F1 score.\nOverall, the table allows comparing the performance of these different AI models across a range of knowledge domains and reasoning tasks. The color coding appears to highlight the best performing model for each metric.\n\n\n\n\nGenerate Code\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": image_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Write python code to create a bar plot from the image table. Only Claude columns, dont include other models. x label is all the metrics, y label is the values.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01THwqDdZn2oWfVF2XNu45w3', content=[ContentBlock(text=\"Here's the Python code to create a bar plot from the image table, including only the Claude columns:\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\nmetrics = ['Undergraduate level knowledge MMLU',\\n           'Graduate level reasoning GFQA, Diamond',\\n           'Grade school math GSMSB',\\n           'Math problem-solving MATH',\\n           'Multilingual math MGSM',\\n           'Code HumanEval',\\n           'Reasoning over text DROP, F1 score',\\n           'Mixed evaluations BIG-Bench-Hard',\\n           'Knowledge Q&A ARC-Challenge',\\n           'Common Knowledge HellaSwag']\\n\\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\\n\\nx = range(len(metrics))\\nwidth = 0.25\\n\\nfig, ax = plt.subplots(figsize=(12, 8))\\n\\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\\nax.bar([i + 2*width for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\\n\\nax.set_xlabel('Metrics')\\nax.set_ylabel('Values')\\nax.set_xticks([i + width for i in x])\\nax.set_xticklabels(metrics, rotation=45, ha='right')\\nax.legend()\\n\\nplt.tight_layout()\\nplt.show()\\n```\\n\\nThis code does the following:\\n\\n1. It imports the necessary matplotlib.pyplot module.\\n\\n2. It defines the metrics as a list of strings.\\n\\n3. It extracts the values for each Claude model (Opus, Sonnet, and Haiku) into separate lists.\\n\\n4. It sets up the x-coordinates and width for the bars.\\n\\n5. It creates a figure and an axis using `plt.subplots()`.\\n\\n6. It creates the bars for each Claude model using `ax.bar()`, with appropriate offsets for the x-coordinates.\\n\\n7. It sets the x-label and y-label using `ax.set_xlabel()` and `ax.set_ylabel()`, respectively.\\n\\n8. It sets the x-tick positions and labels using `ax.set_xticks()` and `ax.set_xticklabels()`, with rotation and horizontal alignment for better readability.\\n\\n9. It adds a legend using `ax.legend()`.\\n\\n10. It adjusts the layout using `plt.tight_layout()` to ensure the labels and titles fit nicely.\\n\\n11. Finally, it displays the plot using `plt.show()`.\\n\\nWhen you run this code, it will generate a bar plot comparing the performance of the Claude models (Opus, Sonnet, and Haiku) across various metrics.\", type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1670, output_tokens=825))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere’s the Python code to create a bar plot from the image table, including only the Claude columns:\nimport matplotlib.pyplot as plt\n\nmetrics = ['Undergraduate level knowledge MMLU',\n           'Graduate level reasoning GFQA, Diamond',\n           'Grade school math GSMSB',\n           'Math problem-solving MATH',\n           'Multilingual math MGSM',\n           'Code HumanEval',\n           'Reasoning over text DROP, F1 score',\n           'Mixed evaluations BIG-Bench-Hard',\n           'Knowledge Q&A ARC-Challenge',\n           'Common Knowledge HellaSwag']\n\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\n\nx = range(len(metrics))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\nax.bar([i + 2*width for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\n\nax.set_xlabel('Metrics')\nax.set_ylabel('Values')\nax.set_xticks([i + width for i in x])\nax.set_xticklabels(metrics, rotation=45, ha='right')\nax.legend()\n\nplt.tight_layout()\nplt.show()\nThis code does the following:\n\nIt imports the necessary matplotlib.pyplot module.\nIt defines the metrics as a list of strings.\nIt extracts the values for each Claude model (Opus, Sonnet, and Haiku) into separate lists.\nIt sets up the x-coordinates and width for the bars.\nIt creates a figure and an axis using plt.subplots().\nIt creates the bars for each Claude model using ax.bar(), with appropriate offsets for the x-coordinates.\nIt sets the x-label and y-label using ax.set_xlabel() and ax.set_ylabel(), respectively.\nIt sets the x-tick positions and labels using ax.set_xticks() and ax.set_xticklabels(), with rotation and horizontal alignment for better readability.\nIt adds a legend using ax.legend().\nIt adjusts the layout using plt.tight_layout() to ensure the labels and titles fit nicely.\nFinally, it displays the plot using plt.show().\n\nWhen you run this code, it will generate a bar plot comparing the performance of the Claude models (Opus, Sonnet, and Haiku) across various metrics.\n\n\n\nimport matplotlib.pyplot as plt\n\nmetrics = ['Undergraduate level knowledge MMLU',\n           'Graduate level reasoning GPQA, Diamond',\n           'Grade school math GSMSK',\n           'Math problem-solving MATH',\n           'Multilingual math MGSM',\n           'Code HumanEval',\n           'Reasoning over text DROP, F1 score',\n           'Mixed evaluations BIG-Bench-Hard',\n           'Knowledge Q&A ARC-Challenge',\n           'Common Knowledge HellaSwag']\n\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\n\nx = range(len(metrics))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(12, 8))\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\nax.bar([i + width*2 for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\n\nax.set_ylabel('Values')\nax.set_xticks([i + width for i in x])\nax.set_xticklabels(metrics, rotation=45, ha='right')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nRecipe Generation\n\nrecipe_data = base64.b64encode(open('recipe.jpg', 'rb').read()).decode('utf-8')\n\n\nfrom IPython.display import Image\n\n\n#display the image\nImage('recipe.jpg', width=800)\n\n\n\n\nPrompt I used to generate the image is ‘A single perfect éclair, dark chocolate glaze, a single raspberry on top, cracked surface revealing vanilla custard’\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": recipe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Generate recipe for the given image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01L7JH75i2MPegcQa4b597DS', content=[ContentBlock(text='This image shows an appetizing raspberry chocolate eclair or cream puff dessert. The eclair pastry is golden brown and flaky looking, filled with a luscious vanilla cream filling, and topped with a rich chocolate ganache glaze and fresh raspberries dusted with cocoa powder.\\n\\nTo make raspberry chocolate eclairs, you would need to:\\n\\n1. Prepare choux pastry dough, pipe it into eclair shapes, and bake until puffed and golden.\\n\\n2. Make a vanilla pastry cream filling, let it chill, then pipe it into the cooled eclair shells. \\n\\n3. Prepare a shiny chocolate ganache glaze and dip or spread it on top of the filled eclairs.\\n\\n4. Top with fresh raspberries and dust with cocoa powder for the finishing touch. \\n\\n5. Chill the assembled eclairs for a couple hours to allow flavors to meld before serving.\\n\\nThe combination of crisp pastry, silky cream, bittersweet chocolate and tart-sweet raspberries makes for an irresistible treat that is sure to impress. While eclairs take some time and technique, the end result of this classic French patisserie is well worth the effort for a special occasion dessert.', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1648, output_tokens=279))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nThis image shows an appetizing raspberry chocolate eclair or cream puff dessert. The eclair pastry is golden brown and flaky looking, filled with a luscious vanilla cream filling, and topped with a rich chocolate ganache glaze and fresh raspberries dusted with cocoa powder.\nTo make raspberry chocolate eclairs, you would need to:\n\nPrepare choux pastry dough, pipe it into eclair shapes, and bake until puffed and golden.\nMake a vanilla pastry cream filling, let it chill, then pipe it into the cooled eclair shells.\nPrepare a shiny chocolate ganache glaze and dip or spread it on top of the filled eclairs.\nTop with fresh raspberries and dust with cocoa powder for the finishing touch.\nChill the assembled eclairs for a couple hours to allow flavors to meld before serving.\n\nThe combination of crisp pastry, silky cream, bittersweet chocolate and tart-sweet raspberries makes for an irresistible treat that is sure to impress. While eclairs take some time and technique, the end result of this classic French patisserie is well worth the effort for a special occasion dessert.\n\n\n\n\nImage with system prompt\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    system=\"You are an expert chef, who can generate recipes from images in french.\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": recipe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Generate recipe for the given image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01QGkczZma6tD84ZQoNccyzW', content=[ContentBlock(text=\"Voici une recette pour un éclair au chocolat et aux framboises, inspirée de l'image :\\n\\nPâte à choux :\\n- 125 ml d'eau\\n- 50 g de beurre\\n- 65 g de farine \\n- 2 œufs\\n- 1 pincée de sel\\n\\nCrème pâtissière à la vanille :\\n- 250 ml de lait\\n- 50 g de sucre\\n- 30 g de farine\\n- 2 jaunes d'œufs \\n- 1 gousse de vanille\\n\\nGanache au chocolat :\\n- 100 g de chocolat noir\\n- 100 ml de crème fraîche liquide\\n\\nDécoration :\\n- Cacao en poudre\\n- Framboises fraîches\\n\\nInstructions :\\n\\n1. Préparez la pâte à choux en portant à ébullition l'eau, le beurre et le sel. Hors du feu, incorporez la farine d'un coup puis remettez sur feu doux en mélangeant jusqu'à ce que la pâte se décolle. Laissez tiédir puis incorporez les œufs un par un. Pochez sur une plaque et faites cuire 30 min à 180°C.\\n\\n2. Pour la crème, portez le lait et la vanille à ébullition. À part, mélangez sucre, farine et jaunes d'œufs. Versez le lait dessus en mélangeant, puis remettez sur feu doux jusqu'à épaississement. Laissez refroidir.\\n\\n3. Préparez la ganache en faisant fondre le chocolat avec la crème chauffée.\\n\\n4. Fourrez les éclairs refroidis de crème pâtissière, glacez-les de ganache, saupoudrez de cacao et décorez de framboises fraîches. \\n\\nDégustez ces délicieux éclairs faits maison, alliant le croquant de la pâte, la douceur vanillée de la crème et l'intense chocolat, rehaussés de framboises acidulées.\", type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1664, output_tokens=543))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nVoici une recette pour un éclair au chocolat et aux framboises, inspirée de l’image :\nPâte à choux : - 125 ml d’eau - 50 g de beurre - 65 g de farine - 2 œufs - 1 pincée de sel\nCrème pâtissière à la vanille : - 250 ml de lait - 50 g de sucre - 30 g de farine - 2 jaunes d’œufs - 1 gousse de vanille\nGanache au chocolat : - 100 g de chocolat noir - 100 ml de crème fraîche liquide\nDécoration : - Cacao en poudre - Framboises fraîches\nInstructions :\n\nPréparez la pâte à choux en portant à ébullition l’eau, le beurre et le sel. Hors du feu, incorporez la farine d’un coup puis remettez sur feu doux en mélangeant jusqu’à ce que la pâte se décolle. Laissez tiédir puis incorporez les œufs un par un. Pochez sur une plaque et faites cuire 30 min à 180°C.\nPour la crème, portez le lait et la vanille à ébullition. À part, mélangez sucre, farine et jaunes d’œufs. Versez le lait dessus en mélangeant, puis remettez sur feu doux jusqu’à épaississement. Laissez refroidir.\nPréparez la ganache en faisant fondre le chocolat avec la crème chauffée.\nFourrez les éclairs refroidis de crème pâtissière, glacez-les de ganache, saupoudrez de cacao et décorez de framboises fraîches.\n\nDégustez ces délicieux éclairs faits maison, alliant le croquant de la pâte, la douceur vanillée de la crème et l’intense chocolat, rehaussés de framboises acidulées.\n\n\n\n\nMultiple Images: Getting Feedback on What Shoe to Wear for a Blue Suit\n\nblue_suit = base64.b64encode(open('suit.jpeg', 'rb').read()).decode('utf-8')\nblack_shoes = base64.b64encode(open('black_shoe.jpeg', 'rb').read()).decode('utf-8')\nbrown_shoes = base64.b64encode(open('brown_shoe.jpeg', 'rb').read()).decode('utf-8')\n\n\nImage('suit.jpeg', width=500)\n\n\n\n\n\nImage('black_shoe.jpeg', width=500)\n\n\n\n\n\nImage('brown_shoe.jpeg', width=500)\n\n\n\n\n\nsuit_data = base64.b64encode(open('suit.jpeg', 'rb').read()).decode('utf-8')\nblack_shoe_data = base64.b64encode(open('black_shoe.jpeg', 'rb').read()).decode('utf-8')\nbrown_shoe_data = base64.b64encode(open('brown_shoe.jpeg', 'rb').read()).decode('utf-8')\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    system=\"You are a fashion expert who has excellent knowledge of color combinations and can recommend the best color shoe for the given suit.\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Suit:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": suit_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Shoe 1:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": black_shoe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Shoe 2:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": brown_shoe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"For my suit, Look into  my suit color, and recommend what color shoe should I wear? Black or brown? Give reasons.\"\n                \n                }\n               \n            ],\n        }\n    ],\n)\n\n\ndisplay(Markdown(message.content[0].text))\n\nBased on the blue plaid suit shown in the image, I would recommend pairing it with the brown leather dress shoes (Shoe 2) rather than the black ones (Shoe 1). Here are a few reasons why:\n\nBrown shoes complement blue suits very well, creating a harmonious and stylish color combination. The warm tones of the brown leather pair nicely with the cool blue hues of the suit fabric.\nWearing brown shoes with a blue suit is a classic and versatile look that can work for both business and more casual occasions. It’s not quite as formal as a black shoe, but still polished and put-together.\nThe rich, burnished leather of the brown shoes in the photo would add some nice visual texture and depth to offset the plaid pattern of the suit. The broguing details on the shoes also provide an extra touch of style.\nBlack shoes, while always appropriate with a navy solid suit, can sometimes look a bit stark or severe with lighter shades of blue or bolder patterns like the plaid shown here. The brown option allows the suit to remain the focal point.\n\nSo in summary, while you can’t go wrong with either, I’d suggest the brown dress shoes as the optimal pairing to elevate this blue plaid suit. The combination strikes the right balance of dapper and distinctive.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html",
    "href": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html",
    "title": "Anthropic Claude3: Function Calling Tools in Python",
    "section": "",
    "text": "Function calling is a powerful technique that allows you to extend the capabilities of a language model like Claude by integrating external functions or APIs. It enables the model to perform tasks or access information that it wouldn’t be able to do on its own.\nIn the final response, Claude incorporates the result of the function call into its output, allowing it to provide a response that it wouldn’t have been able to generate on its own.\nFunction calling opens up a wide range of possibilities for extending the capabilities of language models like Claude. By defining custom functions and providing clear descriptions of how to use them, you can enable Claude to perform complex tasks, access real-time data, and interact with external systems.\n!pip install anthropic --upgrade\n\nRequirement already satisfied: anthropic in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (0.16.0)\nCollecting anthropic\n  Using cached anthropic-0.21.0-py3-none-any.whl (851 kB)\nRequirement already satisfied: anyio&lt;5,&gt;=3.5.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (3.7.1)\nRequirement already satisfied: distro&lt;2,&gt;=1.7.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (1.8.0)\nRequirement already satisfied: httpx&lt;1,&gt;=0.23.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (0.25.0)\nRequirement already satisfied: pydantic&lt;3,&gt;=1.9.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (2.4.2)\nRequirement already satisfied: sniffio in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (1.3.0)\nRequirement already satisfied: tokenizers&gt;=0.13.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (0.14.1)\nRequirement already satisfied: typing-extensions&lt;5,&gt;=4.7 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (4.8.0)\nRequirement already satisfied: idna&gt;=2.8 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anyio&lt;5,&gt;=3.5.0-&gt;anthropic) (3.4)\nRequirement already satisfied: certifi in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (2023.7.22)\nRequirement already satisfied: httpcore&lt;0.19.0,&gt;=0.18.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (0.18.0)\nRequirement already satisfied: annotated-types&gt;=0.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from pydantic&lt;3,&gt;=1.9.0-&gt;anthropic) (0.6.0)\nRequirement already satisfied: pydantic-core==2.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from pydantic&lt;3,&gt;=1.9.0-&gt;anthropic) (2.10.1)\nRequirement already satisfied: huggingface_hub&lt;0.18,&gt;=0.16.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from tokenizers&gt;=0.13.0-&gt;anthropic) (0.17.3)\nRequirement already satisfied: h11&lt;0.15,&gt;=0.13 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpcore&lt;0.19.0,&gt;=0.18.0-&gt;httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (0.14.0)\nRequirement already satisfied: filelock in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (3.12.4)\nRequirement already satisfied: fsspec in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (2023.9.2)\nRequirement already satisfied: requests in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (4.66.1)\nRequirement already satisfied: pyyaml&gt;=5.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (6.0.1)\nRequirement already satisfied: packaging&gt;=20.9 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (23.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from requests-&gt;huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (3.3.0)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from requests-&gt;huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (1.26.18)\nInstalling collected packages: anthropic\n  Attempting uninstall: anthropic\n    Found existing installation: anthropic 0.16.0\n    Uninstalling anthropic-0.16.0:\n      Successfully uninstalled anthropic-0.16.0\nSuccessfully installed anthropic-0.21.0\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\nimport anthropic\nimport re\nimport json\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\ndef construct_format_parameters_prompt(parameters):\n    constructed_prompt = \"\\n\".join(\n        f\"&lt;parameter&gt;\\n&lt;name&gt;{parameter['name']}&lt;/name&gt;\\n&lt;type&gt;{parameter['type']}&lt;/type&gt;\\n&lt;description&gt;{parameter['description']}&lt;/description&gt;\\n&lt;/parameter&gt;\"\n        for parameter in parameters\n    )\n    return constructed_prompt\ndef construct_format_tool_for_claude_prompt(name, description, parameters):\n    constructed_prompt = (\n        \"&lt;tool_description&gt;\\n\"\n        f\"&lt;tool_name&gt;{name}&lt;/tool_name&gt;\\n\"\n        \"&lt;description&gt;\\n\"\n        f\"{description}\\n\"\n        \"&lt;/description&gt;\\n\"\n        \"&lt;parameters&gt;\\n\"\n        f\"{construct_format_parameters_prompt(parameters)}\\n\"\n        \"&lt;/parameters&gt;\\n\"\n        \"&lt;/tool_description&gt;\"\n    )\n    return constructed_prompt\ndef construct_tool_use_system_prompt(tools):\n    tool_use_system_prompt = (\n        \"In this environment you have access to a set of tools you can use to answer the user's question.\\n\"\n        \"\\n\"\n        \"You may call them like this:\\n\"\n        \"&lt;function_calls&gt;\\n\"\n        \"&lt;invoke&gt;\\n\"\n        \"&lt;tool_name&gt;$TOOL_NAME&lt;/tool_name&gt;\\n\"\n        \"&lt;parameters&gt;\\n\"\n        \"&lt;$PARAMETER_NAME&gt;$PARAMETER_VALUE&lt;/$PARAMETER_NAME&gt;\\n\"\n        \"...\\n\"\n        \"&lt;/parameters&gt;\\n\"\n        \"&lt;/invoke&gt;\\n\"\n        \"&lt;/function_calls&gt;\\n\"\n        \"\\n\"\n        \"Here are the tools available:\\n\"\n        \"&lt;tools&gt;\\n\"\n        + '\\n'.join([tool for tool in tools]) +\n        \"\\n&lt;/tools&gt;\"\n    )\n    return tool_use_system_prompt\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -&gt; list[str]:\n    ext_list = re.findall(f\"&lt;{tag}&gt;(.+?)&lt;/{tag}&gt;\", string, re.DOTALL)\n    if strip:\n        ext_list = [e.strip() for e in ext_list]\n    return ext_list\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"Reverse the string encyclopediachatgpt\"\n        },\n\n    ]\n).content[0].text\nprint(message)\n\ntpgtahcaidepcolcycne\n\"tpgtahcaidepcolcycne\" == \"encyclopediachatgpt\"[::-1]\n\nFalse\nMost large language models (LLMs) struggle with string reversal tasks because they are primarily trained on natural language data and lack explicit programming knowledge.\ndef reverse_string(string):\n    return string[::-1]\ntool_name = \"reverse_string\"\ntool_description = \"Reverses the provided string.\"\n\nparameters = [\n    {\n        \"name\": \"string\",\n        \"type\": \"str\",\n        \"description\": \"The string to be reversed.\"\n    }\n]\n\ntool = construct_format_tool_for_claude_prompt(tool_name, tool_description, parameters)\nsystem_prompt = construct_tool_use_system_prompt([tool])\nprint(tool)\n\n&lt;tool_description&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;description&gt;\nReverses the provided string.\n&lt;/description&gt;\n&lt;parameters&gt;\n&lt;parameter&gt;\n&lt;name&gt;string&lt;/name&gt;\n&lt;type&gt;str&lt;/type&gt;\n&lt;description&gt;The string to be reversed.&lt;/description&gt;\n&lt;/parameter&gt;\n&lt;/parameters&gt;\n&lt;/tool_description&gt;\nprint(system_prompt)\n\nIn this environment you have access to a set of tools you can use to answer the user's question.\n\nYou may call them like this:\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;$TOOL_NAME&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;$PARAMETER_NAME&gt;$PARAMETER_VALUE&lt;/$PARAMETER_NAME&gt;\n...\n&lt;/parameters&gt;\n&lt;/invoke&gt;\n&lt;/function_calls&gt;\n\nHere are the tools available:\n&lt;tools&gt;\n&lt;tool_description&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;description&gt;\nReverses the provided string.\n&lt;/description&gt;\n&lt;parameters&gt;\n&lt;parameter&gt;\n&lt;name&gt;string&lt;/name&gt;\n&lt;type&gt;str&lt;/type&gt;\n&lt;description&gt;The string to be reversed.&lt;/description&gt;\n&lt;/parameter&gt;\n&lt;/parameters&gt;\n&lt;/tool_description&gt;\n&lt;/tools&gt;\nreverse_message = {\n    \"role\": \"user\",\n    \"content\": \"Reverse the string encyclopediachatgpt\"\n}\nfunction_calling_message = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[reverse_message],\n    system=system_prompt,\n    stop_sequences=[\"\\n\\nHuman:\", \"\\n\\nAssistant\", \"&lt;/function_calls&gt;\"]\n).content[0].text\n\nprint(function_calling_message)\n\nOkay, let's reverse the string \"encyclopediachatgpt\" using the reverse_string tool:\n\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;string&gt;encyclopediachatgpt&lt;/string&gt;\n&lt;/parameters&gt;\n&lt;/invoke&gt;\nstring = extract_between_tags(\"string\", function_calling_message)[0]\nreversed_string = reverse_string(string)\ndef construct_successful_function_run_injection_prompt(invoke_results):\n    constructed_prompt = (\n        \"&lt;function_results&gt;\\n\"\n        + '\\n'.join(\n            f\"&lt;result&gt;\\n&lt;tool_name&gt;{res['tool_name']}&lt;/tool_name&gt;\\n&lt;stdout&gt;\\n{res['tool_result']}\\n&lt;/stdout&gt;\\n&lt;/result&gt;\" \n            for res in invoke_results\n        ) + \"\\n&lt;/function_results&gt;\"\n    )\n    \n    return constructed_prompt\nformatted_results = [{\n    'tool_name': 'reverse_string',\n    'tool_result': reversed_string\n}]\nfunction_results = construct_successful_function_run_injection_prompt(formatted_results)\nprint(function_results)\n\n&lt;function_results&gt;\n&lt;result&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;stdout&gt;\ntpgtahcaidepolcycne\n&lt;/stdout&gt;\n&lt;/result&gt;\n&lt;/function_results&gt;\npartial_assistant_message = function_calling_message + \"&lt;/function_calls&gt;\" + function_results\n\nfinal_message = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        reverse_message,\n        {\n            \"role\": \"assistant\",\n            \"content\": partial_assistant_message\n        }\n    ],\n    system=system_prompt\n).content[0].text\n\nprint(partial_assistant_message + final_message)\n\nOkay, let's reverse the string \"encyclopediachatgpt\" using the reverse_string tool:\n\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;string&gt;encyclopediachatgpt&lt;/string&gt;\n&lt;/parameters&gt;\n&lt;/invoke&gt;\n&lt;/function_calls&gt;&lt;function_results&gt;\n&lt;result&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;stdout&gt;\ntpgtahcaidepolcycne\n&lt;/stdout&gt;\n&lt;/result&gt;\n&lt;/function_results&gt;\n\n\"encyclopediachatgpt\" reversed is \"tpgtahcaidepolcycne\".\nprint(final_message)\n\n\n\n\"encyclopediachatgpt\" reversed is \"tpgtahcaidepolcycne\"."
  },
  {
    "objectID": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html#anthropic-tools-installation",
    "href": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html#anthropic-tools-installation",
    "title": "Anthropic Claude3: Function Calling Tools in Python",
    "section": "Anthropic Tools Installation",
    "text": "Anthropic Tools Installation\nFunction calling is a technique that allows you to extend the capabilities of a language model like Claude by integrating external functions or APIs. It enables the model to perform tasks or access information that it wouldn’t be able to do on its own.\nThe process involves defining a set of tools (functions) that Claude can use, and then providing a structured prompt format that guides Claude on how to use these tools. The prompt format includes a description of each tool, its parameters, and how to call it.\nWhen Claude receives a user’s message, it analyzes the message and determines if it needs to use any of the available tools to provide a response. If it does, it generates a special message (called a “tool_inputs” message) that specifies which tool it wants to use and what arguments it wants to pass to that tool.\nAt this point, there are two modes of operation: automatic and manual.\n\nAutomatic Mode (execution_mode=‘automatic’):\n\nIn automatic mode, the tool use process is handled automatically by the ToolUser class.\nWhen Claude generates a “tool_inputs” message, the ToolUser automatically extracts the specified tool and its arguments, calls the corresponding function, and generates a “tool_outputs” message with the result.\nThis process continues until Claude generates a response that doesn’t require any tool use (i.e., a regular “assistant” message).\nAutomatic mode is simpler to use but provides less control over the tool use process.\n\nManual Mode (execution_mode=‘manual’):\n\nIn manual mode, you have more control over the tool use process.\nWhen Claude generates a “tool_inputs” message, the ToolUser stops and returns this message to you.\nYou are then responsible for extracting the specified tool and its arguments, calling the corresponding function, and generating a “tool_outputs” message with the result.\nYou pass this “tool_outputs” message back to the ToolUser, which sends it to Claude.\nThis process continues, with you manually handling each “tool_inputs” message, until Claude generates a regular “assistant” message.\nManual mode requires more code to handle the back-and-forth between Claude and the tools, but it allows you to add your own validation logic, custom error handling, and more.\n\n\nRegardless of the mode, the key idea is that Claude can ask to use external tools when it needs them, and the ToolUser facilitates the communication between Claude and these tools.\nThis function calling technique allows you to leverage the language understanding and generation capabilities of Claude, while augmenting it with additional capabilities provided by external functions. It’s a powerful way to create more capable and versatile AI systems.\nSome common use cases for function calling include: - Performing complex calculations or data transformations - Retrieving real-time data from APIs - Accessing databases or knowledge bases - Executing actions in external systems\n\n!git clone https://github.com/anthropics/anthropic-tools.git\n!cd anthropic-tools && pip install -r requirements.txt\n!cd anthropic-tools && cp -r tool_use_package ../\n\nCloning into 'anthropic-tools'...\nremote: Enumerating objects: 478, done.\nremote: Counting objects: 100% (52/52), done.\nremote: Compressing objects: 100% (21/21), done.\nremote: Total 478 (delta 35), reused 31 (delta 31), pack-reused 426\nReceiving objects: 100% (478/478), 1.94 MiB | 5.31 MiB/s, done.\nResolving deltas: 100% (343/343), done.\nRequirement already satisfied: aiohttp==3.8.6 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (3.8.6)\nRequirement already satisfied: aiosignal==1.3.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: annotated-types==0.6.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.6.0)\nRequirement already satisfied: anthropic==0.16.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.16.0)\nRequirement already satisfied: anthropic-bedrock==0.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.8.0)\nRequirement already satisfied: anyio==3.7.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.7.1)\nRequirement already satisfied: async-timeout==4.0.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.0.3)\nRequirement already satisfied: attrs==23.1.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (23.1.0)\nRequirement already satisfied: beautifulsoup4==4.12.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.12.2)\nRequirement already satisfied: certifi==2023.7.22 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2023.7.22)\nRequirement already satisfied: charset-normalizer==3.3.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (3.3.0)\nRequirement already satisfied: dataclasses==0.6 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.6)\nRequirement already satisfied: distro==1.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.8.0)\nRequirement already satisfied: dnspython==2.4.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.4.2)\nRequirement already satisfied: elastic-transport==8.4.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (8.4.1)\nRequirement already satisfied: elasticsearch==8.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (8.10.1)\nRequirement already satisfied: exceptiongroup==1.1.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.1.3)\nRequirement already satisfied: filelock==3.12.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (3.12.4)\nRequirement already satisfied: frozenlist==1.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (1.4.0)\nRequirement already satisfied: fsspec==2023.9.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (2023.9.2)\nRequirement already satisfied: h11==0.14.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (0.14.0)\nRequirement already satisfied: httpcore==0.18.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (0.18.0)\nRequirement already satisfied: httpx==0.25.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.25.0)\nRequirement already satisfied: huggingface-hub==0.17.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (0.17.3)\nRequirement already satisfied: idna==3.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (3.4)\nRequirement already satisfied: install==1.3.5 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (1.3.5)\nRequirement already satisfied: loguru==0.7.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (0.7.2)\nRequirement already satisfied: more-itertools==10.1.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (10.1.0)\nRequirement already satisfied: multidict==6.0.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (6.0.4)\nRequirement already satisfied: numpy==1.26.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (1.26.1)\nRequirement already satisfied: packaging==23.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (23.2)\nRequirement already satisfied: pinecone-client==2.2.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (2.2.4)\nRequirement already satisfied: pydantic==2.4.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (2.4.2)\nRequirement already satisfied: pydantic_core==2.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (2.10.1)\nRequirement already satisfied: python-dateutil==2.8.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (2.8.2)\nRequirement already satisfied: PyYAML==6.0.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (6.0.1)\nRequirement already satisfied: requests==2.31.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (2.31.0)\nRequirement already satisfied: six==1.16.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (1.16.0)\nRequirement already satisfied: sniffio==1.3.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (1.3.0)\nRequirement already satisfied: soupsieve==2.5 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (2.5)\nRequirement already satisfied: tenacity==8.2.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (8.2.3)\nRequirement already satisfied: tokenizers==0.14.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (0.14.1)\nRequirement already satisfied: tqdm==4.66.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (4.66.1)\nRequirement already satisfied: typing_extensions==4.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (4.8.0)\nRequirement already satisfied: urllib3==1.26.18 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (1.26.18)\nRequirement already satisfied: wikipedia==1.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (1.4.0)\nRequirement already satisfied: yarl==1.9.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (1.9.2)\nRequirement already satisfied: boto3&gt;=1.28.57 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.28.58)\nRequirement already satisfied: botocore&gt;=1.31.57 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.31.58)\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from boto3&gt;=1.28.57-&gt;anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.0.1)\nRequirement already satisfied: s3transfer&lt;0.8.0,&gt;=0.7.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from boto3&gt;=1.28.57-&gt;anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (0.7.0)"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-json-mode/messages_api_json.html",
    "href": "posts/anthropic-claude3-messages-api-json-mode/messages_api_json.html",
    "title": "Anthropic Claude3: Messages API with JSON Mode",
    "section": "",
    "text": "How to Use JSON Mode\n\nJSON (JavaScript Object Notation) is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate.\nWhen working with AI models like Claude, you may want to receive structured data in the form of JSON, rather than plain text. This allows for easier processing and extraction of information.\nAlthough Claude doesn’t have a built-in “JSON mode,” you can still get reliable JSON output by following a few techniques:\n\nUse string parsing to extract the JSON from Claude’s response by finding the text between “{” and “}” characters.\nProvide a partial response in the “assistant” role to remove any preamble text before the JSON. For example, send “Here is the JSON requested:\\n{” to start the JSON output immediately.\nIf the JSON output is followed by additional text, you can use a stop sequence to truncate the response after the JSON ends.\n\nFor more complex prompts that may include multiple JSON outputs, you can instruct Claude to wrap each JSON object in specific XML-like tags. This makes it easier to extract the JSON using regular expressions later.\nOnce you have extracted the JSON string from Claude’s response, you can use the json.loads() function in Python to parse it into a dictionary or list, depending on the structure of the JSON.\nBy following these techniques, you can effectively use Claude to generate structured JSON data, which can be easily integrated into your applications or workflows.\n\nRemember, while Claude is capable of generating JSON, it’s essential to provide clear instructions and examples to ensure you get the desired output format.\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nrecipe_text = \"\"\"\nBanana Bread Recipe\nIngredients:\n\n3 ripe bananas, mashed\n1/3 cup melted butter\n1/2 cup sugar\n1 egg, beaten\n1 teaspoon vanilla\n1 teaspoon baking soda\nPinch of salt\n1 1⁄2 cups all-purpose flour Instructions: Preheat oven to 350°F. Mix butter into the mashed bananas in a large mixing bowl. Mix in the sugar, egg, and vanilla. Sprinkle the baking soda and salt over the mixture and mix in. Add the flour last, mix just enough to blend the ingredients. Pour mixture into a buttered 4x8 inch loaf pan. Bake for 1 hour. Cool on a rack before removing from pan. Slice to serve. \"\"\"\n\n\nprompt = f\"\"\"\n\nRECIPE: {recipe_text}\n\nGive me a JSON dictionay of ingredients and quantities.\n\"\"\"\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": prompt\n        },\n        {\n            \"role\":\"assistant\",\n            \"content\": \"Here is the JSON requested:\\n{\"\n        }\n    ]\n).content[0].text\nprint(message)\n\n\n\n  \"ingredients\":[  \n    {\n      \"item\":\"ripe bananas\",\n      \"amount\":\"3\",\n      \"notes\":\"mashed\"\n    },\n    {\n      \"item\":\"butter\", \n      \"amount\":\"1/3 cup\",\n      \"notes\":\"melted\"\n    },\n    {\n      \"item\":\"sugar\",\n      \"amount\":\"1/2 cup\"\n    },\n    {\n      \"item\":\"egg\",\n      \"amount\":\"1\",\n      \"notes\":\"beaten\"  \n    },\n    {\n      \"item\":\"vanilla\",\n      \"amount\":\"1 teaspoon\"\n    },\n    {\n      \"item\":\"baking soda\",  \n      \"amount\":\"1 teaspoon\"\n    },\n    {\n      \"item\":\"salt\",\n      \"amount\":\"1 pinch\"\n    },\n    {\n      \"item\":\"all-purpose flour\",\n      \"amount\":\"1 1/2 cups\"  \n    }\n  ]\n\n}\n\n\n\nimport json\n\n\noutput_json = json.loads(\"{\" + message[:message.rfind(\"}\") + 1])\noutput_json\n\n{'ingredients': [{'item': 'ripe bananas', 'amount': '3', 'notes': 'mashed'},\n  {'item': 'butter', 'amount': '1/3 cup', 'notes': 'melted'},\n  {'item': 'sugar', 'amount': '1/2 cup'},\n  {'item': 'egg', 'amount': '1', 'notes': 'beaten'},\n  {'item': 'vanilla', 'amount': '1 teaspoon'},\n  {'item': 'baking soda', 'amount': '1 teaspoon'},\n  {'item': 'salt', 'amount': '1 pinch'},\n  {'item': 'all-purpose flour', 'amount': '1 1/2 cups'}]}\n\n\n\n\nGenerate Month names in English, Tamil, Spanish, and French\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"Generate month names in English, Tamil, Spanish, and French in JSON format. Language as keys, and list of month names as values.\"\n        },\n        {\n            \"role\":\"assistant\",\n            \"content\": \"Here is the JSON requested:\\n{\"\n        }\n    ]\n).content[0].text\nprint(message)\n\n\n  \"English\":\n  [\n    \"January\",\n    \"February\", \n    \"March\",\n    \"April\",\n    \"May\",\n    \"June\",\n    \"July\",\n    \"August\",\n    \"September\",\n    \"October\",\n    \"November\",\n    \"December\"\n  ],\n  \"Tamil\":\n  [\n    \"ஜனவரி\",\n    \"பிப்ரவரி\",\n    \"மார்ச்\",\n    \"ஏப்ரல்\",\n    \"மே\",\n    \"ஜூன்\",\n    \"ஜூலை\",\n    \"ஆகஸ்ட்\",\n    \"செப்டம்பர்\",\n    \"அக்டோபர்\",\n    \"நவம்பர்\",\n    \"டிசம்பர்\"\n  ],\n  \"Spanish\":\n  [\n    \"enero\",\n    \"febrero\",\n    \"marzo\",\n    \"abril\",\n    \"mayo\",\n    \"junio\",\n    \"julio\",\n    \"agosto\",\n    \"septiembre\",\n    \"octubre\",\n    \"noviembre\",\n    \"diciembre\"\n  ],\n  \"French\":\n  [\n    \"janvier\",\n    \"février\",\n    \"mars\",\n    \"avril\",\n    \"mai\",\n    \"juin\",\n    \"juillet\",\n    \"août\",\n    \"septembre\",\n    \"octobre\",\n    \"novembre\",\n    \"décembre\"\n  ]\n}\n\n\n\noutput_json = json.loads(\"{\" + message[:message.rfind(\"}\") + 1])\noutput_json\n\n{'English': ['January',\n  'February',\n  'March',\n  'April',\n  'May',\n  'June',\n  'July',\n  'August',\n  'September',\n  'October',\n  'November',\n  'December'],\n 'Tamil': ['ஜனவரி',\n  'பிப்ரவரி',\n  'மார்ச்',\n  'ஏப்ரல்',\n  'மே',\n  'ஜூன்',\n  'ஜூலை',\n  'ஆகஸ்ட்',\n  'செப்டம்பர்',\n  'அக்டோபர்',\n  'நவம்பர்',\n  'டிசம்பர்'],\n 'Spanish': ['enero',\n  'febrero',\n  'marzo',\n  'abril',\n  'mayo',\n  'junio',\n  'julio',\n  'agosto',\n  'septiembre',\n  'octubre',\n  'noviembre',\n  'diciembre'],\n 'French': ['janvier',\n  'février',\n  'mars',\n  'avril',\n  'mai',\n  'juin',\n  'juillet',\n  'août',\n  'septembre',\n  'octobre',\n  'novembre',\n  'décembre']}\n\n\n\noutput_json[\"English\"]\n\n['January',\n 'February',\n 'March',\n 'April',\n 'May',\n 'June',\n 'July',\n 'August',\n 'September',\n 'October',\n 'November',\n 'December']\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-streaming-python/messages_api_streaming.html",
    "href": "posts/anthropic-claude3-messages-api-streaming-python/messages_api_streaming.html",
    "title": "Anthropic Claude3: Messages API with Streaming",
    "section": "",
    "text": "# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nWithout Streaming\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"You are an expert travel guide\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ]\n)\n\nprint(message.content)\n\n[ContentBlock(text=\"Here are some of the top places to visit in Sydney, Australia:\\n\\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\\n\\n2. Sydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\\n\\n3. Bondi Beach - One of Australia's most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\\n\\n4. The Rocks - A historic neighborhood with cobblestone streets, colonial buildings, museums, and markets.\\n\\n5. Darling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\\n\\n6. Royal Botanic Garden Sydney - A beautiful park featuring diverse plant collections, harbor views, and a colony of flying foxes.\\n\\n7. Taronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\\n\\n8. Manly Beach - Take a ferry from Circular Quay to Manly to enjoy the beach, walk along the Manly Corso, and visit the Manly SEA LIFE Sanctuary.\\n\\n9. Queen Victoria Building (QVB) - A historic shopping center with intricate Romanesque architecture and high-end boutiques.\\n\\n10. Blue Mountains National Park - Located about 1.5 hours from Sydney, this stunning park offers hiking trails, waterfalls, and the famous Three Sisters rock formation.\", type='text')]\n\n\n\nfrom IPython.display import display, HTML, Markdown\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere are some of the top places to visit in Sydney, Australia:\n\nSydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\nSydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\nBondi Beach - One of Australia’s most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\nThe Rocks - A historic neighborhood with cobblestone streets, colonial buildings, museums, and markets.\nDarling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\nRoyal Botanic Garden Sydney - A beautiful park featuring diverse plant collections, harbor views, and a colony of flying foxes.\nTaronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\nManly Beach - Take a ferry from Circular Quay to Manly to enjoy the beach, walk along the Manly Corso, and visit the Manly SEA LIFE Sanctuary.\nQueen Victoria Building (QVB) - A historic shopping center with intricate Romanesque architecture and high-end boutiques.\nBlue Mountains National Park - Located about 1.5 hours from Sydney, this stunning park offers hiking trails, waterfalls, and the famous Three Sisters rock formation.\n\n\n\nIt took ~22 seconds to process the output\n\n\nWith Streaming\n\nwith client.messages.stream(\n    max_tokens=1024,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ],\n    model=\"claude-3-opus-20240229\",\n) as stream:\n  for text in stream.text_stream:\n      print(text, end=\"\", flush=True)\n\nHere are some of the top places to visit in Sydney, Australia:\n\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\n\n2. Sydney Harbour Bridge - Climb the bridge for stunning views of the city or walk across it for free.\n\n3. Bondi Beach - One of Australia's most famous beaches, known for its surf, sand, and cafes.\n\n4. The Rocks - A historic neighborhood with cobblestone streets, markets, and museums.\n\n5. Royal Botanic Garden Sydney - A beautiful park with stunning views of the harbor and city skyline.\n\n6. Taronga Zoo - A world-class zoo with a wide variety of animals and stunning views of the city.\n\n7. Darling Harbour - A waterfront precinct with restaurants, bars, and entertainment venues.\n\n8. Sydney Tower Eye - The tallest structure in Sydney, offering panoramic views of the city.\n\n9. Manly Beach - A popular beach town that can be reached by ferry from Circular Quay.\n\n10. Blue Mountains National Park - A stunning national park with hiking trails, waterfalls, and scenic lookouts, located just outside the city.\n\nThese are just a few of the many attractions Sydney has to offer. The city is also known for its diverse food scene, vibrant nightlife, and cultural events throughout the year.\n\n\n\ntype(stream)\n\nanthropic.lib.streaming._messages.MessageStream\n\n\n\n[f for f in dir(stream) if not f.startswith(\"_\")]\n\n['close',\n 'current_message_snapshot',\n 'get_final_message',\n 'get_final_text',\n 'on_content_block',\n 'on_end',\n 'on_exception',\n 'on_message',\n 'on_stream_event',\n 'on_text',\n 'on_timeout',\n 'response',\n 'text_stream',\n 'until_done']\n\n\nWhen you receive data from a server using Server-Sent Events (SSE), the server sends events to your application. Each event has a specific name and some associated data in JSON format. The event name tells you what kind of event it is, and the JSON data provides more details about that event.\nHere’s a step-by-step explanation of how the events flow:\n\nFirst, you’ll receive a message_start event. This event includes a Message object, but the content of the message will be empty at this point. It’s like a placeholder for the message that will be filled in later.\nNext, you’ll receive a series of content blocks. Each content block represents a part of the message’s content. The content blocks come in three stages:\n\ncontent_block_start: This event indicates the start of a new content block.\ncontent_block_delta: You might receive one or more of these events. They contain the actual content of the block.\ncontent_block_stop: This event marks the end of the content block.\n\nEach content block has an index number that tells you its position in the final Message object’s content array.\nAfter receiving all the content blocks, you’ll receive one or more message_delta events. These events indicate changes or updates to the overall Message object.\nFinally, you’ll receive a message_stop event. This event signifies that the server has finished sending the complete message.\n\nSo, in summary, the server sends events to your application, piece by piece, to gradually build up the complete message. It starts with a message_start event, followed by content blocks, message_delta events for updates, and ends with a message_stop event.\nBy following this event flow, your application can receive and process the message data from the server in a structured way, even if the message is sent in multiple parts.\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "",
    "text": "Voyage Vista\nWelcome to our tutorial on “Building a Personalised Travel Planner using OpenAI Assistants APIs”. In this blog post, we will guide you through the process of creating “Voyage Vista”, a travel planning tool that uses OpenAI Assistants APIs to bring your dream vacation to life."
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#voyage-vista-your-personal-travel-planner",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#voyage-vista-your-personal-travel-planner",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "Voyage Vista: Your Personal Travel Planner",
    "text": "Voyage Vista: Your Personal Travel Planner\nVoyage Vista is designed to make travel planning an immersive and enjoyable experience. It provides real-time weather updates, lists top tourist attractions, and offers customized travel guides, all with the aim of helping you create unforgettable memories.\n\nKey Features\n\nInteractive Map: Voyage Vista’s map provides real-time weather updates with intuitive color-coded indicators, making it easy to plan your day.\nCustomized Itineraries: Voyage Vista generates a detailed Word document that serves as your travel guide, filled with historical and cultural insights about your destination.\nReal-Time Weather Forecasts: Weather forecasts are displayed on an interactive map, helping you plan your day perfectly.\nTop Tourist Attractions: Voyage Vista ensures you don’t miss out on any highlights by listing the must-see spots of your chosen destination."
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#leveraging-openai-assistants-apis",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#leveraging-openai-assistants-apis",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "Leveraging OpenAI Assistants APIs",
    "text": "Leveraging OpenAI Assistants APIs\nIn the development of Voyage Vista, we will be using several features of the OpenAI Assistants APIs:\n\nParallel Function Calling: This feature allows us to execute multiple functions simultaneously, improving the efficiency of our application.\nCode Interpreter: The Code Interpreter feature will be instrumental in processing and interpreting the data and generate word documents and other processing data.\nThreads: Threads allow us to manage multiple conversations or tasks concurrently, which is useful for handling multiple user requests at the same time.\nMessages: The Messages feature will be used to communicate with users, providing them with real-time updates and responses to their queries.\n\nBy leveraging these features, we aim to create a dynamic, efficient, and user-friendly travel planning tool. In the following sections of this tutorial, we will delve deeper into each of these features and show you how to use them to build your own version of Voyage Vista\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\nimport time\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\n\n\nprint(openai.__version__)\n\n1.7.0\n\n\n\nimport plotly.graph_objects as go\nimport requests\n\ndef get_coordinates(place_name, city_name):\n    \"\"\"Fetches coordinates of a place using Nominatim API.\"\"\"\n    url = f\"https://nominatim.openstreetmap.org/search?format=json&q={place_name}, {city_name}\"\n    response = requests.get(url)\n    data = response.json()\n    if data:\n        return float(data[0]['lat']), float(data[0]['lon'])\n    else:\n        return None, None\n\nThis function takes a place name and city name and retrieve coordinates using nominatim API. It returns a tuple of latitude and longitude.\n\ndef create_city_map(city_name, attractions, is_rainy):\n    if not attractions:\n        print(f\"No attractions found for {city_name}\")\n        return None\n\n    # Prepare lists for latitudes and longitudes\n    lats, lons = [], []\n\n    # Add markers for each attraction\n    markers = []\n    for index, place in enumerate(attractions):\n        lat, lon = get_coordinates(place, city_name)\n        if lat and lon:\n            lats.append(lat)\n            lons.append(lon)\n            marker_color = 'red' if is_rainy[index].lower() == 'yes' else 'blue'\n            markers.append(go.Scattermapbox(\n                lon = [lon],\n                lat = [lat],\n                mode = 'markers+text',  # Combine markers and text\n                marker = go.scattermapbox.Marker(size=14, color=marker_color),\n                text = [f\"{index + 1}. {place}\"],\n                textposition = \"top right\",  # Position of the text,\n                name=place\n            ))\n\n    # Create a Plotly map\n    city_map = go.Figure(markers)\n\n    # Automatically adjust the zoom to fit all markers\n    city_map.update_layout(\n        mapbox_style=\"open-street-map\",\n        mapbox = {\n            'center': go.layout.mapbox.Center(lat=sum(lats) / len(lats), lon=sum(lons) / len(lons)),\n            'zoom': 10  # Adjust this value for best fit\n        },\n        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n    )\n\n    city_map.show()\n\n    # save the map to png file\n    city_map.write_image(f'{city_name}.png')\n\n    return {'png': f'{city_name}.png'}\n\n# Dummy data\ncity_name = 'London'\nattractions = ['London Eye', 'Buckingham Palace', 'British Museum']\nis_rainy = ['Yes', 'No', 'No']\n\ncreate_city_map(city_name, attractions, is_rainy)\n\n\n                                                \n\n\n{'png': 'London.png'}\n\n\ncreate_city_map function is helpfule to plot the map of tourist attractions, it also takes weather information such as is_raining and color code the map accordingly.\n\n# !pip install -U kaleido\n\n\napi_key = os.getenv(\"OPENWEATHER_API_KEY\")\n\n\nimport requests\nimport json\nimport os\nfrom datetime import datetime\n\n\ndef get_weather(location, date, unit=\"metric\", use_coordinates=False):\n    \"\"\"Get weather for a given location and date using OpenWeather API.\"\"\"\n    current_date = datetime.now().date()\n    requested_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n\n    if requested_date == current_date:\n        endpoint = \"weather\"  # Current weather\n    elif requested_date &lt; current_date:\n        endpoint = (\n            \"timemachine\"  # Historical weather (requires different API subscription)\n        )\n    else:\n        endpoint = \"forecast\"  # Future weather (limited to 5-16 days based on API plan)\n\n    base_url = f\"http://api.openweathermap.org/data/2.5/{endpoint}\"\n\n    if use_coordinates:\n        params = {\n            \"lat\": location[0],\n            \"lon\": location[1],\n            \"appid\": api_key,\n            \"units\": unit,\n        }\n    else:\n        params = {\"q\": location, \"appid\": api_key, \"units\": unit}\n\n    if endpoint == \"timemachine\":\n        params[\"dt\"] = int(requested_date.timestamp())\n\n    try:\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        data = response.json()\n\n        weather = {\n            \"location\": location,\n            \"date\": date,\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\",\n            \"temperature\": data[\"list\"][0][\"main\"][\"temp\"],\n            \"humidity\": data[\"list\"][0][\"main\"][\"humidity\"],\n            \"wind_speed\": data[\"list\"][0][\"wind\"][\"speed\"],\n            \"description\": data[\"list\"][0][\"weather\"][0][\"description\"],\n        }\n        # weather.update(data[\"list\"][0])\n        return json.dumps(weather, indent=4)\n    except KeyError as err:\n        # for current date\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        data = response.json()\n        weather = {\n            \"location\": location,\n            \"date\": date,\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\",\n            \"temperature\": data[\"main\"][\"temp\"],\n            \"humidity\": data[\"main\"][\"humidity\"],\n            \"wind_speed\": data[\"wind\"][\"speed\"],\n            \"description\": data[\"weather\"][0][\"description\"],\n        }\n        return json.dumps(weather, indent=4)\n    except requests.exceptions.HTTPError as err:\n        return json.dumps({\"error\": f\"HTTP Error: {err}\"})\n    except requests.exceptions.RequestException as e:\n        return json.dumps({\"error\": f\"Request Error: {e}\"})\n\n\nweather_info = get_weather(\"Kyoto\", \"2024-01-11\")\nprint(weather_info)\n\n{\n    \"location\": \"Kyoto\",\n    \"date\": \"2024-01-11\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 6.17,\n    \"humidity\": 78,\n    \"wind_speed\": 2.36,\n    \"description\": \"overcast clouds\"\n}\n\n\nThe get_weather function for fetching weather information for a specific location and date using the OpenWeather API. It handles current, historical, and future weather data. The script is designed to process requests for specific dates and locations, returning a JSON formatted output with details like temperature, humidity, wind speed, and a weather description.\n\n# find location and weather details\n\nplace_name = \"Fushimi Inari-taisha Shrine, Kyoto\"\nlat, lon = get_coordinates(place_name, \"Kyoto\")\nprint(f\"Coordinates of {place_name}: {lat}, {lon}\")\n\nweather_info = get_weather((lat, lon), use_coordinates=True, date=\"2024-01-11\")\nprint(weather_info)\n\nCoordinates of Fushimi Inari-taisha Shrine, Kyoto: 34.9672545, 135.7737731\n{\n    \"location\": [\n        34.9672545,\n        135.7737731\n    ],\n    \"date\": \"2024-01-11\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 6.24,\n    \"humidity\": 77,\n    \"wind_speed\": 2.06,\n    \"description\": \"overcast clouds\"\n}\n\n\n\nweather_info = get_weather((lat, lon), use_coordinates=True, date=\"2024-01-10\")\nprint(weather_info)\n\n{\n    \"location\": [\n        34.9672545,\n        135.7737731\n    ],\n    \"date\": \"2024-01-10\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 7.22,\n    \"humidity\": 78,\n    \"wind_speed\": 0.45,\n    \"description\": \"overcast clouds\"\n}\n\n\n\ncity_name = \"Kyoto\""
  },
  {
    "objectID": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "href": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "title": "Master the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners",
    "section": "",
    "text": "# !pip3 install openai -U\n\nWelcome to our comprehensive guide on leveraging function calling in the OpenAI Assistant API. Whether you’re a seasoned developer or a curious beginner, this tutorial is designed to help you understand and implement this powerful feature in your AI projects.\nHere’s what we’ll be diving into:\n\nThe basics of function calling in the OpenAI Assistant API\nSteps to create an assistant\nCrafting a message and initiating a thread\nIdentifying when a message requires a function call\nDetermining which function to call and what arguments to pass\nRetrieving the response from a function call\nUnderstanding the final response\n\nOpenAI Assistants are equipped with a variety of tools, including retrieval, code interpretation, and function calling. In this guide, we’ll be focusing primarily on the function calling capabilities.\nTo illustrate these concepts, we’ll walk you through a simple demo. We’ll start by demonstrating a common challenge - reversing a string - and then show you how to overcome this challenge by creating a function that reverses the string and integrating it with the assistant.\nOur goal is to provide you with a clear, practical understanding of function calling in the OpenAI Assistant API, empowering you to create more dynamic and interactive AI applications. Let’s get started!\nIn general, assistants can use tools such as retrrieval, code interpreter, and function calling.\nIn this tutorial we focus more on function calling capabilities of assistants.\nWe create a simple demo that shows the failure of reversing a string and then we create a function that reverses the string and connect it with the assistant.\n\n# dictionary print indentatio\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\n\n# openai version\nopenai.__version__\n\n'1.6.1'\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nTo reverse the string “openaichatgpt”, you would simply reverse the order of the characters to get “tpgtahciapeneo”.\n\n\n\n\"tpgtahciapeneo\" == \"openaichatgpt\"[::-1]\n\nFalse\n\n\nLarge Language Models use tokens to split text into smaller pieces, and reversing a string is not a usual data that is has seen during training, so it is not able to predict it correctly.\nWe can fix this by creating a function that will reverse the string, and use the model to ask us to call the function and get results and pass it to the model.\n\ndef reverse_string(string):\n    return string[::-1]\n\n\nCreating an Assistant\n\n# function_json for reverse_string\nfunction_json = {'type':'function',\n            'function':{\n                'name': 'reverse_string',\n                'parameters':{\n                    \"type\":\"object\",\n                      \"properties\":{\n                          \"string\": {'type':'string','description':\"A single word\"},\n                      },\n                    'required' : [\"string\"]\n                }\n\n    }\n}\n\n\navailable_functions = {\n    \"reverse_string\": reverse_string\n}\n\n\nfrom openai import OpenAI\nclient = OpenAI()\n\n\nassistant = client.beta.assistants.create(\n    name=\"Python Tutor\",\n    instructions=\"You are a personal python tutor.\",\n    tools=[function_json],\n    model=\"gpt-4-1106-preview\"\n)\n\n\nassistant\n\nAssistant(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', created_at=1704457106, description=None, file_ids=[], instructions='You are a personal python tutor.', metadata={}, model='gpt-4-1106-preview', name='Python Tutor', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nprint(json.dumps(assistant.model_dump(), indent=4))\n\n{\n    \"id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"created_at\": 1704457106,\n    \"description\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"name\": \"Python Tutor\",\n    \"object\": \"assistant\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\ntype(assistant)\n\nopenai.types.beta.assistant.Assistant\n\n\n\n\nThread\n\nthread = client.beta.threads.create()\n\n\nthread.model_dump()\n\n{'id': 'thread_3fT59LTUrodHJPjBQYsIYm6F',\n 'created_at': 1704457106,\n 'metadata': {},\n 'object': 'thread'}\n\n\n\nthread\n\nThread(id='thread_3fT59LTUrodHJPjBQYsIYm6F', created_at=1704457106, metadata={}, object='thread')\n\n\n\n\nAdd a Message to a Thread\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what are different loops in python?\"\n)\n\n\nmessage\n\nThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')\n\n\n\nmessage.model_dump()\n\n{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'assistant_id': None,\n 'content': [{'text': {'annotations': [],\n    'value': 'what are different loops in python?'},\n   'type': 'text'}],\n 'created_at': 1704457107,\n 'file_ids': [],\n 'metadata': {},\n 'object': 'thread.message',\n 'role': 'user',\n 'run_id': None,\n 'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}\n\n\n\nthread_messages = client.beta.threads.messages.list(thread_id=thread.id)\nthread_messages.data\n\n[ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')]\n\n\n\nthread_messages.model_dump()\n\n{'data': [{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n   'assistant_id': None,\n   'content': [{'text': {'annotations': [],\n      'value': 'what are different loops in python?'},\n     'type': 'text'}],\n   'created_at': 1704457107,\n   'file_ids': [],\n   'metadata': {},\n   'object': 'thread.message',\n   'role': 'user',\n   'run_id': None,\n   'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}],\n 'object': 'list',\n 'first_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'last_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'has_more': False}\n\n\n\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": null,\n    \"status\": \"queued\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=thread.id,\n  run_id=run.id\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": 1704457108,\n    \"status\": \"in_progress\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=None, created_at=1704457108, expires_at=1704457708, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='in_progress', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nrun.status\n\n'in_progress'\n\n\n\nimport time\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n    \n\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\ncompleted\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=1704457140, created_at=1704457108, expires_at=None, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='completed', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nmessages = client.beta.threads.messages.list(\n  thread_id=thread.id\n)\n\nmessages\n\nSyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_a5FW3oicgn271ztQwcIa6kQ6', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', content=[MessageContentText(text=Text(annotations=[], value='In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\"apple\", \"banana\", \"cherry\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here\\'s an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere\\'s an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\"Found an even number\", num)\\n        continue\\n    print(\"Found a number\", num)\\nelse:\\n    print(\"The loop is completed without a break statement.\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it\\'s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.'), type='text')], created_at=1704457109, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BLZnD60Vl7wePLUsdmUFR5zd', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F'), ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')], object='list', first_id='msg_a5FW3oicgn271ztQwcIa6kQ6', last_id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', has_more=False)\n\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\n\n# new message\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what's the reverse of the string openaichatgpt?\"\n)\n\n\n# new run\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n# wait for run to complete\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\nin_progress\nrequires_action\n\n\n\nrun.status\n\n'requires_action'\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun.required_action\n\nRequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')]), type='submit_tool_outputs')\n\n\n\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    print(\"Tool call: \", tool_call)\n    function_name = tool_call.function.name\n    print(\"Function name: \", function_name)\n    arguments = json.loads(tool_call.function.arguments)\n    print(\"Function arguments: \", arguments)\n\nTool call:  RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')\nFunction name:  reverse_string\nFunction arguments:  {'string': 'openaichatgpt'}\n\n\n\n# call the function\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    function_name = tool_call.function.name\n    arguments = json.loads(tool_call.function.arguments)\n    function = available_functions[function_name]\n    output = function(**arguments)\n    print(\"Function output: \", output)\n\nFunction output:  tpgtahcianepo\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\n\nLet the Model Know about the function outputs\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n    thread_id=thread.id,\n    run_id=run.id,\n    tool_outputs=[{\"tool_call_id\": tool_call.id, \"output\": json.dumps(output)}],\n)\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\ncompleted\n\n\n\n\nRetrieve the message from history and display the output\n\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n    )\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"The reverse of the string \\\"openaichatgpt\\\" is \\\"tpgtahcianepo\\\".\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457154,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_QPbWzZkoRFveMIRPWtvREz0s\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what's the reverse of the string openaichatgpt?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457145,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\nfor message in messages.data:\n    display(Markdown(message.content[0].text.value))\n    print(\"*\" * 80)\n\nThe reverse of the string “openaichatgpt” is “tpgtahcianepo”.\n\n\n********************************************************************************\n********************************************************************************\n********************************************************************************\n********************************************************************************\n\n\nwhat’s the reverse of the string openaichatgpt?\n\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\nwhat are different loops in python?\n\n\n\n\nDelete the Assistant\n\nresponse = client.beta.assistants.delete(assistant_id=assistant.id)\nprint(response)\n\nAssistantDeleted(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', deleted=True, object='assistant.deleted')\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/chatcompletions-vs-assistants-ai-openai/assistants_chatcomplettion.html",
    "href": "posts/chatcompletions-vs-assistants-ai-openai/assistants_chatcomplettion.html",
    "title": "OpenAI ChatCompletions vs OpenAI Assistants API: A Hands-on Comparison",
    "section": "",
    "text": "import json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\n\nAPI Keys: https://platform.openai.com/api-keys\n\n\nChat Completions API\n\nTakes a user’s message and a model as inputs\nGenerates responses to user inputs\nMessages serve as the fundamental component in Chat Completions API operations\n\n\n\nChat Completion Models: Drawbacks\n\nNo message history tracking\nLack of support for file inputs (e.g., PDFs, CSVs)\nChallenges with computational tasks\nNo management of context windows\nOperate synchronously\n\n\n\nAssistants API\n\nManages conversation Threads for Context Maintenance\nTools: Code Interpreter, Retrieval, Function calling\nSupports file handling\nAsynchronous support\nCan generate graphs, charts, and process various file types\n\n\n# !pip3 install openai --upgrade\n\n\n# openai version\nopenai.__version__\n\n'1.8.0'\n\n\n\n\n1. No Message Histories in ChatCompletions\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the capital of Japan\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nThe capital of Japan is Tokyo.\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Tell me something about that city\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nI’m sorry, but you didn’t specify which city you’re referring to. Could you please provide the name of the city you’re interested in learning about?\n\n\n\n\nNo Code Interpreter - Computational Tasks\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nTo reverse the string “openaichatgpt”, you would simply reverse the order of the characters to get “tpgtaahcianepo”.\n\n\n\n\"tpgtahciapeneo\" == \"openaichatgpt\"[::-1]\n\nFalse\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"what's todays date?\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nAs an AI, I don’t have real-time capabilities, so I can’t provide the current date. However, you can easily check the date on your computer, smartphone, or any other device with a calendar function.\n\n\n\n\nContext Window Handling\n\n\nSynchronous\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\n\nAssistants API\n\nassistant = client.beta.assistants.create(\n    name=\"Python Tutor\",\n    instructions=\"You are a python tutor teaching someone who has experience in Java\",\n    tools=[{\"type\":\"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\"\n)\n\n\nassistant\n\nAssistant(id='asst_4bTZR8hx96VEvyFca4hnmoe1', created_at=1705686038, description=None, file_ids=[], instructions='You are a python tutor teaching someone who has experience in Java', metadata={}, model='gpt-4-1106-preview', name='Python Tutor', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])\n\n\n\nthread = client.beta.threads.create()\nthread\n\nThread(id='thread_z12e0BsDI8SfaePTmRMsApXo', created_at=1705686038, metadata={}, object='thread')\n\n\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"reverse the string openaichatgpt\"\n)\n\n\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=assistant.id)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_npuaz95TU2HdDGu3cgRhkOsW\",\n    \"assistant_id\": \"asst_4bTZR8hx96VEvyFca4hnmoe1\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1705686039,\n    \"expires_at\": 1705686639,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a python tutor teaching someone who has experience in Java\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": null,\n    \"status\": \"queued\",\n    \"thread_id\": \"thread_z12e0BsDI8SfaePTmRMsApXo\",\n    \"tools\": [\n        {\n            \"type\": \"code_interpreter\"\n        }\n    ]\n}\n\n\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=thread.id,\n  run_id=run.id\n)\n\n\nrun.status\n\n'in_progress'\n\n\n\nmessages = client.beta.threads.messages.list(\n  thread_id=thread.id\n)\n\nmessages\n\nSyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_j9CJRJRiYrsfl7pk6a07u72c', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='reverse the string openaichatgpt'), type='text')], created_at=1705686038, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_z12e0BsDI8SfaePTmRMsApXo')], object='list', first_id='msg_j9CJRJRiYrsfl7pk6a07u72c', last_id='msg_j9CJRJRiYrsfl7pk6a07u72c', has_more=False)\n\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"reverse the string openaichatgpt\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1705686038,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_z12e0BsDI8SfaePTmRMsApXo\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n    \"last_id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n    \"has_more\": false\n}\n\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nreverse the string openaichatgpt\n\n\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"make the previous input as uppercase and tell me the length of the string\"\n)\n\n\nimport time\n\n\n# new run\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n# wait for run to complete\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\nin_progress\nin_progress\ncompleted\n\n\n\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n    )\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nThe reversed string “tpgtahcianepo” in uppercase is “TPGTAHCIANEPO”. The length of this string is 13 characters.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "",
    "text": "Voyage Vista\n# !pip install selenium\n# !pip install webdriver-manager\n# !pip install fpdf\n# !pip install python-telegram-bot\n# !pip install nest_asyncio\nImagine a tool that transforms your morning routine into a seamless experience, where the latest updates on generative AI, large language models (LLMs), OpenAI, and more are delivered directly to you, not through the usual scrolling and searching, but through a personalized audio news briefing. This innovative project does just that. It autonomously navigates through your Twitter, Reddit, GitHub, and other websites, capturing screenshots as it scrolls through the feeds. These images are then analyzed to curate news content that aligns with your interests.\nThe magic doesn’t end there. This curated content is converted into an audio format and accompanying text documents with source urls, which are then sent to your Telegram. As you sip your morning coffee, you can listen to the latest developments in your fields of interest. If a particular story piques your curiosity, you can delve deeper by exploring the links provided. This not only saves you time but also ensures you’re always informed about the topics that matter to you. Gone are the days of manually sifting through various accounts for relevant news. Now, your custom news comes to you, allowing you to start your day informed and inspired.\nIn this blog post, I go through the different components and technologies I used to build this project."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#interesting-projects",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#interesting-projects",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Interesting Projects",
    "text": "Interesting Projects\n\nWhisper’s Performance Leap\nOne of the notable advancements that caught the attention of the AI community is the improvement in OpenAI’s Whisper model. Whisper, known for its robust speech-to-text capabilities, has seen a significant boost in performance with the introduction of Speculative Decoding. The processing time for transcribing audio has been nearly halved from 73 seconds to 33 seconds without any drop in accuracy. This enhancement is a testament to OpenAI’s commitment to pushing the boundaries of AI efficiency.\n\n\nGPT Store and Custom GPTs\nOpenAI’s GPT Store has been a hot topic, especially with the introduction of actions to custom GPTs. While some users have expressed concerns about the utility of most GPTs available in the store, others have shared advanced tutorials on how to improve GPTs by incorporating actions. This feature allows developers to rank higher and potentially monetize their custom GPTs, adding a new dimension to AI’s commercial viability.\n\n\nAI Hardware Innovations\nThe AI hardware space is also experiencing disruption, with companies like Humane raising significant funds and OpenAI reportedly raising $1 billion for the development of the “aiPhone.” These developments indicate a shift towards AI-integrated devices that could redefine user interactions with technology.\n\n\nAI and Copyrighted Material\nA contentious issue that has emerged is the use of copyrighted materials in training AI models. OpenAI has acknowledged the challenge of creating effective AI tools like ChatGPT without such materials. This has sparked a debate on the ethical and legal implications of AI development, with calls for proper consent and compensation for copyright holders.\n\n\nOpenAI’s Diverse Team\nOpenAI’s diverse team composition has also been a subject of discussion, with the bulk of the team being in their 30s, 40s, and 50s. This diversity is seen as a strength, bringing a wealth of experience and perspectives to the organization’s mission of ensuring that artificial general intelligence benefits all of humanity."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#community-reactions",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#community-reactions",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Community Reactions",
    "text": "Community Reactions\n\nGPT-4 Usage Caps and DALL-E Output\nOn platforms like Reddit, users have been vocal about their experiences with OpenAI’s services. Some have noticed tighter usage caps on ChatGPT-4, leading to quicker exhaustion of their allocated resources. Others have inquired about the impact of GPT Plus subscriptions on the speed and quality of DALL-E outputs.\n\n\nImplementing RAG on Document Corpora\nThe community has also been seeking best practices for implementing Retrieval-Augmented Generation (RAG) on document corpora with wide-ranging topics. This highlights the growing interest in leveraging OpenAI’s models for complex information retrieval tasks.\n\n\nGPT Store’s Selection Process\nCriticism has been directed at the GPT Store’s selection process, with some users pointing out a lack of vision in featuring unique and useful GPTs. The community has called for a more thoughtful curation process that prioritizes quality and utility over quantity.\n\n\nGPT Auth - Authentication for Custom GPTs\nAn interesting project shared by a community member is GPT Auth, which provides authentication and analytics for custom GPTs. This tool aims to help developers track users and queries, ensuring better management of their AI services.\n\n\nChatGPT, GPT-4, and Assistant API Distinctions\nThere’s a growing curiosity about the differences between ChatGPT, GPT-4, and the Assistant API. While GPT-4 is the core language model, ChatGPT and the Assistant API are seen as specialized workflows built around it, each with its unique capabilities and use cases."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#conclusion",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#conclusion",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Conclusion",
    "text": "Conclusion\nOpenAI continues to be at the forefront of AI research and development, with its projects and updates sparking lively discussions and debates within the tech community. From performance improvements in models like Whisper to the ethical considerations of using copyrighted materials, OpenAI’s work is shaping the future of AI and its integration into our daily lives. As the community engages with these advancements, it’s clear that OpenAI’s mission to benefit all of humanity through AI is a journey that many are keen to be a part of."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#message-2-create-a-word-document",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#message-2-create-a-word-document",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Message 2: Create a word document",
    "text": "Message 2: Create a word document\nI am creating one more assistant specialised in creating word documents.\nThe main reason is, I tried to use the same previous assistant to create word document, but it did not return any file in the annotations.\n\nassistant_doc = client.beta.assistants.create(\n    name=\"News Word Document Creater Assistant\",\n    instructions=\"\"\"You are a helpful assistant that creates word document with the full news along with their urls for read more\n    Do not miss any information.\n    \"\"\",\n    tools=[{\"type\":\"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\",\n\n)\n\n\n# new message\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Create a word document with the news content and their urls. Save the file as news.docx\"\n)\n\n\nmessages = run_assistant(assistant_doc.id, thread.id)\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: completed\n\n\nThe news content has been compiled into a Word document, and the file news.docx has been saved. You can download it from the link below:\nDownload news.docx\n\n\n\nfile_id = messages.data[0].content[0].text.annotations[0].file_path.file_id\n\n\ndef write_file_to_temp_dir(file_id, output_path):\n    file_data = openai.files.content(file_id)\n    file_data_bytes = file_data.read()\n    with open(output_path, \"wb\") as file:\n        file.write(file_data_bytes)\n\nnews_file = 'news.docx'\n\nwrite_file_to_temp_dir(file_id, news_file)"
  },
  {
    "objectID": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "href": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "title": "MoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists",
    "section": "",
    "text": "This blog post introduces “MoodCast,” a project that leverages OpenAI’s function calling feature to create real-time, weather-based music playlists. By integrating the OpenWeather and Spotify APIs, MoodCast demonstrates the power and flexibility of OpenAI’s function calling in a practical, engaging application.\nOpenAI’s function calling feature allows developers to describe a function, and the model generates a JSON output containing arguments. This feature doesn’t call any function itself, but it generates the JSON that can be used to call a function from your code. This is a significant advancement as it allows developers to interact with AI in a more structured and systematic way, overcoming the challenges of dealing with unstructured data outputs.\nIn the context of MoodCast, this feature is used to interact with the OpenWeather and Spotify APIs, creating a unique blend of AI, weather data, and music. The project serves as a practical example of how OpenAI’s function calling can be used to solve complex problems and create innovative applications.\nThis blog post will focus on how to use function calling for OpenAI’s chat completion endpoints. It will provide a detailed guide on how to leverage this feature for your applications, with MoodCast serving as a real-world example. Whether you’re a seasoned developer or a beginner in the field of AI, this post aims to provide valuable insights into the potential of OpenAI’s function calling feature.\n\n\n\nLogo\n\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\nFirst let’s check what openai chat completion say about current weather\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"what's the current weather in Tokyo?\"}\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\nprint(response)\n\nChatCompletion(id='chatcmpl-8dISDM1s7co80v8cx8z65WwUKkTLQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\", role='assistant', function_call=None, tool_calls=None))], created=1704376421, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=82, prompt_tokens=15, total_tokens=97))\n\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nI’m sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\n\n\nAs we can see openai does not have any information about the current weather. So we will use openweather api to get the current weather and then use openai chat completion to generate a response.\n\nLive Data using OpenWeatherMap API\nYou can signup here to get your api key https://openweathermap.org/api\nI have stored all the api key infomration in a .env file. You can create your own .env file and store your api key there.\n\n# .env file\n\nOPENWEATHER_API_KEY=your_api_key\nOPENAI_API_KEY = sk-key\nSPOTIFY_CLIENT_ID = 4444633gfdggdggdgdgdg\nSPOTIFY_CLIENT_SECRET = 23rtrrgrdgdr5353terg\n\nimport requests\n\ndef get_current_weather(city, api_key=os.getenv(\"OPENWEATHER_API_KEY\"), unit=\"metric\"):\n    \"\"\"Get the current weather for a given city using OpenWeather API.\"\"\"\n    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n    params = {\n        \"q\": city,\n        \"appid\": api_key,\n        \"units\": unit\n    }\n    response = requests.get(base_url, params=params)\n    if response.status_code == 200:\n        data = response.json()\n        #print(data)\n        weather = {\n            \"location\": data[\"name\"],\n            \"temperature\": int(data[\"main\"][\"temp\"]),\n            \"rain\": data[\"weather\"][0][\"main\"],\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\"\n        }\n        return json.dumps(weather)\n    else:\n        return {\"location\": city, \"temperature\": \"unknown\", \"unit\": unit, \"rain\": \"unknown\"}\n\napi_key = os.getenv(\"OPENWEATHER_API_KEY\")\nweather_info = get_current_weather(\"Nagercoil\")\nprint(weather_info)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\ntype(weather_info)\n\nstr\n\n\n\n\nSpotify Music\nWe can create an application on spotify and get the client id and client secret. We can use these credentials to get the access token and then use the access token to get the current weather based playlist.\nhttps://developer.spotify.com/\n\n# !pip3 install spotipy\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport os\nfrom IPython.display import Image, display, Audio\n\ndef search_song(song_name):\n    # Set up your Spotify credentials\n    client_id = os.getenv(\"SPOTIFY_CLIENT_ID\")\n    client_secret = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n\n    # Authenticate with Spotify\n    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\n    # Search for the song\n    results = sp.search(q=song_name, limit=1, type='track')\n    tracks = results['tracks']['items']\n\n    # Display the first result\n    if tracks:\n        track = tracks[0]\n        return json.dumps({\n            \"song\": track['name'],\n            \"artist\": ', '.join(artist['name'] for artist in track['artists']),\n            \"album\": track['album']['name'],\n            \"album_cover_url\": track['album']['images'][0]['url'],\n            \"preview_url\": track['preview_url']\n        })\n\n    else:\n        return \"No song found\"\n\nsong_name = \"Appadi podu\"\nsong_details = search_song(song_name)\nprint(song_details)\n\n{\"song\": \"Appadi Podu\", \"artist\": \"Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\", \"album\": \"Ghilli (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2737bbef42d34fd25b14b2a54ea\", \"preview_url\": \"https://p.scdn.co/mp3-preview/df03b78315eaa0c7e20d66ea17dcf1a5fa4e6e3e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\n# display song details\nsong_details_json = json.loads(song_details)\ndisplay(Image(url=song_details_json[\"album_cover_url\"], width=100), )\ndisplay(Markdown(f\"[{song_details_json['song']} by {song_details_json['artist']}]({song_details_json['preview_url']})\"))\nprint(song_details_json[\"album\"])\n\n\n\n\nAppadi Podu by Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\n\n\nGhilli (Original Motion Picture Soundtrack)\n\n\n\n\nCreating Tools\n\navailable_tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Get the current weather in a given location, use farhenheit\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city to get the weather for\",\n                        },\n                        \"unit\": {\n                            \"type\": \"string\",\n                            \"description\": \"The unit to use for the temperature, metric is default\",\n                            \"enum\": [\"metric\", \"imperial\"],\n                        }\n                    },\n                    \"required\": [\"city\", \"unit\"],\n                },\n            },\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_song\",\n                \"description\": \"Search for a song on Spotify and display its details including the artist, album, album cover, and a preview link if available\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"song_name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the song to search for\",\n                        }\n                    },\n                    \"required\": [\"song_name\"],\n                }\n            }\n        }\n    ]\n\nIn the MoodCast project, JSON is utilized to define tools for function descriptions, which are essential for the OpenAI function calling feature. This feature enables the AI to generate structured data outputs, specifically JSON objects containing arguments for functions described in the API call. For instance, the get_current_weather function is defined to fetch current weather data for a specified city, while the search_song function is designed to search for songs on Spotify. These function descriptions are crucial as they guide the AI in generating the correct JSON output that can be used to call functions from the code, thereby facilitating the integration with OpenWeather and Spotify APIs.\nTo effectively use function calling with OpenAI, developers must clearly define their functions, including the name, description, and parameters, in a JSON format. This structured approach allows the AI to understand the context and generate the appropriate JSON output. The OpenAI API documentation provides guidelines on how to describe functions for function calling, emphasizing the importance of a clear and detailed function schema to ensure accurate and useful responses from the AI model.\nFor MoodCast, this means that by defining functions like get_current_weather and search_song with precise parameters and descriptions, the AI can produce JSON outputs that correspond to these functions. These outputs can then be used to make API calls to OpenWeather and Spotify, respectively, to create a music playlist that matches the current weather conditions, showcasing a practical application of OpenAI’s function calling capability in a real-world project.\n\ncity = \"Nagercoil\"\n\n\n\nOpenai Chat Completion Function Calling\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n        and display their album details such as album cover, artist, and preview link.\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n        \"\"\"\n    }\n]\n\ntools = available_tools\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=messages,\n    tools=tools,\n    tool_choice=\"auto\", \n    temperature=0.9\n)\nresponse_message = response.choices[0].message\ntool_calls = response_message.tool_calls\n\nWe can also force the model to use some particular function by using tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function.\n\nresponse\n\nChatCompletion(id='chatcmpl-8dISaihzl1Q2k7S09VBau44EwlMMv', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]))], created=1704376444, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=28, prompt_tokens=249, total_tokens=277))\n\n\nAs when openai gonna use function calling, you can see the finish_reason in the response, which indicates we have to call the function with the given arguments and get the results, and pass it to the model again\n\nresponse_message\n\nChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])\n\n\n\nresponse_message.tool_calls\n\n[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]\n\n\n\nTool Calls\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_FmoMsWB1hklh6GvT9QmrTX3k\nCall the function: get_current_weather\nParameters: {\n  \"city\": \"Nagercoil\",\n  \"unit\": \"metric\"\n}\n\n\n\nfunction_name = tool_calls[0].function.name\nfunction_args = tool_calls[0].function.arguments\n\nfunction_name, function_args\n\n('get_current_weather', '{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}')\n\n\n\nfunction_args = json.loads(function_args)\nfunction_args\n\n{'city': 'Nagercoil', 'unit': 'metric'}\n\n\n\navailable_functions = {\n        \"get_current_weather\": get_current_weather,\n        \"search_song\": search_song,\n    }\n\n\nfunction_response = available_functions[function_name](**function_args)\nprint(function_response)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '}]\n\n\n\nmessages.append(response_message)\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])]\n\n\n\n\nAppending Tool Call Responses to the Message History\n\nmessages.append(\n                {\n                    \"tool_call_id\": tool_calls[0].id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'}]\n\n\n\n\nSecond Call to get Song Details\n\nsecond_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\nprint(second_response)\n\nChatCompletion(id='chatcmpl-8dISdx8ctxPgd8bD3BDnYCEOmialh', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]))], created=1704376447, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c6efb4aa39', usage=CompletionUsage(completion_tokens=279, prompt_tokens=307, total_tokens=586))\n\n\n\ndisplay(Markdown(second_response.choices[0].message.content))\n\nThe current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.\n\n\n\ntool_calls = second_response.choices[0].message.tool_calls\n\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_UEVy6FVIVy3V2kwcD36tDRvv\nCall the function: search_song\nParameters: {\"song_name\": \"Mazhai Kuruvi\"}\nTool ID: call_XKVJrqRjh1aafYldWeBWNnG2\nCall the function: search_song\nParameters: {\"song_name\": \"Nenjukulle\"}\nTool ID: call_I5Gnz9hvK1JuX8cSPFH14aL8\nCall the function: search_song\nParameters: {\"song_name\": \"Uyire Uyire\"}\nTool ID: call_KrUYtZqTDopUCua3dRbrOC9B\nCall the function: search_song\nParameters: {\"song_name\": \"Vaseegara\"}\nTool ID: call_w724Il0i6dFCDLG4l4OmPY4e\nCall the function: search_song\nParameters: {\"song_name\": \"Aaromale\"}\n\n\n\nmessages.append(second_response.choices[0].message)\n\n\n\nCall the function and append the results to the message history\n\nfor tool in tool_calls:\n    function_name = tool.function.name\n    function_args = json.loads(tool.function.arguments)\n    function_response = available_functions[function_name](**function_args)\n\n    messages.append(\n        {\n            \"tool_call_id\": tool.id,\n            \"role\": \"tool\",\n            \"name\": function_name,\n            \"content\": function_response,\n        }\n    )\n    print(function_response)\n\n{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'},\n ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]),\n {'tool_call_id': 'call_UEVy6FVIVy3V2kwcD36tDRvv',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_XKVJrqRjh1aafYldWeBWNnG2',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_I5Gnz9hvK1JuX8cSPFH14aL8',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_KrUYtZqTDopUCua3dRbrOC9B',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_w724Il0i6dFCDLG4l4OmPY4e',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'}]\n\n\n\n\nThird Response to get the final results as JSON Object\n\nthird_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n\nthird_response.choices[0].message.content\n\n'\\n{\\n    \"song_suggestions\": [\\n        {\\n            \"song\": \"Mazhai Kuruvi\",\\n            \"artist\": \"A.R. Rahman\",\\n            \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\"\\n        },\\n        {\\n            \"song\": \"Nenjukulle\",\\n            \"artist\": \"A.R. Rahman, Shakthisree Gopalan\",\\n            \"album\": \"Kadal (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\"\\n        },\\n        {\\n            \"song\": \"Uyire Uyire\",\\n            \"artist\": \"Hariharan, Bombay Jayashri\",\\n            \"album\": \"Bombay (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\"\\n        },\\n        {\\n            \"song\": \"Vaseegara\",\\n            \"artist\": \"Bombay Jayashri\",\\n            \"album\": \"Minnalae (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This classic love ballad with its serene mood is perfect for a cloudy day lounging.\"\\n        },\\n        {\\n            \"song\": \"Aaromale\",\\n            \"artist\": \"Alphons Joseph\",\\n            \"album\": \"Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"A refreshing song that\\'s well-suited for when the clouds are out and you crave an uplifting atmosphere.\"\\n        }\\n    ]\\n}'\n\n\n\n# display song details\nsong_details_json = json.loads(third_response.choices[0].message.content)\n\n\nsong_details_json\n\n{'song_suggestions': [{'song': 'Mazhai Kuruvi',\n   'artist': 'A.R. Rahman',\n   'album': 'Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.'},\n  {'song': 'Nenjukulle',\n   'artist': 'A.R. Rahman, Shakthisree Gopalan',\n   'album': 'Kadal (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.'},\n  {'song': 'Uyire Uyire',\n   'artist': 'Hariharan, Bombay Jayashri',\n   'album': 'Bombay (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b',\n   'preview_url': 'https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.'},\n  {'song': 'Vaseegara',\n   'artist': 'Bombay Jayashri',\n   'album': 'Minnalae (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This classic love ballad with its serene mood is perfect for a cloudy day lounging.'},\n  {'song': 'Aaromale',\n   'artist': 'Alphons Joseph',\n   'album': 'Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5',\n   'preview_url': 'https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"A refreshing song that's well-suited for when the clouds are out and you crave an uplifting atmosphere.\"}]}\n\n\n\ntype(song_details_json)\n\ndict\n\n\n\n\n\nDisplay Model Outputs\n\n# Displaying each song suggestion with its details\nfor song in song_details_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nMazhai Kuruvi\n\n\nArtist: A.R. Rahman\n\n\nAlbum: Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\n\n\n\n\n\nNenjukulle\n\n\nArtist: A.R. Rahman, Shakthisree Gopalan\n\n\nAlbum: Kadal (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\n\n\n\n\n\nUyire Uyire\n\n\nArtist: Hariharan, Bombay Jayashri\n\n\nAlbum: Bombay (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\n\n\n\n\n\nVaseegara\n\n\nArtist: Bombay Jayashri\n\n\nAlbum: Minnalae (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This classic love ballad with its serene mood is perfect for a cloudy day lounging.\n\n\n\n\n\nAaromale\n\n\nArtist: Alphons Joseph\n\n\nAlbum: Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: A refreshing song that’s well-suited for when the clouds are out and you crave an uplifting atmosphere.\n\n\n\n\n\n\n\nPutting it all together\n\ndef generate_weather_music(city):\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n            and display their album details such as album cover, artist, and preview link.\n            return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n            key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n            \"\"\"\n        }\n    ]\n    tools = available_tools\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",\n        temperature=0.9\n    )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n\n    if tool_calls:\n        function_name = tool_calls[0].function.name\n        function_args = json.loads(tool_calls[0].function.arguments)\n        function_response = available_functions[function_name](**function_args)\n\n        messages.append(response_message)\n        messages.append(\n            {\n                \"tool_call_id\": tool_calls[0].id,\n                \"role\": \"tool\",\n                \"name\": function_name,\n                \"content\": function_response,\n            }\n        )\n\n        second_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\n        response_message = second_response.choices[0].message\n        tool_calls = response_message.tool_calls\n\n        if tool_calls:\n            messages.append(response_message)\n            for tool in tool_calls:\n                function_name = tool.function.name\n                function_args = json.loads(tool.function.arguments)\n                function_response = available_functions[function_name](**function_args)\n\n                messages.append(\n                    {\n                        \"tool_call_id\": tool.id,\n                        \"role\": \"tool\",\n                        \"name\": function_name,\n                        \"content\": function_response,\n                    }\n                )\n\n            third_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n            return third_response\n\n\n\n\nimage.png\n\n\n\nresult = generate_weather_music(\"Sydney\")\n\n\nsong_suggestions_json = result.choices[0].message.content\n\n\ntype(song_suggestions_json)\n\nstr\n\n\n\nsong_suggestions_json = json.loads(song_suggestions_json)\n\n\nsong_suggestions_json \n\n{'song_suggestions': [{'song': 'Over the Rainbow',\n   'artist': \"Israel Kamakawiwo'ole\",\n   'album': 'Alone In Iz World',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27356c868c8c85e7e4e62bd9ec1',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2b0ebc854ece09122c1918aeff6af258493defe9?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"This classic song's soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\"},\n  {'song': 'Sweater Weather',\n   'artist': 'The Neighbourhood',\n   'album': 'I Love You.',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738265a736a1eb838ad5a0b921',\n   'preview_url': 'https://p.scdn.co/mp3-preview/877602f424a9dea277b13301ffc516f9fd1fbe7e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"The title itself and the song's vibe are a nod to the cozy feel of the current Sydney weather.\"},\n  {'song': 'Set Fire to the Rain',\n   'artist': 'Adele',\n   'album': '21',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2732118bf9b198b05a95ded6300',\n   'preview_url': 'https://p.scdn.co/mp3-preview/6fc68c105e091645376471727960d2ba3cd0ee01?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"Though it's not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\"},\n  {'song': 'Cloudy Day',\n   'artist': 'Tones And I',\n   'album': 'Cloudy Day',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d2cf6639f08099bdb14e388d',\n   'preview_url': 'https://p.scdn.co/mp3-preview/9c49fc0dfef73b4f91d444309b06450c9e30fee5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.'},\n  {'song': 'Cloudbusting',\n   'artist': 'Kate Bush',\n   'album': 'Hounds Of Love',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273ad08f4b38efbff0c0da0f252',\n   'preview_url': 'https://p.scdn.co/mp3-preview/0156aec767cfcbe6bfc80bb9c8ad931169a3d910?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.'}]}\n\n\n\nfor song in song_suggestions_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nOver the Rainbow\n\n\nArtist: Israel Kamakawiwo’ole\n\n\nAlbum: Alone In Iz World\n\n\n\n\n\nPreview the song\n\n\nReason: This classic song’s soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\n\n\n\n\n\nSweater Weather\n\n\nArtist: The Neighbourhood\n\n\nAlbum: I Love You.\n\n\n\n\n\nPreview the song\n\n\nReason: The title itself and the song’s vibe are a nod to the cozy feel of the current Sydney weather.\n\n\n\n\n\nSet Fire to the Rain\n\n\nArtist: Adele\n\n\nAlbum: 21\n\n\n\n\n\nPreview the song\n\n\nReason: Though it’s not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\n\n\n\n\n\nCloudy Day\n\n\nArtist: Tones And I\n\n\nAlbum: Cloudy Day\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.\n\n\n\n\n\nCloudbusting\n\n\nArtist: Kate Bush\n\n\nAlbum: Hounds Of Love\n\n\n\n\n\nPreview the song\n\n\nReason: An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/ai-assistants-crewai/classroom_crew.html",
    "href": "posts/ai-assistants-crewai/classroom_crew.html",
    "title": "crewAI: Simulating a Classroom with CrewAI Agents",
    "section": "",
    "text": "I’ve developed several AI Assistants using OpenAI’s API. In one project, I created an assistant that sifts through my social media and a few other websites, capturing screenshots, analyzing content, and preparing personalized news. Every morning, it sends me a voice message and a report on Telegram. In another project, I built a personalized travel planner. This assistant, upon receiving a city I plan to visit, checks its weather, creates a color-coded map, devises a personalized itinerary with an optimized travel path, and compiles a travel guide complete with cultural insights.\nA recurring challenge in these projects was that a single assistant couldn’t handle all the tasks. I had to design specialized assistants: one excelled at creating Word documents, another was adept at recommending places, and so on.\nUpon exploring the Crew Library, I realized that it enables the creation of multiple agents, each with specialized skills, roles, and tools. Importantly, these agents can share a common memory, allowing each to be aware of the others’ actions and progress.\nIn this blog post, let’s construct an AI Assistant/Agent to simulate a classroom setting. One agent will act as a teacher, instructing on a topic, while other agents will play the role of students, asking questions. The teacher agent will then incorporate these questions to make the class more engaging and interactive.\nIntroduction: The realm of AI development is constantly evolving, offering innovative ways to utilize technology in everyday tasks. In a recent project, we explored the capabilities of the Crew Library, a powerful tool for creating multiple AI agents, each with specialized skills. This article delves into a fascinating application of the Crew Library: simulating a classroom environment with AI agents.\nProject Overview: The project aimed to simulate a classroom setting with AI agents acting as a teacher and students. Using the Crew Library, we developed a teacher agent specialized in deep learning and multiple student agents at different comprehension levels: beginner, intermediate, and advanced. This setup allowed for an interactive and engaging educational experience, mimicking a real classroom.\nImplementation: 1. Agent Creation: We began by creating a teacher agent with a role as a deep learning instructor, equipped with goals, a backstory, and the ability to search the internet. The teacher’s primary goal was to teach deep learning to a diverse group of students. Similarly, student agents were created, each with their own goals and backstories corresponding to their understanding levels.\n\nTasks and Classroom Crew: We defined tasks for each agent. The student agents were tasked with asking questions based on their understanding levels, while the teacher agent’s task was to incorporate these questions into a more comprehensive teaching script. We then integrated these agents and tasks into a ‘classroom crew’ using the Crew Library, enabling sequential processing of tasks.\nExecution and Results: The classroom simulation was executed, where initially the teacher taught a topic in deep learning. Then, student agents asked questions according to their levels, which the teacher later integrated into a revised teaching script. The Crew Library’s sequential task processing allowed for a smooth flow of the classroom simulation.\nDisplay and Analysis: We utilized IPython’s display and markdown features to present the results. The final output showcased the teacher’s initial lecture, the students’ questions, and the final, enriched teaching script that included answers to these questions.\n\nConclusion: This project demonstrated the versatility and potential of the Crew Library in creating interactive and dynamic AI-driven environments. The successful simulation of a classroom setting not only underscores the importance of specialized AI agents in handling diverse tasks but also opens up new possibilities for AI-assisted learning and other applications.\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nclient.api_key = OPENAI_API_KEY\n\n\n# !pip install git+https://github.com/joaomdmoura/crewAI.git\n\n\n# !pip install openai --upgrade\n\n\n# !pip install crewai --upgrade\n# !pip install duckduckgo-search\n\n\nfrom langchain.tools import DuckDuckGoSearchRun\nsearch_tool = DuckDuckGoSearchRun()\n\n\nimport os\nfrom crewai import Agent, Task, Crew, Process\n\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n\n# !pip install -U langchain-openai\n\n\nfrom langchain_openai.chat_models import ChatOpenAI\n\n\n\nmodel = ChatOpenAI(model_name=\"gpt-4-turbo-preview\")\n\n\ntopic = \"Deep Learning\"\n\n\n\n# Create a classroom with a teacher and 5 students\nteacher = Agent(\n    role=f'{topic} Teacher',\n    goal=f'Teach {topic} to a diverse group of students',\n    backstory=f\"\"\"You are an experienced teacher specializing in {topic}.\n    Your goal is to impart knowledge to a class with varying levels of understanding.\n    You enjoy challenges and strive to make complex concepts accessible.You answer students' questions and provide feedback on their understanding.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[search_tool],\n    llm=model\n)\n\nadvanced_student1 = Agent(\n    role='Advanced Level Student',\n    goal=f'Understand advanced concepts in {topic}',\n    backstory=\"\"\"You are an advanced level student who excels in grasping complex\n    scientific principles. You enjoy pushing the boundaries of your understanding and\n    asking challenging questions.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],  # No specific tools for now\n    llm=model\n)\n\nadvanced_student2 = Agent(\n    role='Advanced Level Student',\n    goal=f'Understand advanced concepts in {topic}',\n    backstory=f\"\"\"You are another advanced level student who has a keen interest\n    in the intricate details of {topic}. You aim to explore the subject\n    at an advanced level and may pose challenging questions.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nintermediate_student1 = Agent(\n    role='Intermediate Level Student',\n    goal=f'Grasp fundamental concepts in {topic}',\n    backstory=f\"\"\"You are an intermediate level student with a good understanding of basic\n    {topic} principles. Your goal is to \n    ask questions that clarify fundamental concepts.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nintermediate_student2 = Agent(\n    role='Intermediate Level Student',\n    goal=f'Grasp fundamental concepts in {topic}',\n    backstory=f\"\"\"You are another intermediate level student aiming to ask questions to strengthen your grasp\n    on fundamental {topic} concepts. \"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nbeginner_student = Agent(\n    role='Beginner Level Student',\n    goal=f'Understand basic concepts in {topic}',\n    backstory=\"\"\"You are a beginner student who is working hard to understand\n    the basic principles of {topic}. Your questions may be more basic,\n    focusing on fundamental concepts.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\n\n\n\n\n\n# Create tasks for the students to ask questions\nquestion1 = Task(\n    description=f\"Ask a challenging question related to advanced {topic}. Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=advanced_student1)\n\nquestion2 = Task(\n    description=f\"Ask a challenging question related to advanced {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=advanced_student2\n)\n\nquestion3 = Task(\n    description=f\"Ask an average level question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=intermediate_student1\n)\n\nquestion4 = Task(\n    description=f\"Ask an average level question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=intermediate_student2\n)\n\nquestion5 = Task(\n    description=f\"Ask a basic question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=beginner_student\n)\n\n# Create a task for the teacher to answer questions\nteach1 = Task(\n    description=f\"Write your teaching script for the class. Your main goal is to teach {topic}. write 1000-1200 words\",\n    agent=teacher\n)\n\nteach2 = Task(\n    description=f\"Now re-write your teaching script based on your earlier script, incorporate the questions asked by the students, and include your answer in your script for maximum engagment.Your main goal is to write the script for the topic {topic}, we are just including students relevant question to the topic along with answers for better understanding of the topic. So stick with the topic {topic}\",\n    agent=teacher\n)\n\n\n\n# Instantiate the crew with a sequential process\nclassroom_crew = Crew(\n    agents=[teacher, advanced_student1, advanced_student2, intermediate_student1, intermediate_student2, beginner_student],\n    tasks=[teach1, question1, question2, question3, question4, question5, teach2],\n    verbose=2,\n    process= Process.sequential,\n    \n)\n\n# Start the class!\nclassroom_result = classroom_crew.kickoff()\n\nprint(\"######################\")\nprint(classroom_result)\n\n\n[DEBUG]: Working Agent: Deep Learning Teacher\n\n[INFO]: Starting Task: Write your teaching script for the class. Your main goal is to teach Deep Learning. write 1000-1200 words\n\n\n&gt; Entering new CrewAgentExecutor chain...\n**Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!Invalid Format: Missing 'Action:' after 'Thought:Do I need to use a tool? No\nFinal Answer: **Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!\n\n&gt; Finished chain.\n\n[DEBUG]: [Deep Learning Teacher] Task output: **Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!\n\n\n\n[DEBUG]: Working Agent: Advanced Level Student\n\n[INFO]: Starting Task: Ask a challenging question related to advanced Deep Learning. Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\n```\nThought: Do I need to use a tool? No\nFinal Answer: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n```\n\n&gt; Finished chain.\n\n[DEBUG]: [Advanced Level Student] Task output: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n```\n\n\n\n[DEBUG]: Working Agent: Advanced Level Student\n\n[INFO]: Starting Task: Ask a challenging question related to advanced Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n\n&gt; Finished chain.\n\n[DEBUG]: [Advanced Level Student] Task output: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n\n\n\n[DEBUG]: Working Agent: Intermediate Level Student\n\n[INFO]: Starting Task: Ask an average level question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In light of the concerns regarding the environmental impact of training large-scale deep learning models, a fundamental question arises: What are some of the emerging techniques or methodologies in deep learning that are aimed at reducing the computational intensity and, consequently, the carbon footprint of training these models, while still maintaining or enhancing their performance?\n\n&gt; Finished chain.\n\n[DEBUG]: [Intermediate Level Student] Task output: In light of the concerns regarding the environmental impact of training large-scale deep learning models, a fundamental question arises: What are some of the emerging techniques or methodologies in deep learning that are aimed at reducing the computational intensity and, consequently, the carbon footprint of training these models, while still maintaining or enhancing their performance?\n\n\n\n[DEBUG]: Working Agent: Intermediate Level Student\n\n[INFO]: Starting Task: Ask an average level question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In the quest to address the environmental concerns associated with training deep learning models, what are some of the innovative approaches being adopted to minimize computational demands and carbon emissions without compromising the effectiveness of these models?\n\n&gt; Finished chain.\n\n[DEBUG]: [Intermediate Level Student] Task output: In the quest to address the environmental concerns associated with training deep learning models, what are some of the innovative approaches being adopted to minimize computational demands and carbon emissions without compromising the effectiveness of these models?\n\n\n\n[DEBUG]: Working Agent: Beginner Level Student\n\n[INFO]: Starting Task: Ask a basic question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In addressing environmental concerns related to deep learning model training, several innovative approaches are being adopted. One fundamental approach is the development and use of more efficient algorithms that require less computational power, thereby reducing energy consumption. Another approach is the utilization of model pruning and quantization techniques, which streamline models by removing unnecessary parameters or reducing the precision of the calculations, making them less resource-intensive without significantly affecting performance. Additionally, there's a growing trend towards using renewable energy sources for powering data centers where these models are trained, further minimizing the carbon footprint associated with deep learning. Lastly, transfer learning is also gaining popularity as it allows developers to leverage pre-trained models on new tasks with minimal additional training required, significantly cutting down on the resources and energy needed for training models from scratch.\n\n&gt; Finished chain.\n\n[DEBUG]: [Beginner Level Student] Task output: In addressing environmental concerns related to deep learning model training, several innovative approaches are being adopted. One fundamental approach is the development and use of more efficient algorithms that require less computational power, thereby reducing energy consumption. Another approach is the utilization of model pruning and quantization techniques, which streamline models by removing unnecessary parameters or reducing the precision of the calculations, making them less resource-intensive without significantly affecting performance. Additionally, there's a growing trend towards using renewable energy sources for powering data centers where these models are trained, further minimizing the carbon footprint associated with deep learning. Lastly, transfer learning is also gaining popularity as it allows developers to leverage pre-trained models on new tasks with minimal additional training required, significantly cutting down on the resources and energy needed for training models from scratch.\n\n\n\n[DEBUG]: Working Agent: Deep Learning Teacher\n\n[INFO]: Starting Task: Now re-write your teaching script based on your earlier script, incorporate the questions asked by the students, and include your answer in your script for maximum engagment.Your main goal is to write the script for the topic Deep Learning, we are just including students relevant question to the topic along with answers for better understanding of the topic. So stick with the topic Deep Learning\n\n\n&gt; Entering new CrewAgentExecutor chain...\n### Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.Invalid Format: Missing 'Action:' after 'Thought:Thought: Do I need to use a tool? No\nFinal Answer: Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n&gt; Finished chain.\n\n[DEBUG]: [Deep Learning Teacher] Task output: Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n######################\nDeep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n\nclassroom_result\n\n'Deep Learning: A Comprehensive Introduction with Student Queries Integrated\\n\\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\\n\\n#### The Essence of Deep Learning\\n\\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain\\'s functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\\n\\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\\n\\n#### Key Components and Challenges\\n\\nLet\\'s break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\\n\\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\\n\\n#### Addressing Environmental Concerns\\n\\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\\n\\n#### Ethical Considerations and Future Potential\\n\\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\\n\\n#### Continuous Learning and Exploration\\n\\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\\n\\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let\\'s embark on this exciting journey together, ready to learn, question, and innovate.\\n\\n---\\n\\nThis script integrates the essence of deep learning with answers to students\\' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.'\n\n\n\nfrom IPython.display import display, Markdown\n\n\ndisplay(Markdown(classroom_crew.tasks[0].output.result))\n\nIntroduction to Deep Learning\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\nUnderstanding the Basics\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\nAt its core, a neural network consists of layers of nodes, or “neurons,” each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\nWhy Deep Learning?\nThe “deep” in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\nKey Components of Deep Learning\n\nData: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\nNeural Networks: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\nActivation Functions: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\nBackpropagation and Gradient Descent: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\nChallenges and Solutions\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\nEthics and Future Perspectives\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\nConclusion\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\nYour journey into deep learning starts now. Embrace the challenges, and let’s make the most of this opportunity to learn and grow together. Welcome aboard!\n\n\n\ndisplay(Markdown(f\"{classroom_result}\"))\n\nDeep Learning: A Comprehensive Introduction with Student Queries Integrated\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\nThe Essence of Deep Learning\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain’s functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\nA student once asked, “Why do we need multiple layers in neural networks?” The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n\nKey Components and Challenges\nLet’s break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n\nAddressing Environmental Concerns\nA pertinent question from a student highlighted a growing concern: “How does deep learning impact the environment?” Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n\nEthical Considerations and Future Potential\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n\nContinuous Learning and Exploration\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let’s embark on this exciting journey together, ready to learn, question, and innovate.\n\nThis script integrates the essence of deep learning with answers to students’ queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n\n\n# classroom_crew.tasks[0]\n\n\n# classroom_crew.tasks[0].model_dump()\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "href": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "title": "Understanding OpenAI ChatCompletion Model Parameters",
    "section": "",
    "text": "In this notebook, we will go through different parameters in LLM that control the token generation process\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\nIn each parameter, we will explore different range of values and discuss about openai’s default values and recommendations. Then in the final section we will go through some real examples to understand how these parameters affect the token generation process.\n\n\n\nIMG_F4CC52CE7F7F-1.jpeg\n\n\nI have written two helper functions highlight_openai_response and highlight for highlighting the probabilities of the tokens generated by the model. Less probable tokens are highlighted in white and more probable tokens are highlighted in green.\n\nquestion = \"\"\"\n\nWhat is machine learning? Explain it to a five year old.\nAnswer within 100 words, 3 paragraphs\n\"\"\"\n\nmodel = \"gpt-3.5-turbo\"\n\n\n\n\nimport seaborn as sns\nfrom IPython.display import HTML\nimport matplotlib.colors as mcolors\nimport numpy as np\n\n\ndef highlight_openai_response(response):\n    messages = response.choices[0].message.content\n    probabilities = []\n\n    for res in response.choices[0].logprobs.content:\n        probabilities.append(np.exp(res.logprob))\n\n    highlight(messages, probabilities)\n\n\ndef highlight(text, probabilities):\n    # Split the text into words, preserving newlines and spaces\n    words = []\n    for line in text.split(\"\\n\"):\n        words.extend([(word, \" \") for word in line.split(\" \")] + [(\"\\n\", \"\")])\n\n    # Remove the last element if it is a newline, added due to the split\n    if words[-1][0] == \"\\n\":\n        words.pop()\n\n    # Ensure probabilities list matches the number of non-empty words\n    normalized_probs = [min(max(0, p), 1) for p in probabilities]\n\n    # Use a Seaborn color palette and map probabilities to colors\n    palette = sns.light_palette(\"green\", as_cmap=True)\n\n    # Start building the HTML string using the 'pre' tag to preserve whitespace\n    html_string = \"&lt;pre style='font-family: inherit; white-space: pre-wrap; word-break: break-all;'&gt;\"\n\n\n    prob_index = 0  # Index for the current probability\n\n    for word, space in words:\n        if word and word != \"\\n\":  # If the element is not a space or newline\n            rgba_color = palette(normalized_probs[prob_index])\n            hex_color = mcolors.to_hex(rgba_color)\n            # Set the text color to black and the background color to the word's color\n            html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{word}&lt;/span&gt;\"\n            if space:\n                # Set the space's background color to the word's color\n                html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{space}&lt;/span&gt;\"\n            prob_index += 1\n        elif word == \"\\n\":\n            # Add a newline in HTML, and reset the color for the next line\n            html_string += \"&lt;br&gt;\"\n        else:\n            # This case handles multiple spaces in a row\n            previous_hex_color = mcolors.to_hex(\n                palette(normalized_probs[prob_index - 1])\n            )\n            html_string += (\n                f\"&lt;span style='background-color: {previous_hex_color};'&gt; &lt;/span&gt;\"\n            )\n\n    html_string += \"&lt;/pre&gt;\"  # Close the 'pre' tag\n\n    # Display the HTML string\n    display(HTML(html_string))\n\n\nhighlight(\"Hello I am Arun\", [0.9, 0.8, 0.6, 0.4])\n\nHello I am Arun \n\n\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n\n\nfrom openai import OpenAI, __version__\nprint(f\"OpenAI version: {__version__}\")\nclient = OpenAI()\n\nOpenAI version: 1.5.0\n\n\n\nseed = 42\n\n\nTokens\nIn large language models (LLMs), tokens are the smallest units of text that the model processes and generates. They can represent individual characters, words, subwords, or even larger linguistic units, depending on the specific tokenization approach used. Tokens act as a bridge between the raw text data and the numerical representations that LLMs can work with.\nIn the context of OpenAI, tokens are the basic units of text processed by their language models, such as GPT-3. OpenAI employs Byte-Pair Encoding (BPE) for tokenization, which is a method initially designed for text compression. BPE identifies the most frequent pairs of characters or tokens and merges them to form new tokens, thus optimizing the tokenization process for efficiency and effectiveness in representing the text data. This approach allows the model to handle a wide range of vocabulary, including rare words or phrases, by breaking them down into subword units.\n\n\n\nimage.png\n\n\nsource https://platform.openai.com/tokenizer\nIn openai chat completion APIs, four parameter controls the token generation process. They are\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\n\n\nTemperature\nIn large language models, temperature is a parameter that controls the randomness of predictions by scaling the logits before applying the softmax function. A low temperature makes the model more confident and conservative, favoring more likely predictions, while a high temperature increases diversity and creativity, allowing for less probable outcomes.\nTemperature adjusts the probability distribution of the next word. A higher temperature increases randomness, while a lower one makes the model more deterministic.\nPurpose: It controls the level of unpredictability in the output.\nThe temperature adjustment equation in LaTeX format is as follows:\n\\[\nP'(w_i) = \\frac{P(w_i)^{\\frac{1}{T}}}{\\sum_{j=1}^{V} P(w_j)^{\\frac{1}{T}}}\n\\]\nHere, \\(P(w_i)\\) is the original probability of the word \\(w_i\\), \\(T\\) is the temperature, \\(P'(w_i)\\) is the adjusted probability of the word, and \\(V\\) is the vocabulary size (the total number of words over which the probabilities are distributed). This equation shows how each original probability \\(P(w_i)\\) is raised to the power of the reciprocal of the temperature, and then normalized by dividing by the sum of all such adjusted probabilities to ensure that the adjusted probabilities sum to 1.\n\n0.15** (1/1.9)\n\n0.368437494723581\n\n\n\n0.15** (1/0.7)\n\n0.06652540281931184\n\n\n\nimport pandas as pd\n\n# Base probabilities for 20 words\nbase_probabilities = [\n    0.19, 0.12, 0.10, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03,\n    0.03, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01\n]\n\n# Temperatures\nhigh_temperature = 1.9\nlow_temperature = 0.4\n\n# Adjusted probabilities with high temperature\nadjusted_probabilities_high = [p ** (1 / high_temperature) for p in base_probabilities]\n\n# Adjusted probabilities with low temperature\nadjusted_probabilities_low = [p ** (1 / low_temperature) for p in base_probabilities]\n\n# Normalizing the adjusted probabilities for high temperature\nsum_adjusted_probabilities_high = sum(adjusted_probabilities_high)\nnormalized_probabilities_high = [p / sum_adjusted_probabilities_high for p in adjusted_probabilities_high]\n\n# Normalizing the adjusted probabilities for low temperature\nsum_adjusted_probabilities_low = sum(adjusted_probabilities_low)\nnormalized_probabilities_low = [p / sum_adjusted_probabilities_low for p in adjusted_probabilities_low]\n\nwords = [f\"word{i}\" for i in range(20)]\n\n# Create a DataFrame with the words and their probabilities, adjusted for high and low temperatures\ndf = pd.DataFrame({\n    \"word\": words,\n    \"base_probability\": base_probabilities,\n    \"adjusted_probability_high=1.9\": adjusted_probabilities_high,\n    \"normalized_probabilities_high=1.9\": normalized_probabilities_high,\n    \"adjusted_probability_low=0.4\": adjusted_probabilities_low,\n    \"normalized_probabilities_low=0.4\": normalized_probabilities_low\n})\n\ndf\n\n\n\n\n\n\n\n\nword\nbase_probability\nadjusted_probability_high=1.9\nnormalized_probabilities_high=1.9\nadjusted_probability_low=0.4\nnormalized_probabilities_low=0.4\n\n\n\n\n0\nword0\n0.19\n0.417250\n0.111183\n0.015736\n0.493728\n\n\n1\nword1\n0.12\n0.327611\n0.087298\n0.004988\n0.156515\n\n\n2\nword2\n0.10\n0.297635\n0.079310\n0.003162\n0.099221\n\n\n3\nword3\n0.09\n0.281580\n0.075032\n0.002430\n0.076245\n\n\n4\nword4\n0.08\n0.264654\n0.070522\n0.001810\n0.056797\n\n\n5\nword5\n0.07\n0.246693\n0.065736\n0.001296\n0.040677\n\n\n6\nword6\n0.06\n0.227469\n0.060613\n0.000882\n0.027668\n\n\n7\nword7\n0.05\n0.206656\n0.055067\n0.000559\n0.017540\n\n\n8\nword8\n0.04\n0.183756\n0.048965\n0.000320\n0.010040\n\n\n9\nword9\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n10\nword10\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n11\nword11\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n12\nword12\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n13\nword13\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n14\nword14\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n15\nword15\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n16\nword16\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n17\nword17\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n18\nword18\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n19\nword19\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n\n\n\n\n\n\ndf[\"base_probability\"].sum()\n\n1.0\n\n\nAs we can see that the base probabilities decrease progressively from word0 to word19, starting at 0.19 and going down to 0.01. However, after the adjustment, the probabilities are closer to each other, indicating that the temperature scaling has made the less likely words more probable and the more probable words less dominant.\nFor example, word0 has its probability decreased from 0.19 to about 0.11, while word19 has its probability slightly increased from 0.01 to about 0.024. This adjustment serves to flatten the probability distribution, making the model less certain and more explorative in its word choices.\nThe adjusted probabilities are also normalized, as their sum should equal 1 to represent a valid probability distribution. This adjustment allows for a less deterministic and more varied text generation, which can be useful for generating more diverse and creative text outputs.\nThe temperature adjustment has effectively reduced the likelihood of the most probable word being selected and increased the likelihood of less probable words, thus adding variability to the text generation process.\n\n# plot the probabilities\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.plot(words, base_probabilities, label=\"Base Probabilities\")\nplt.plot(words, normalized_probabilities_high, label=\"High Temperature\")\nplt.plot(words, normalized_probabilities_low, label=\"Low Temperature\")\nplt.xticks(rotation=90)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Probability\")\nplt.legend()\nplt.show()\n\n\n\n\n\nTemperature : 0( Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=0,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out.\n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.001537835, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.00058532227, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00044044392, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-0.31134152, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' having', bytes=[32, 104, 97, 118, 105, 110, 103], logprob=-1.0659788, top_logprobs=[])]\n\n\n\nprobs = []\n\n\nimport numpy as np\n\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\nresponse.system_fingerprint\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\n\nHigh Temperature ( More Randomness)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1.6,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster. That's how machines work too, they start with learning puzzles and every time they make a mistake, they remember that and try not to make the same mistake again. They keep getting better and better! They can use what they have learned to help us, like find things on the internet or even drive cars. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nTemperature : 1 ( Default)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs)\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\nOpenAI Recommendations for Temperature\n - default is 1 - range: 0 to 2 \n\n\nTop-P (Nucleus Sampling)\nTop-p sampling, also known as nucleus sampling, is a technique used in large language models to control the diversity and quality of generated text. It involves selecting tokens from the most probable options, where the sum of their probabilities determines the selection.\nThe “top p” parameter acts as a filter, controlling how many different words or phrases the model considers when predicting the next word. The lower the value of p, the more deterministic the responses generated by the model are.\nThis method helps balance between diversity and high-probability words, ensuring the output is both diverse and contextually relevant.\n\ndf_p = df[['word', 'base_probability']].copy()\n\ndf_p['cumulative_probability'] = df_p['base_probability'].cumsum()\n\ndf_p\n\n\n\n\n\n\n\n\nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.19\n0.19\n\n\n1\nword1\n0.12\n0.31\n\n\n2\nword2\n0.10\n0.41\n\n\n3\nword3\n0.09\n0.50\n\n\n4\nword4\n0.08\n0.58\n\n\n5\nword5\n0.07\n0.65\n\n\n6\nword6\n0.06\n0.71\n\n\n7\nword7\n0.05\n0.76\n\n\n8\nword8\n0.04\n0.80\n\n\n9\nword9\n0.03\n0.83\n\n\n10\nword10\n0.03\n0.86\n\n\n11\nword11\n0.03\n0.89\n\n\n12\nword12\n0.02\n0.91\n\n\n13\nword13\n0.02\n0.93\n\n\n14\nword14\n0.02\n0.95\n\n\n15\nword15\n0.01\n0.96\n\n\n16\nword16\n0.01\n0.97\n\n\n17\nword17\n0.01\n0.98\n\n\n18\nword18\n0.01\n0.99\n\n\n19\nword19\n0.01\n1.00\n\n\n\n\n\n\n\n\ndf_p.style.apply(lambda x: ['background: yellow' if x.cumulative_probability &lt;= 0.8 else '' for i in x], axis=1)\n\n\n\n\n\n\n \nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.190000\n0.190000\n\n\n1\nword1\n0.120000\n0.310000\n\n\n2\nword2\n0.100000\n0.410000\n\n\n3\nword3\n0.090000\n0.500000\n\n\n4\nword4\n0.080000\n0.580000\n\n\n5\nword5\n0.070000\n0.650000\n\n\n6\nword6\n0.060000\n0.710000\n\n\n7\nword7\n0.050000\n0.760000\n\n\n8\nword8\n0.040000\n0.800000\n\n\n9\nword9\n0.030000\n0.830000\n\n\n10\nword10\n0.030000\n0.860000\n\n\n11\nword11\n0.030000\n0.890000\n\n\n12\nword12\n0.020000\n0.910000\n\n\n13\nword13\n0.020000\n0.930000\n\n\n14\nword14\n0.020000\n0.950000\n\n\n15\nword15\n0.010000\n0.960000\n\n\n16\nword16\n0.010000\n0.970000\n\n\n17\nword17\n0.010000\n0.980000\n\n\n18\nword18\n0.010000\n0.990000\n\n\n19\nword19\n0.010000\n1.000000\n\n\n\n\n\n\ndf_p[\"base_probability\"].sum()\n\n1.0\n\n\n\nHigh Top-P ( Includes more tokens to sample)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture. \n\nMachine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things!\n\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.0015492603, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.0005857991, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00047642877, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' when', bytes=[32, 119, 104, 101, 110], logprob=-1.7854097, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' computers', bytes=[32, 99, 111, 109, 112, 117, 116, 101, 114, 115], logprob=-0.25018257, top_logprobs=[])]\n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\nLow Top-P ( More Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nOpenAI Recommendations for Top-P\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\nInteractions between Temperature and Top-P\nLet’s experiment the interactions between temperature and top-p\n\nHigh Temperature and High Top-P\nHigh Temperature and Low Top-P\nLow Temperature and High Top-P\nLow Temperature and Low Top-P\n\n\nHigh Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=1.6,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster.   Machine learning works a bit like that. It's like a really smart program that learns from doing things over and over again. It gets more and more powerful, by learning from its own experiences! So just like you, the computer program gets better and better at solving the problems it faces. Isn’t that amazing?! \n\n\n\n\nHigh Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=1.5,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\nLow Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. It's like when you play a game and get better each time because you remember what you did before. But instead of a game, the robot friend learns from lots of information and figures out patterns and rules. Then it can use what it learned to make predictions or do tasks without being told exactly what to do. It's like having a really clever friend who can help you with all sorts of things! \n\n\n\n\nLow Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just a computer using math to learn and make decisions. \n\n\n\n\n\nimage.png\n\n\n\n\n\nFrequency Penalty\nFrequency Penalty is used to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\nIt ranges from -2.0 to 2.0, where positive values discourage repetition by penalizing tokens that occur frequently, and negative values can increase the likelihood of repetition. This helps control the diversity of the generated content and prevent verbatim repetition.\n\n\n\nimage.png\n\n\nIn the above example, we can see recommendations such as National Park appeared twice in the generated text. We can use frequency penalty to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\n\nquestion = \"\"\"\n\nWrite 10 slogans for ChatGPT\n\n\"\"\"\n\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, we'll wow you!\" 6. \"ChatGPT: Making Conversations Magical!\" 7. \"Experience Smarter Chats with ChatGPT - Your virtual chat guru!\" 8. \"Elevate Your Chats with ChatGPT - Your chatbot companion!\" 9. \"ChatGPT: The Perfect Balance of Wit and Intelligence!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations made effortless!\" \n\n\n\nHigh Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with the Intelligence of ChatGPT.\" 5. \"Chat Smarter, With Confidence - Made Possible by ChatGPT!\" 6. \"Discover a New Level of Conversation Excellence with ChatGPT.\" 7. “Experience Artificial Intelligence that Feels Human – Meet chatbot G.” 8.“Make Every Interaction Count – Talk to Our Powerful AI Assistant!” 9.“Unlock Boundless Knowledge and Vivid Imagination– Say Hi to Our Intelligent AI friend!\"  10.\"Connect, Collaborate, Converse like never before - Powered by the Amazingness Of 'Yethe'\" \n\n\n\n\nLow Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT!\" 4. \"ChatGPT: Making Conversations Smarter!\" 5. \"Connect, Engage, and Learn with ChatGPT!\" 6. \"Elevate Your Conversations with ChatGPT!\" 7. \"ChatGPT: Your Virtual Conversational Superpower!\" 8. \"Experience the Future of Chat with ChatGPT!\" 9. \"ChatGPT: Making Talk as Intelligent as You!\" 10. \"ChatGPT: Your Chatbot Buddy for Every Occasion!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nPresence Penalty\nPresence Penalty is a parameter that influences the generation of new content by penalizing tokens that have already appeared in the text. It ranges from -2.0 to 2.0, where positive values discourage repetition and encourage the model to introduce new topics, while negative values do the opposite. This penalty is applied as a one-time, additive contribution to tokens that have been used at least once, helping to ensure more diverse and creative outputs\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, knowledge expands!\" 6. \"Join the Chat Revolution - Welcome to ChatGPT!\" 7. \"Experience Chat Brilliance with ChatGPT - Seamless Conversations, Unmatched Results!\" 8. \"Chat Smarter, Talk Faster with ChatGPT!\" 9. \"ChatGPT: The Intelligent Chatbot for All Your Conversational Needs!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations Redefined!\" \n\n\n\nHigh Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with ChatGPT's Intelligent AI.\" 5. \"ChatGPT: With You Every Step of the Conversation.\" 6. \"Unlock New Possibilities in Dialogue with ChatGPT.\" 7. \"Experience Natural Language Communication with ChatGPT.\" 8. \"Supercharge Your Conversations with ChatGPT's AI Assistant.\" 9. \"Chat Smarter, Not Harder, with ChatGPT.\" 10. \"Say Hello to Seamless Chats and Intelligent Responses with ChatGPT!\" \n\n\n\n\nLow Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Your Virtual Chatting Guru!\" 5. \"ChatGPT: Arm Your Conversations With Intelligence!\" 6. \"ChatGPT: Chatting Perfected with Artificial Intelligence!\" 7. \"ChatGPT: Your Personal Chatting Assistant with the Power of AI!\" 8. \"ChatGPT: Elevate Your Conversations to the Next Level!\" 9. \"ChatGPT: Your Smart Friend for Engaging Chats!\" 10. \"ChatGPT: Intelligent Conversations Made Effortless!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nInteraction between Frequency Penalty and Presence Penalty\n\nHigh Frequency Penalty and High Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.8,\n  frequency_penalty=1.8\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with AI-Powered ChatGPT.\" 5. \"Let's Talk! With Dynamic Dialogue Made Easy by ChatGPT.\" 6. \"Discover Smarter, More Natural Chats Using ChatGPT.\" 7. \"Unlock a World of Seamless Communication with ChatGPT.\"  8 .\"Experience Human-Like Interactions using our Advanced Assistant -Chat Gpt\" 9 .\"Your Virtual Conversation Buddy – Get Talking With Chat Gpt Now ! \" 10 .\"Revolutionize Your Conversations w \n\n\n\n\nLow Frequency Penalty and Low Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-0.5,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Chatting with Intelligence!\" 5. \"ChatGPT: Revolutionizing Chatting, One Conversation at a Time!\" 6. \"ChatGPT: Your Virtual Chatting Expert!\" 7. \"ChatGPT: Chatting with Artificial Intelligence that Feels Human!\" 8. \"ChatGPT: Chatting made Easy, Chatting made Powerful!\" 9. \"ChatGPT: Chatting with the Next Level of Chatbot Technology!\" 10. \"ChatGPT: Chatting. Redefined. \" \n\n\n\n\n\nPractical Use Cases\n\nIndustry 1: Creative Writing (e.g., Novels, Short Stories)\n\nTemperature: Set to 0.8-0.9. Higher temperature encourages more creative and unexpected turns of phrase, enhancing the storytelling with originality.\nTop P (Nucleus Sampling): Set around 0.9. Allows for a good range of probable words while still fostering creativity, which is vital in creative writing.\nFrequency Penalty: Set to a moderate value (e.g., 0.5). Helps avoid excessive repetition of words/phrases, maintaining a fresh and engaging narrative.\nPresence Penalty: Set to a lower value (e.g., 0.3-0.4). Encourages some repetition of key themes or phrases, which can be a powerful tool in storytelling.\n\n\n\nIndustry 2: Customer Support (e.g., Chatbots for Service Queries)\n\nTemperature: Set lower, around 0.3-0.4. Ensures more predictable and relevant responses, crucial for accurate customer support.\nTop P (Nucleus Sampling): Set around 0.8. Balances the need for coherent, relevant responses while allowing for some variability to better match customer queries.\nFrequency Penalty: Moderate to high (e.g., 0.6-0.8). In customer support, avoiding repetitive phrases can enhance clarity and professionalism in responses.\nPresence Penalty: Moderate (e.g., 0.5). Helps ensure a variety of information is provided, which can be crucial in addressing diverse customer queries comprehensively.\n\n\nExplanation:\n\nCreative Writing: The settings are designed to maximize creativity and originality, ensuring a rich and engaging narrative.\nCustomer Support: The focus here is on accuracy, relevance, and clarity in responses, which are essential in a customer support context.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-python/messages_api.html",
    "href": "posts/anthropic-claude3-messages-api-python/messages_api.html",
    "title": "Anthropic Claude3: Messages API with Multimodal Input",
    "section": "",
    "text": "The Claude 3 family represents Anthropic’s latest, most advanced AI models, offering state-of-the-art performance, versatility, and ease of use for open-ended conversation, idea collaboration, coding, and text processing."
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-python/messages_api.html#installation",
    "href": "posts/anthropic-claude3-messages-api-python/messages_api.html#installation",
    "title": "Anthropic Claude3: Messages API with Multimodal Input",
    "section": "Installation",
    "text": "Installation\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Large Language Models - Explained Intuitively",
    "section": "",
    "text": "Anthropic Claude3: Messages API with Images\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\nimage-analysis\n\n\n\n\nAnthropic’s Claude 3 models can understand and analyze images, allowing for conversations that include both text and visuals. Supported image formats include JPEG, PNG, GIF, and WebP. Multiple images can be included in a single request for analysis. Image analysis counts towards token usage. Claude has some limitations in image understanding but provides valuable interpretations.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Function Calling Tools in Python\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nfunction-calling\n\n\npython\n\n\n\n\nFunction calling tools in Python allow extending Claude’s capabilities by integrating external functions or APIs. Define functions, create tool descriptions, construct system prompts, and process user messages to generate responses with function calls. This powerful technique enables Claude to perform tasks beyond its built-in knowledge.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with JSON Mode\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Claude AI model can generate structured JSON data by following specific techniques. By providing clear instructions and examples, developers can extract JSON from Claude’s responses using string parsing, partial responses, stop sequences, or XML-like tags. The JSON can then be easily parsed and integrated into applications or workflows.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with Streaming\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Messages API supports streaming mode for real-time conversational AI responses. Using server-sent events (SSE), the API incrementally streams message content, allowing for dynamic user experiences. SDKs simplify implementation, while raw HTTP streaming is available for custom integrations. Developers can handle various event types and gracefully process unknown events.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with Multimodal Input\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Messages API enables creating sophisticated conversational AI experiences with text and image inputs. Customize model behavior using system prompts, fine-tune randomness with temperature, and stream responses. The API supports single queries and multi-turn conversations, making it versatile for various applications.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\ncrewAI: Simulating a Classroom with CrewAI Agents\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nagents\n\n\n\n\nWe use crewAI library to develop many agents and make them work together. We build a project where we simulate a classroom with students and teachers. Teacher agent teach a topic, student agents ask questions, then teacher agents incorporate the questions into the topic and teach again.\n\n\n\n\n\n\nFeb 2, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nOpenAI ChatCompletions vs OpenAI Assistants API: A Hands-on Comparison\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nopenai_assistants_api\n\n\nchat_completions\n\n\nhandson\n\n\n\n\nAssistants API offers advanced features like conversation threading, code execution, and data retrieval, ideal for complex AI applications. In contrast, Chat Completion Models are lightweight and efficient, ideal for simple AI applications.\n\n\n\n\n\n\nJan 20, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMorning with Jarvis: Craft Your Own News Universe from Social Media and News Digests\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\nhandson\n\n\n\n\nRevolutionize your morning routine with an AI-powered tool that delivers personalized audio news briefings on your topic of interest directly to your telegram. This project uses openai assistants API, Selenium, telegram API, openai text to speech models, DuckDuckGo for search, and many more.\n\n\n\n\n\n\nJan 14, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nTransform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\nhandson\n\n\n\n\nIn this article, we will build a personalised travel planner using OpenAI Assistants API. We will explore multiple parallel function calling, creating multiple assistants each focuses on a specific task, and we create a thread that interacts with multiple assistants. We create a fun project that does interactive maps, a personalised travel guide with real time weather updates, and a personalised travel planner.\n\n\n\n\n\n\nJan 10, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMaster the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\n\n\nDiscover how to leverage function calling in the OpenAI Assistant API with our comprehensive guide. This tutorial, suitable for both seasoned developers and beginners, covers the basics of function calling, creating an assistant, initiating a thread, and more. Learn how to identify when a message requires a function call, determine which function to call and what arguments to pass, and retrieve the response from a function call. We illustrate these concepts with a simple demo of reversing a string using a function integrated with the assistant. Enhance your AI applications with a clear, practical understanding of function calling in the OpenAI Assistant API\n\n\n\n\n\n\nJan 5, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\n\n\nThe blog post introduces MoodCast, a project that uses OpenAI’s parallel function calling feature to create real-time, weather-based music playlists. It integrates OpenWeather and Spotify APIs, demonstrating the power and flexibility of OpenAI’s function calling. This feature allows developers to describe a function, and the model generates a JSON output containing arguments. It doesn’t call any function itself, but generates the JSON that can be used to call a function from your code. This is a significant advancement as it allows developers to interact with AI in a more structured and systematic way, overcoming the challenges of dealing with unstructured data outputs. The blog post provides a detailed guide on how to use function calling for OpenAI’s chat completion endpoints, with MoodCast serving as a real-world example. It aims to provide valuable insights into the potential of OpenAI’s function calling feature for both seasoned developers and beginners in the field of AI\n\n\n\n\n\n\nJan 3, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding OpenAI ChatCompletion Model Parameters\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\n\n\nDetails: Dive into the intricacies of LLM token generation with our insightful notebook. We cover key parameters like temperature, top_p, frequency_penalty, and presence_penalty, examining their value ranges and OpenAI’s defaults.We highlight the generation probability using log_probs. Our comprehensive guide includes real examples to demonstrate how these settings impact the token generation process, providing a valuable resource for developers and AI enthusiasts alike\n\n\n\n\n\n\nDec 17, 2023\n\n\nArun Prakash\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I write and teach about my learnings in large language models.\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]