[
  {
    "objectID": "posts/anthropic-claude3-messages-images-claude3/messages_api_images.html",
    "href": "posts/anthropic-claude3-messages-images-claude3/messages_api_images.html",
    "title": "Anthropic Claude3: Messages API with Images",
    "section": "",
    "text": "Claude Vision\n\nClaude 3 models can understand and analyze images, allowing for conversations that include both text and visuals.\nSupported image formats include JPEG, PNG, GIF, and WebP. For optimal performance, resize images to no more than 1.15 megapixels and 1568 pixels in both dimensions.\nYou can include multiple images in a single request (up to 20 for API requests) for analysis\nEach image counts towards your token usage. Approximate cost per image can be calculated using the formula: tokens = (width px * height px) / 750.\nClaude has some limitations, such as identifying people, spatial reasoning, counting objects, and detecting AI-generated images. Always review and verify Claude’s interpretations.\nClaude does not generate, produce, edit, manipulate or create images; it only interprets and analyzes them.\n\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"You are an expert travel guide\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ]\n)\n\nprint(message.content)\n\n[ContentBlock(text=\"Here are some of the top places to visit in Sydney, Australia:\\n\\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\\n\\n2. Sydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\\n\\n3. Bondi Beach - One of Australia's most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\\n\\n4. The Rocks - A historic neighborhood with cobblestone streets, museums, galleries, and markets.\\n\\n5. Darling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\\n\\n6. Royal Botanic Garden Sydney - A beautiful oasis in the heart of the city, with diverse plant collections and stunning harbor views.\\n\\n7. Taronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\\n\\n8. Sydney Tower Eye - The tallest structure in Sydney, offering 360-degree views of the city from the observation deck and revolving restaurant.\\n\\n9. Manly Beach - A popular beach located a short ferry ride from the city center, known for its laid-back atmosphere and water activities.\\n\\n10. Blue Mountains National Park - A scenic park located about 2 hours from Sydney, known for its dramatic rock formations, waterfalls, and hiking trails.\\n\\nThese are just a few of the many attractions Sydney has to offer, and there are plenty of other neighborhoods, beaches, and cultural experiences to explore in this vibrant city.\", type='text')]\n\n\n\nfrom IPython.display import display, HTML, Markdown\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere are some of the top places to visit in Sydney, Australia:\n\nSydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\nSydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\nBondi Beach - One of Australia’s most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\nThe Rocks - A historic neighborhood with cobblestone streets, museums, galleries, and markets.\nDarling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\nRoyal Botanic Garden Sydney - A beautiful oasis in the heart of the city, with diverse plant collections and stunning harbor views.\nTaronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\nSydney Tower Eye - The tallest structure in Sydney, offering 360-degree views of the city from the observation deck and revolving restaurant.\nManly Beach - A popular beach located a short ferry ride from the city center, known for its laid-back atmosphere and water activities.\nBlue Mountains National Park - A scenic park located about 2 hours from Sydney, known for its dramatic rock formations, waterfalls, and hiking trails.\n\nThese are just a few of the many attractions Sydney has to offer, and there are plenty of other neighborhoods, beaches, and cultural experiences to explore in this vibrant city.\n\n\n\nfrom IPython.display import Image\n\n\nImage('claude_results.jpeg', width=800)\n\n\n\n\n\n# load image and convert to base64\nimport base64\nfrom PIL import Image\nfrom io import BytesIO\n\nimage_data = base64.b64encode(open('claude_results.jpeg', 'rb').read()).decode('utf-8')\n\n\ntype(image_data)\n\nstr\n\n\n\nimage_data[:100]\n\n'/9j/4AAQSkZJRgABAgEASABIAAD/4QDKRXhpZgAATU0AKgAAAAgABgESAAMAAAABAAEAAAEaAAUAAAABAAAAVgEbAAUAAAABAAAA'\n\n\n\n\nDescribe an Image\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": image_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Describe this image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01Xd14cQdncxYH1Cqt7ULGte', content=[ContentBlock(text='This image shows a comparison table of performance metrics across different AI language models.\\n\\nThe models compared include Claude 3 (in its Opus, Sonnet and Haiku variants), GPT-4, GPT-3.5, and two versions of Gemini 1.0.\\n\\nVarious metrics are listed down the left side, including:\\n- Undergraduate level knowledge (MMLU)\\n- Graduate level reasoning (GQPA, Diamond)\\n- Grade school math (GSM8K)  \\n- Math problem-solving (MATH)\\n- Multilingual math (MGSM)\\n- Code generation (HumanEval)\\n- Reasoning over text (DROP, F1 score) \\n- Mixed evaluations (BIG-Bench-Hard)\\n- Knowledge Q&A (ARC-Challenge)\\n- Common Knowledge (HellaSwag)\\n\\nThe cells contain the score each model achieved on the corresponding metric. The score format varies by row, with some showing x-shot scores, others showing raw scores, F1 scores, or number of shots.\\n\\nOverall, this table enables a side-by-side comparison of how well these prominent language models perform across a diverse set of NLP benchmarks and capability assessments. The color coding also helps highlight relative strengths and weaknesses.', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1640, output_tokens=291))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nThis image shows a comparison table of various metrics across different AI language models, including Claude 3 (in Opus, Sonnet and Haiku variants), GPT-4, GPT-3.5, and two versions of Gemini.\nThe metrics compared include: - Undergraduate level knowledge (MMLU) - Graduate level reasoning (GPQA, Diamond) - Grade school math (GSM8K) - Math problem-solving (MATH) - Multilingual math (MGSM) - Code generation (HumanEval) - Reasoning over text (DROP, F1 score) - Mixed evaluations (BIG-Bench-Hard) - Knowledge Q&A (ARC-Challenge) - Common Knowledge (HellaSwag)\nFor each metric, the scores are provided along with the number of “shots” used in the evaluation (e.g. 0-shot, 5-shot, 10-shot etc.). The scores are given as percentages, except for the DROP reasoning metric which uses an F1 score.\nOverall, the table allows comparing the performance of these different AI models across a range of knowledge domains and reasoning tasks. The color coding appears to highlight the best performing model for each metric.\n\n\n\n\nGenerate Code\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": image_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Write python code to create a bar plot from the image table. Only Claude columns, dont include other models. x label is all the metrics, y label is the values.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01THwqDdZn2oWfVF2XNu45w3', content=[ContentBlock(text=\"Here's the Python code to create a bar plot from the image table, including only the Claude columns:\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\nmetrics = ['Undergraduate level knowledge MMLU',\\n           'Graduate level reasoning GFQA, Diamond',\\n           'Grade school math GSMSB',\\n           'Math problem-solving MATH',\\n           'Multilingual math MGSM',\\n           'Code HumanEval',\\n           'Reasoning over text DROP, F1 score',\\n           'Mixed evaluations BIG-Bench-Hard',\\n           'Knowledge Q&A ARC-Challenge',\\n           'Common Knowledge HellaSwag']\\n\\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\\n\\nx = range(len(metrics))\\nwidth = 0.25\\n\\nfig, ax = plt.subplots(figsize=(12, 8))\\n\\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\\nax.bar([i + 2*width for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\\n\\nax.set_xlabel('Metrics')\\nax.set_ylabel('Values')\\nax.set_xticks([i + width for i in x])\\nax.set_xticklabels(metrics, rotation=45, ha='right')\\nax.legend()\\n\\nplt.tight_layout()\\nplt.show()\\n```\\n\\nThis code does the following:\\n\\n1. It imports the necessary matplotlib.pyplot module.\\n\\n2. It defines the metrics as a list of strings.\\n\\n3. It extracts the values for each Claude model (Opus, Sonnet, and Haiku) into separate lists.\\n\\n4. It sets up the x-coordinates and width for the bars.\\n\\n5. It creates a figure and an axis using `plt.subplots()`.\\n\\n6. It creates the bars for each Claude model using `ax.bar()`, with appropriate offsets for the x-coordinates.\\n\\n7. It sets the x-label and y-label using `ax.set_xlabel()` and `ax.set_ylabel()`, respectively.\\n\\n8. It sets the x-tick positions and labels using `ax.set_xticks()` and `ax.set_xticklabels()`, with rotation and horizontal alignment for better readability.\\n\\n9. It adds a legend using `ax.legend()`.\\n\\n10. It adjusts the layout using `plt.tight_layout()` to ensure the labels and titles fit nicely.\\n\\n11. Finally, it displays the plot using `plt.show()`.\\n\\nWhen you run this code, it will generate a bar plot comparing the performance of the Claude models (Opus, Sonnet, and Haiku) across various metrics.\", type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1670, output_tokens=825))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere’s the Python code to create a bar plot from the image table, including only the Claude columns:\nimport matplotlib.pyplot as plt\n\nmetrics = ['Undergraduate level knowledge MMLU',\n           'Graduate level reasoning GFQA, Diamond',\n           'Grade school math GSMSB',\n           'Math problem-solving MATH',\n           'Multilingual math MGSM',\n           'Code HumanEval',\n           'Reasoning over text DROP, F1 score',\n           'Mixed evaluations BIG-Bench-Hard',\n           'Knowledge Q&A ARC-Challenge',\n           'Common Knowledge HellaSwag']\n\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\n\nx = range(len(metrics))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\nax.bar([i + 2*width for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\n\nax.set_xlabel('Metrics')\nax.set_ylabel('Values')\nax.set_xticks([i + width for i in x])\nax.set_xticklabels(metrics, rotation=45, ha='right')\nax.legend()\n\nplt.tight_layout()\nplt.show()\nThis code does the following:\n\nIt imports the necessary matplotlib.pyplot module.\nIt defines the metrics as a list of strings.\nIt extracts the values for each Claude model (Opus, Sonnet, and Haiku) into separate lists.\nIt sets up the x-coordinates and width for the bars.\nIt creates a figure and an axis using plt.subplots().\nIt creates the bars for each Claude model using ax.bar(), with appropriate offsets for the x-coordinates.\nIt sets the x-label and y-label using ax.set_xlabel() and ax.set_ylabel(), respectively.\nIt sets the x-tick positions and labels using ax.set_xticks() and ax.set_xticklabels(), with rotation and horizontal alignment for better readability.\nIt adds a legend using ax.legend().\nIt adjusts the layout using plt.tight_layout() to ensure the labels and titles fit nicely.\nFinally, it displays the plot using plt.show().\n\nWhen you run this code, it will generate a bar plot comparing the performance of the Claude models (Opus, Sonnet, and Haiku) across various metrics.\n\n\n\nimport matplotlib.pyplot as plt\n\nmetrics = ['Undergraduate level knowledge MMLU',\n           'Graduate level reasoning GPQA, Diamond',\n           'Grade school math GSMSK',\n           'Math problem-solving MATH',\n           'Multilingual math MGSM',\n           'Code HumanEval',\n           'Reasoning over text DROP, F1 score',\n           'Mixed evaluations BIG-Bench-Hard',\n           'Knowledge Q&A ARC-Challenge',\n           'Common Knowledge HellaSwag']\n\nclaude_3_opus = [86.8, 50.4, 95.0, 60.1, 90.7, 84.9, 83.1, 86.8, 96.4, 95.4]\nclaude_3_sonnet = [79.0, 40.4, 92.3, 43.1, 83.5, 73.0, 78.9, 82.9, 93.2, 89.0]\nclaude_3_haiku = [75.2, 33.3, 88.9, 38.9, 75.1, 75.9, 78.4, 73.7, 89.2, 85.9]\n\nx = range(len(metrics))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(12, 8))\nax.bar(x, claude_3_opus, width, label='Claude 3 Opus')\nax.bar([i + width for i in x], claude_3_sonnet, width, label='Claude 3 Sonnet')\nax.bar([i + width*2 for i in x], claude_3_haiku, width, label='Claude 3 Haiku')\n\nax.set_ylabel('Values')\nax.set_xticks([i + width for i in x])\nax.set_xticklabels(metrics, rotation=45, ha='right')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nRecipe Generation\n\nrecipe_data = base64.b64encode(open('recipe.jpg', 'rb').read()).decode('utf-8')\n\n\nfrom IPython.display import Image\n\n\n#display the image\nImage('recipe.jpg', width=800)\n\n\n\n\nPrompt I used to generate the image is ‘A single perfect éclair, dark chocolate glaze, a single raspberry on top, cracked surface revealing vanilla custard’\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": recipe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Generate recipe for the given image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01L7JH75i2MPegcQa4b597DS', content=[ContentBlock(text='This image shows an appetizing raspberry chocolate eclair or cream puff dessert. The eclair pastry is golden brown and flaky looking, filled with a luscious vanilla cream filling, and topped with a rich chocolate ganache glaze and fresh raspberries dusted with cocoa powder.\\n\\nTo make raspberry chocolate eclairs, you would need to:\\n\\n1. Prepare choux pastry dough, pipe it into eclair shapes, and bake until puffed and golden.\\n\\n2. Make a vanilla pastry cream filling, let it chill, then pipe it into the cooled eclair shells. \\n\\n3. Prepare a shiny chocolate ganache glaze and dip or spread it on top of the filled eclairs.\\n\\n4. Top with fresh raspberries and dust with cocoa powder for the finishing touch. \\n\\n5. Chill the assembled eclairs for a couple hours to allow flavors to meld before serving.\\n\\nThe combination of crisp pastry, silky cream, bittersweet chocolate and tart-sweet raspberries makes for an irresistible treat that is sure to impress. While eclairs take some time and technique, the end result of this classic French patisserie is well worth the effort for a special occasion dessert.', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1648, output_tokens=279))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nThis image shows an appetizing raspberry chocolate eclair or cream puff dessert. The eclair pastry is golden brown and flaky looking, filled with a luscious vanilla cream filling, and topped with a rich chocolate ganache glaze and fresh raspberries dusted with cocoa powder.\nTo make raspberry chocolate eclairs, you would need to:\n\nPrepare choux pastry dough, pipe it into eclair shapes, and bake until puffed and golden.\nMake a vanilla pastry cream filling, let it chill, then pipe it into the cooled eclair shells.\nPrepare a shiny chocolate ganache glaze and dip or spread it on top of the filled eclairs.\nTop with fresh raspberries and dust with cocoa powder for the finishing touch.\nChill the assembled eclairs for a couple hours to allow flavors to meld before serving.\n\nThe combination of crisp pastry, silky cream, bittersweet chocolate and tart-sweet raspberries makes for an irresistible treat that is sure to impress. While eclairs take some time and technique, the end result of this classic French patisserie is well worth the effort for a special occasion dessert.\n\n\n\n\nImage with system prompt\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    system=\"You are an expert chef, who can generate recipes from images in french.\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": recipe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Generate recipe for the given image.\"\n                }\n            ],\n        }\n    ],\n)\nprint(message)\n\nMessage(id='msg_01QGkczZma6tD84ZQoNccyzW', content=[ContentBlock(text=\"Voici une recette pour un éclair au chocolat et aux framboises, inspirée de l'image :\\n\\nPâte à choux :\\n- 125 ml d'eau\\n- 50 g de beurre\\n- 65 g de farine \\n- 2 œufs\\n- 1 pincée de sel\\n\\nCrème pâtissière à la vanille :\\n- 250 ml de lait\\n- 50 g de sucre\\n- 30 g de farine\\n- 2 jaunes d'œufs \\n- 1 gousse de vanille\\n\\nGanache au chocolat :\\n- 100 g de chocolat noir\\n- 100 ml de crème fraîche liquide\\n\\nDécoration :\\n- Cacao en poudre\\n- Framboises fraîches\\n\\nInstructions :\\n\\n1. Préparez la pâte à choux en portant à ébullition l'eau, le beurre et le sel. Hors du feu, incorporez la farine d'un coup puis remettez sur feu doux en mélangeant jusqu'à ce que la pâte se décolle. Laissez tiédir puis incorporez les œufs un par un. Pochez sur une plaque et faites cuire 30 min à 180°C.\\n\\n2. Pour la crème, portez le lait et la vanille à ébullition. À part, mélangez sucre, farine et jaunes d'œufs. Versez le lait dessus en mélangeant, puis remettez sur feu doux jusqu'à épaississement. Laissez refroidir.\\n\\n3. Préparez la ganache en faisant fondre le chocolat avec la crème chauffée.\\n\\n4. Fourrez les éclairs refroidis de crème pâtissière, glacez-les de ganache, saupoudrez de cacao et décorez de framboises fraîches. \\n\\nDégustez ces délicieux éclairs faits maison, alliant le croquant de la pâte, la douceur vanillée de la crème et l'intense chocolat, rehaussés de framboises acidulées.\", type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=1664, output_tokens=543))\n\n\n\ndisplay(Markdown(message.content[0].text))\n\nVoici une recette pour un éclair au chocolat et aux framboises, inspirée de l’image :\nPâte à choux : - 125 ml d’eau - 50 g de beurre - 65 g de farine - 2 œufs - 1 pincée de sel\nCrème pâtissière à la vanille : - 250 ml de lait - 50 g de sucre - 30 g de farine - 2 jaunes d’œufs - 1 gousse de vanille\nGanache au chocolat : - 100 g de chocolat noir - 100 ml de crème fraîche liquide\nDécoration : - Cacao en poudre - Framboises fraîches\nInstructions :\n\nPréparez la pâte à choux en portant à ébullition l’eau, le beurre et le sel. Hors du feu, incorporez la farine d’un coup puis remettez sur feu doux en mélangeant jusqu’à ce que la pâte se décolle. Laissez tiédir puis incorporez les œufs un par un. Pochez sur une plaque et faites cuire 30 min à 180°C.\nPour la crème, portez le lait et la vanille à ébullition. À part, mélangez sucre, farine et jaunes d’œufs. Versez le lait dessus en mélangeant, puis remettez sur feu doux jusqu’à épaississement. Laissez refroidir.\nPréparez la ganache en faisant fondre le chocolat avec la crème chauffée.\nFourrez les éclairs refroidis de crème pâtissière, glacez-les de ganache, saupoudrez de cacao et décorez de framboises fraîches.\n\nDégustez ces délicieux éclairs faits maison, alliant le croquant de la pâte, la douceur vanillée de la crème et l’intense chocolat, rehaussés de framboises acidulées.\n\n\n\n\nMultiple Images: Getting Feedback on What Shoe to Wear for a Blue Suit\n\nblue_suit = base64.b64encode(open('suit.jpeg', 'rb').read()).decode('utf-8')\nblack_shoes = base64.b64encode(open('black_shoe.jpeg', 'rb').read()).decode('utf-8')\nbrown_shoes = base64.b64encode(open('brown_shoe.jpeg', 'rb').read()).decode('utf-8')\n\n\nImage('suit.jpeg', width=500)\n\n\n\n\n\nImage('black_shoe.jpeg', width=500)\n\n\n\n\n\nImage('brown_shoe.jpeg', width=500)\n\n\n\n\n\nsuit_data = base64.b64encode(open('suit.jpeg', 'rb').read()).decode('utf-8')\nblack_shoe_data = base64.b64encode(open('black_shoe.jpeg', 'rb').read()).decode('utf-8')\nbrown_shoe_data = base64.b64encode(open('brown_shoe.jpeg', 'rb').read()).decode('utf-8')\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    system=\"You are a fashion expert who has excellent knowledge of color combinations and can recommend the best color shoe for the given suit.\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Suit:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": suit_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Shoe 1:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": black_shoe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Shoe 2:\"\n                },\n                {\n                    \"type\": \"image\",\n                    \"source\": {\n                        \"type\": \"base64\",\n                        \"media_type\": \"image/jpeg\",\n                        \"data\": brown_shoe_data,\n                    },\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"For my suit, Look into  my suit color, and recommend what color shoe should I wear? Black or brown? Give reasons.\"\n                \n                }\n               \n            ],\n        }\n    ],\n)\n\n\ndisplay(Markdown(message.content[0].text))\n\nBased on the blue plaid suit shown in the image, I would recommend pairing it with the brown leather dress shoes (Shoe 2) rather than the black ones (Shoe 1). Here are a few reasons why:\n\nBrown shoes complement blue suits very well, creating a harmonious and stylish color combination. The warm tones of the brown leather pair nicely with the cool blue hues of the suit fabric.\nWearing brown shoes with a blue suit is a classic and versatile look that can work for both business and more casual occasions. It’s not quite as formal as a black shoe, but still polished and put-together.\nThe rich, burnished leather of the brown shoes in the photo would add some nice visual texture and depth to offset the plaid pattern of the suit. The broguing details on the shoes also provide an extra touch of style.\nBlack shoes, while always appropriate with a navy solid suit, can sometimes look a bit stark or severe with lighter shades of blue or bolder patterns like the plaid shown here. The brown option allows the suit to remain the focal point.\n\nSo in summary, while you can’t go wrong with either, I’d suggest the brown dress shoes as the optimal pairing to elevate this blue plaid suit. The combination strikes the right balance of dapper and distinctive.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html",
    "href": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html",
    "title": "Anthropic Claude3: Function Calling Tools in Python",
    "section": "",
    "text": "Function calling is a powerful technique that allows you to extend the capabilities of a language model like Claude by integrating external functions or APIs. It enables the model to perform tasks or access information that it wouldn’t be able to do on its own.\nIn the final response, Claude incorporates the result of the function call into its output, allowing it to provide a response that it wouldn’t have been able to generate on its own.\nFunction calling opens up a wide range of possibilities for extending the capabilities of language models like Claude. By defining custom functions and providing clear descriptions of how to use them, you can enable Claude to perform complex tasks, access real-time data, and interact with external systems.\n!pip install anthropic --upgrade\n\nRequirement already satisfied: anthropic in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (0.16.0)\nCollecting anthropic\n  Using cached anthropic-0.21.0-py3-none-any.whl (851 kB)\nRequirement already satisfied: anyio&lt;5,&gt;=3.5.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (3.7.1)\nRequirement already satisfied: distro&lt;2,&gt;=1.7.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (1.8.0)\nRequirement already satisfied: httpx&lt;1,&gt;=0.23.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (0.25.0)\nRequirement already satisfied: pydantic&lt;3,&gt;=1.9.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (2.4.2)\nRequirement already satisfied: sniffio in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (1.3.0)\nRequirement already satisfied: tokenizers&gt;=0.13.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (0.14.1)\nRequirement already satisfied: typing-extensions&lt;5,&gt;=4.7 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic) (4.8.0)\nRequirement already satisfied: idna&gt;=2.8 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anyio&lt;5,&gt;=3.5.0-&gt;anthropic) (3.4)\nRequirement already satisfied: certifi in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (2023.7.22)\nRequirement already satisfied: httpcore&lt;0.19.0,&gt;=0.18.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (0.18.0)\nRequirement already satisfied: annotated-types&gt;=0.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from pydantic&lt;3,&gt;=1.9.0-&gt;anthropic) (0.6.0)\nRequirement already satisfied: pydantic-core==2.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from pydantic&lt;3,&gt;=1.9.0-&gt;anthropic) (2.10.1)\nRequirement already satisfied: huggingface_hub&lt;0.18,&gt;=0.16.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from tokenizers&gt;=0.13.0-&gt;anthropic) (0.17.3)\nRequirement already satisfied: h11&lt;0.15,&gt;=0.13 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from httpcore&lt;0.19.0,&gt;=0.18.0-&gt;httpx&lt;1,&gt;=0.23.0-&gt;anthropic) (0.14.0)\nRequirement already satisfied: filelock in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (3.12.4)\nRequirement already satisfied: fsspec in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (2023.9.2)\nRequirement already satisfied: requests in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (4.66.1)\nRequirement already satisfied: pyyaml&gt;=5.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (6.0.1)\nRequirement already satisfied: packaging&gt;=20.9 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (23.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from requests-&gt;huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (3.3.0)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from requests-&gt;huggingface_hub&lt;0.18,&gt;=0.16.4-&gt;tokenizers&gt;=0.13.0-&gt;anthropic) (1.26.18)\nInstalling collected packages: anthropic\n  Attempting uninstall: anthropic\n    Found existing installation: anthropic 0.16.0\n    Uninstalling anthropic-0.16.0:\n      Successfully uninstalled anthropic-0.16.0\nSuccessfully installed anthropic-0.21.0\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\nimport anthropic\nimport re\nimport json\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\ndef construct_format_parameters_prompt(parameters):\n    constructed_prompt = \"\\n\".join(\n        f\"&lt;parameter&gt;\\n&lt;name&gt;{parameter['name']}&lt;/name&gt;\\n&lt;type&gt;{parameter['type']}&lt;/type&gt;\\n&lt;description&gt;{parameter['description']}&lt;/description&gt;\\n&lt;/parameter&gt;\"\n        for parameter in parameters\n    )\n    return constructed_prompt\ndef construct_format_tool_for_claude_prompt(name, description, parameters):\n    constructed_prompt = (\n        \"&lt;tool_description&gt;\\n\"\n        f\"&lt;tool_name&gt;{name}&lt;/tool_name&gt;\\n\"\n        \"&lt;description&gt;\\n\"\n        f\"{description}\\n\"\n        \"&lt;/description&gt;\\n\"\n        \"&lt;parameters&gt;\\n\"\n        f\"{construct_format_parameters_prompt(parameters)}\\n\"\n        \"&lt;/parameters&gt;\\n\"\n        \"&lt;/tool_description&gt;\"\n    )\n    return constructed_prompt\ndef construct_tool_use_system_prompt(tools):\n    tool_use_system_prompt = (\n        \"In this environment you have access to a set of tools you can use to answer the user's question.\\n\"\n        \"\\n\"\n        \"You may call them like this:\\n\"\n        \"&lt;function_calls&gt;\\n\"\n        \"&lt;invoke&gt;\\n\"\n        \"&lt;tool_name&gt;$TOOL_NAME&lt;/tool_name&gt;\\n\"\n        \"&lt;parameters&gt;\\n\"\n        \"&lt;$PARAMETER_NAME&gt;$PARAMETER_VALUE&lt;/$PARAMETER_NAME&gt;\\n\"\n        \"...\\n\"\n        \"&lt;/parameters&gt;\\n\"\n        \"&lt;/invoke&gt;\\n\"\n        \"&lt;/function_calls&gt;\\n\"\n        \"\\n\"\n        \"Here are the tools available:\\n\"\n        \"&lt;tools&gt;\\n\"\n        + '\\n'.join([tool for tool in tools]) +\n        \"\\n&lt;/tools&gt;\"\n    )\n    return tool_use_system_prompt\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -&gt; list[str]:\n    ext_list = re.findall(f\"&lt;{tag}&gt;(.+?)&lt;/{tag}&gt;\", string, re.DOTALL)\n    if strip:\n        ext_list = [e.strip() for e in ext_list]\n    return ext_list\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"Reverse the string encyclopediachatgpt\"\n        },\n\n    ]\n).content[0].text\nprint(message)\n\ntpgtahcaidepcolcycne\n\"tpgtahcaidepcolcycne\" == \"encyclopediachatgpt\"[::-1]\n\nFalse\nMost large language models (LLMs) struggle with string reversal tasks because they are primarily trained on natural language data and lack explicit programming knowledge.\ndef reverse_string(string):\n    return string[::-1]\ntool_name = \"reverse_string\"\ntool_description = \"Reverses the provided string.\"\n\nparameters = [\n    {\n        \"name\": \"string\",\n        \"type\": \"str\",\n        \"description\": \"The string to be reversed.\"\n    }\n]\n\ntool = construct_format_tool_for_claude_prompt(tool_name, tool_description, parameters)\nsystem_prompt = construct_tool_use_system_prompt([tool])\nprint(tool)\n\n&lt;tool_description&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;description&gt;\nReverses the provided string.\n&lt;/description&gt;\n&lt;parameters&gt;\n&lt;parameter&gt;\n&lt;name&gt;string&lt;/name&gt;\n&lt;type&gt;str&lt;/type&gt;\n&lt;description&gt;The string to be reversed.&lt;/description&gt;\n&lt;/parameter&gt;\n&lt;/parameters&gt;\n&lt;/tool_description&gt;\nprint(system_prompt)\n\nIn this environment you have access to a set of tools you can use to answer the user's question.\n\nYou may call them like this:\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;$TOOL_NAME&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;$PARAMETER_NAME&gt;$PARAMETER_VALUE&lt;/$PARAMETER_NAME&gt;\n...\n&lt;/parameters&gt;\n&lt;/invoke&gt;\n&lt;/function_calls&gt;\n\nHere are the tools available:\n&lt;tools&gt;\n&lt;tool_description&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;description&gt;\nReverses the provided string.\n&lt;/description&gt;\n&lt;parameters&gt;\n&lt;parameter&gt;\n&lt;name&gt;string&lt;/name&gt;\n&lt;type&gt;str&lt;/type&gt;\n&lt;description&gt;The string to be reversed.&lt;/description&gt;\n&lt;/parameter&gt;\n&lt;/parameters&gt;\n&lt;/tool_description&gt;\n&lt;/tools&gt;\nreverse_message = {\n    \"role\": \"user\",\n    \"content\": \"Reverse the string encyclopediachatgpt\"\n}\nfunction_calling_message = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[reverse_message],\n    system=system_prompt,\n    stop_sequences=[\"\\n\\nHuman:\", \"\\n\\nAssistant\", \"&lt;/function_calls&gt;\"]\n).content[0].text\n\nprint(function_calling_message)\n\nOkay, let's reverse the string \"encyclopediachatgpt\" using the reverse_string tool:\n\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;string&gt;encyclopediachatgpt&lt;/string&gt;\n&lt;/parameters&gt;\n&lt;/invoke&gt;\nstring = extract_between_tags(\"string\", function_calling_message)[0]\nreversed_string = reverse_string(string)\ndef construct_successful_function_run_injection_prompt(invoke_results):\n    constructed_prompt = (\n        \"&lt;function_results&gt;\\n\"\n        + '\\n'.join(\n            f\"&lt;result&gt;\\n&lt;tool_name&gt;{res['tool_name']}&lt;/tool_name&gt;\\n&lt;stdout&gt;\\n{res['tool_result']}\\n&lt;/stdout&gt;\\n&lt;/result&gt;\" \n            for res in invoke_results\n        ) + \"\\n&lt;/function_results&gt;\"\n    )\n    \n    return constructed_prompt\nformatted_results = [{\n    'tool_name': 'reverse_string',\n    'tool_result': reversed_string\n}]\nfunction_results = construct_successful_function_run_injection_prompt(formatted_results)\nprint(function_results)\n\n&lt;function_results&gt;\n&lt;result&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;stdout&gt;\ntpgtahcaidepolcycne\n&lt;/stdout&gt;\n&lt;/result&gt;\n&lt;/function_results&gt;\npartial_assistant_message = function_calling_message + \"&lt;/function_calls&gt;\" + function_results\n\nfinal_message = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        reverse_message,\n        {\n            \"role\": \"assistant\",\n            \"content\": partial_assistant_message\n        }\n    ],\n    system=system_prompt\n).content[0].text\n\nprint(partial_assistant_message + final_message)\n\nOkay, let's reverse the string \"encyclopediachatgpt\" using the reverse_string tool:\n\n&lt;function_calls&gt;\n&lt;invoke&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;parameters&gt;\n&lt;string&gt;encyclopediachatgpt&lt;/string&gt;\n&lt;/parameters&gt;\n&lt;/invoke&gt;\n&lt;/function_calls&gt;&lt;function_results&gt;\n&lt;result&gt;\n&lt;tool_name&gt;reverse_string&lt;/tool_name&gt;\n&lt;stdout&gt;\ntpgtahcaidepolcycne\n&lt;/stdout&gt;\n&lt;/result&gt;\n&lt;/function_results&gt;\n\n\"encyclopediachatgpt\" reversed is \"tpgtahcaidepolcycne\".\nprint(final_message)\n\n\n\n\"encyclopediachatgpt\" reversed is \"tpgtahcaidepolcycne\"."
  },
  {
    "objectID": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html#anthropic-tools-installation",
    "href": "posts/anthropic-claude3-function-calling-tools-python/function_calling_tools.html#anthropic-tools-installation",
    "title": "Anthropic Claude3: Function Calling Tools in Python",
    "section": "Anthropic Tools Installation",
    "text": "Anthropic Tools Installation\nFunction calling is a technique that allows you to extend the capabilities of a language model like Claude by integrating external functions or APIs. It enables the model to perform tasks or access information that it wouldn’t be able to do on its own.\nThe process involves defining a set of tools (functions) that Claude can use, and then providing a structured prompt format that guides Claude on how to use these tools. The prompt format includes a description of each tool, its parameters, and how to call it.\nWhen Claude receives a user’s message, it analyzes the message and determines if it needs to use any of the available tools to provide a response. If it does, it generates a special message (called a “tool_inputs” message) that specifies which tool it wants to use and what arguments it wants to pass to that tool.\nAt this point, there are two modes of operation: automatic and manual.\n\nAutomatic Mode (execution_mode=‘automatic’):\n\nIn automatic mode, the tool use process is handled automatically by the ToolUser class.\nWhen Claude generates a “tool_inputs” message, the ToolUser automatically extracts the specified tool and its arguments, calls the corresponding function, and generates a “tool_outputs” message with the result.\nThis process continues until Claude generates a response that doesn’t require any tool use (i.e., a regular “assistant” message).\nAutomatic mode is simpler to use but provides less control over the tool use process.\n\nManual Mode (execution_mode=‘manual’):\n\nIn manual mode, you have more control over the tool use process.\nWhen Claude generates a “tool_inputs” message, the ToolUser stops and returns this message to you.\nYou are then responsible for extracting the specified tool and its arguments, calling the corresponding function, and generating a “tool_outputs” message with the result.\nYou pass this “tool_outputs” message back to the ToolUser, which sends it to Claude.\nThis process continues, with you manually handling each “tool_inputs” message, until Claude generates a regular “assistant” message.\nManual mode requires more code to handle the back-and-forth between Claude and the tools, but it allows you to add your own validation logic, custom error handling, and more.\n\n\nRegardless of the mode, the key idea is that Claude can ask to use external tools when it needs them, and the ToolUser facilitates the communication between Claude and these tools.\nThis function calling technique allows you to leverage the language understanding and generation capabilities of Claude, while augmenting it with additional capabilities provided by external functions. It’s a powerful way to create more capable and versatile AI systems.\nSome common use cases for function calling include: - Performing complex calculations or data transformations - Retrieving real-time data from APIs - Accessing databases or knowledge bases - Executing actions in external systems\n\n!git clone https://github.com/anthropics/anthropic-tools.git\n!cd anthropic-tools && pip install -r requirements.txt\n!cd anthropic-tools && cp -r tool_use_package ../\n\nCloning into 'anthropic-tools'...\nremote: Enumerating objects: 478, done.\nremote: Counting objects: 100% (52/52), done.\nremote: Compressing objects: 100% (21/21), done.\nremote: Total 478 (delta 35), reused 31 (delta 31), pack-reused 426\nReceiving objects: 100% (478/478), 1.94 MiB | 5.31 MiB/s, done.\nResolving deltas: 100% (343/343), done.\nRequirement already satisfied: aiohttp==3.8.6 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (3.8.6)\nRequirement already satisfied: aiosignal==1.3.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: annotated-types==0.6.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.6.0)\nRequirement already satisfied: anthropic==0.16.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.16.0)\nRequirement already satisfied: anthropic-bedrock==0.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.8.0)\nRequirement already satisfied: anyio==3.7.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.7.1)\nRequirement already satisfied: async-timeout==4.0.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.0.3)\nRequirement already satisfied: attrs==23.1.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (23.1.0)\nRequirement already satisfied: beautifulsoup4==4.12.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.12.2)\nRequirement already satisfied: certifi==2023.7.22 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2023.7.22)\nRequirement already satisfied: charset-normalizer==3.3.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (3.3.0)\nRequirement already satisfied: dataclasses==0.6 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.6)\nRequirement already satisfied: distro==1.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.8.0)\nRequirement already satisfied: dnspython==2.4.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.4.2)\nRequirement already satisfied: elastic-transport==8.4.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (8.4.1)\nRequirement already satisfied: elasticsearch==8.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (8.10.1)\nRequirement already satisfied: exceptiongroup==1.1.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.1.3)\nRequirement already satisfied: filelock==3.12.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (3.12.4)\nRequirement already satisfied: frozenlist==1.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (1.4.0)\nRequirement already satisfied: fsspec==2023.9.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (2023.9.2)\nRequirement already satisfied: h11==0.14.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (0.14.0)\nRequirement already satisfied: httpcore==0.18.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (0.18.0)\nRequirement already satisfied: httpx==0.25.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.25.0)\nRequirement already satisfied: huggingface-hub==0.17.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (0.17.3)\nRequirement already satisfied: idna==3.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (3.4)\nRequirement already satisfied: install==1.3.5 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (1.3.5)\nRequirement already satisfied: loguru==0.7.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (0.7.2)\nRequirement already satisfied: more-itertools==10.1.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (10.1.0)\nRequirement already satisfied: multidict==6.0.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (6.0.4)\nRequirement already satisfied: numpy==1.26.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (1.26.1)\nRequirement already satisfied: packaging==23.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (23.2)\nRequirement already satisfied: pinecone-client==2.2.4 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (2.2.4)\nRequirement already satisfied: pydantic==2.4.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (2.4.2)\nRequirement already satisfied: pydantic_core==2.10.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (2.10.1)\nRequirement already satisfied: python-dateutil==2.8.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (2.8.2)\nRequirement already satisfied: PyYAML==6.0.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (6.0.1)\nRequirement already satisfied: requests==2.31.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (2.31.0)\nRequirement already satisfied: six==1.16.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (1.16.0)\nRequirement already satisfied: sniffio==1.3.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (1.3.0)\nRequirement already satisfied: soupsieve==2.5 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (2.5)\nRequirement already satisfied: tenacity==8.2.3 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (8.2.3)\nRequirement already satisfied: tokenizers==0.14.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (0.14.1)\nRequirement already satisfied: tqdm==4.66.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (4.66.1)\nRequirement already satisfied: typing_extensions==4.8.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (4.8.0)\nRequirement already satisfied: urllib3==1.26.18 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (1.26.18)\nRequirement already satisfied: wikipedia==1.4.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (1.4.0)\nRequirement already satisfied: yarl==1.9.2 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (1.9.2)\nRequirement already satisfied: boto3&gt;=1.28.57 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.28.58)\nRequirement already satisfied: botocore&gt;=1.31.57 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.31.58)\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from boto3&gt;=1.28.57-&gt;anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (1.0.1)\nRequirement already satisfied: s3transfer&lt;0.8.0,&gt;=0.7.0 in /Users/arunprakash/opt/anaconda3/envs/gpt/lib/python3.11/site-packages (from boto3&gt;=1.28.57-&gt;anthropic-bedrock==0.8.0-&gt;-r requirements.txt (line 5)) (0.7.0)"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-json-mode/messages_api_json.html",
    "href": "posts/anthropic-claude3-messages-api-json-mode/messages_api_json.html",
    "title": "Anthropic Claude3: Messages API with JSON Mode",
    "section": "",
    "text": "How to Use JSON Mode\n\nJSON (JavaScript Object Notation) is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate.\nWhen working with AI models like Claude, you may want to receive structured data in the form of JSON, rather than plain text. This allows for easier processing and extraction of information.\nAlthough Claude doesn’t have a built-in “JSON mode,” you can still get reliable JSON output by following a few techniques:\n\nUse string parsing to extract the JSON from Claude’s response by finding the text between “{” and “}” characters.\nProvide a partial response in the “assistant” role to remove any preamble text before the JSON. For example, send “Here is the JSON requested:\\n{” to start the JSON output immediately.\nIf the JSON output is followed by additional text, you can use a stop sequence to truncate the response after the JSON ends.\n\nFor more complex prompts that may include multiple JSON outputs, you can instruct Claude to wrap each JSON object in specific XML-like tags. This makes it easier to extract the JSON using regular expressions later.\nOnce you have extracted the JSON string from Claude’s response, you can use the json.loads() function in Python to parse it into a dictionary or list, depending on the structure of the JSON.\nBy following these techniques, you can effectively use Claude to generate structured JSON data, which can be easily integrated into your applications or workflows.\n\nRemember, while Claude is capable of generating JSON, it’s essential to provide clear instructions and examples to ensure you get the desired output format.\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nrecipe_text = \"\"\"\nBanana Bread Recipe\nIngredients:\n\n3 ripe bananas, mashed\n1/3 cup melted butter\n1/2 cup sugar\n1 egg, beaten\n1 teaspoon vanilla\n1 teaspoon baking soda\nPinch of salt\n1 1⁄2 cups all-purpose flour Instructions: Preheat oven to 350°F. Mix butter into the mashed bananas in a large mixing bowl. Mix in the sugar, egg, and vanilla. Sprinkle the baking soda and salt over the mixture and mix in. Add the flour last, mix just enough to blend the ingredients. Pour mixture into a buttered 4x8 inch loaf pan. Bake for 1 hour. Cool on a rack before removing from pan. Slice to serve. \"\"\"\n\n\nprompt = f\"\"\"\n\nRECIPE: {recipe_text}\n\nGive me a JSON dictionay of ingredients and quantities.\n\"\"\"\n\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": prompt\n        },\n        {\n            \"role\":\"assistant\",\n            \"content\": \"Here is the JSON requested:\\n{\"\n        }\n    ]\n).content[0].text\nprint(message)\n\n\n\n  \"ingredients\":[  \n    {\n      \"item\":\"ripe bananas\",\n      \"amount\":\"3\",\n      \"notes\":\"mashed\"\n    },\n    {\n      \"item\":\"butter\", \n      \"amount\":\"1/3 cup\",\n      \"notes\":\"melted\"\n    },\n    {\n      \"item\":\"sugar\",\n      \"amount\":\"1/2 cup\"\n    },\n    {\n      \"item\":\"egg\",\n      \"amount\":\"1\",\n      \"notes\":\"beaten\"  \n    },\n    {\n      \"item\":\"vanilla\",\n      \"amount\":\"1 teaspoon\"\n    },\n    {\n      \"item\":\"baking soda\",  \n      \"amount\":\"1 teaspoon\"\n    },\n    {\n      \"item\":\"salt\",\n      \"amount\":\"1 pinch\"\n    },\n    {\n      \"item\":\"all-purpose flour\",\n      \"amount\":\"1 1/2 cups\"  \n    }\n  ]\n\n}\n\n\n\nimport json\n\n\noutput_json = json.loads(\"{\" + message[:message.rfind(\"}\") + 1])\noutput_json\n\n{'ingredients': [{'item': 'ripe bananas', 'amount': '3', 'notes': 'mashed'},\n  {'item': 'butter', 'amount': '1/3 cup', 'notes': 'melted'},\n  {'item': 'sugar', 'amount': '1/2 cup'},\n  {'item': 'egg', 'amount': '1', 'notes': 'beaten'},\n  {'item': 'vanilla', 'amount': '1 teaspoon'},\n  {'item': 'baking soda', 'amount': '1 teaspoon'},\n  {'item': 'salt', 'amount': '1 pinch'},\n  {'item': 'all-purpose flour', 'amount': '1 1/2 cups'}]}\n\n\n\n\nGenerate Month names in English, Tamil, Spanish, and French\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"Generate month names in English, Tamil, Spanish, and French in JSON format. Language as keys, and list of month names as values.\"\n        },\n        {\n            \"role\":\"assistant\",\n            \"content\": \"Here is the JSON requested:\\n{\"\n        }\n    ]\n).content[0].text\nprint(message)\n\n\n  \"English\":\n  [\n    \"January\",\n    \"February\", \n    \"March\",\n    \"April\",\n    \"May\",\n    \"June\",\n    \"July\",\n    \"August\",\n    \"September\",\n    \"October\",\n    \"November\",\n    \"December\"\n  ],\n  \"Tamil\":\n  [\n    \"ஜனவரி\",\n    \"பிப்ரவரி\",\n    \"மார்ச்\",\n    \"ஏப்ரல்\",\n    \"மே\",\n    \"ஜூன்\",\n    \"ஜூலை\",\n    \"ஆகஸ்ட்\",\n    \"செப்டம்பர்\",\n    \"அக்டோபர்\",\n    \"நவம்பர்\",\n    \"டிசம்பர்\"\n  ],\n  \"Spanish\":\n  [\n    \"enero\",\n    \"febrero\",\n    \"marzo\",\n    \"abril\",\n    \"mayo\",\n    \"junio\",\n    \"julio\",\n    \"agosto\",\n    \"septiembre\",\n    \"octubre\",\n    \"noviembre\",\n    \"diciembre\"\n  ],\n  \"French\":\n  [\n    \"janvier\",\n    \"février\",\n    \"mars\",\n    \"avril\",\n    \"mai\",\n    \"juin\",\n    \"juillet\",\n    \"août\",\n    \"septembre\",\n    \"octobre\",\n    \"novembre\",\n    \"décembre\"\n  ]\n}\n\n\n\noutput_json = json.loads(\"{\" + message[:message.rfind(\"}\") + 1])\noutput_json\n\n{'English': ['January',\n  'February',\n  'March',\n  'April',\n  'May',\n  'June',\n  'July',\n  'August',\n  'September',\n  'October',\n  'November',\n  'December'],\n 'Tamil': ['ஜனவரி',\n  'பிப்ரவரி',\n  'மார்ச்',\n  'ஏப்ரல்',\n  'மே',\n  'ஜூன்',\n  'ஜூலை',\n  'ஆகஸ்ட்',\n  'செப்டம்பர்',\n  'அக்டோபர்',\n  'நவம்பர்',\n  'டிசம்பர்'],\n 'Spanish': ['enero',\n  'febrero',\n  'marzo',\n  'abril',\n  'mayo',\n  'junio',\n  'julio',\n  'agosto',\n  'septiembre',\n  'octubre',\n  'noviembre',\n  'diciembre'],\n 'French': ['janvier',\n  'février',\n  'mars',\n  'avril',\n  'mai',\n  'juin',\n  'juillet',\n  'août',\n  'septembre',\n  'octobre',\n  'novembre',\n  'décembre']}\n\n\n\noutput_json[\"English\"]\n\n['January',\n 'February',\n 'March',\n 'April',\n 'May',\n 'June',\n 'July',\n 'August',\n 'September',\n 'October',\n 'November',\n 'December']\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-streaming-python/messages_api_streaming.html",
    "href": "posts/anthropic-claude3-messages-api-streaming-python/messages_api_streaming.html",
    "title": "Anthropic Claude3: Messages API with Streaming",
    "section": "",
    "text": "# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    api_key=api_key,\n)\n\n\nWithout Streaming\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"You are an expert travel guide\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ]\n)\n\nprint(message.content)\n\n[ContentBlock(text=\"Here are some of the top places to visit in Sydney, Australia:\\n\\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\\n\\n2. Sydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\\n\\n3. Bondi Beach - One of Australia's most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\\n\\n4. The Rocks - A historic neighborhood with cobblestone streets, colonial buildings, museums, and markets.\\n\\n5. Darling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\\n\\n6. Royal Botanic Garden Sydney - A beautiful park featuring diverse plant collections, harbor views, and a colony of flying foxes.\\n\\n7. Taronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\\n\\n8. Manly Beach - Take a ferry from Circular Quay to Manly to enjoy the beach, walk along the Manly Corso, and visit the Manly SEA LIFE Sanctuary.\\n\\n9. Queen Victoria Building (QVB) - A historic shopping center with intricate Romanesque architecture and high-end boutiques.\\n\\n10. Blue Mountains National Park - Located about 1.5 hours from Sydney, this stunning park offers hiking trails, waterfalls, and the famous Three Sisters rock formation.\", type='text')]\n\n\n\nfrom IPython.display import display, HTML, Markdown\n\n\ndisplay(Markdown(message.content[0].text))\n\nHere are some of the top places to visit in Sydney, Australia:\n\nSydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\nSydney Harbour Bridge - Take a walk across the bridge or participate in a guided climb for stunning views of the city and harbor.\nBondi Beach - One of Australia’s most famous beaches, known for its golden sand, surfing, and vibrant beach culture.\nThe Rocks - A historic neighborhood with cobblestone streets, colonial buildings, museums, and markets.\nDarling Harbour - A waterfront precinct with restaurants, shops, and attractions like the SEA LIFE Sydney Aquarium and the Australian National Maritime Museum.\nRoyal Botanic Garden Sydney - A beautiful park featuring diverse plant collections, harbor views, and a colony of flying foxes.\nTaronga Zoo - Located on the shores of Sydney Harbour, this zoo is home to a wide variety of native Australian and exotic animals.\nManly Beach - Take a ferry from Circular Quay to Manly to enjoy the beach, walk along the Manly Corso, and visit the Manly SEA LIFE Sanctuary.\nQueen Victoria Building (QVB) - A historic shopping center with intricate Romanesque architecture and high-end boutiques.\nBlue Mountains National Park - Located about 1.5 hours from Sydney, this stunning park offers hiking trails, waterfalls, and the famous Three Sisters rock formation.\n\n\n\nIt took ~22 seconds to process the output\n\n\nWith Streaming\n\nwith client.messages.stream(\n    max_tokens=1024,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Top places to visit in Sydney\"}\n    ],\n    model=\"claude-3-opus-20240229\",\n) as stream:\n  for text in stream.text_stream:\n      print(text, end=\"\", flush=True)\n\nHere are some of the top places to visit in Sydney, Australia:\n\n1. Sydney Opera House - This iconic building is a UNESCO World Heritage site and a must-see attraction.\n\n2. Sydney Harbour Bridge - Climb the bridge for stunning views of the city or walk across it for free.\n\n3. Bondi Beach - One of Australia's most famous beaches, known for its surf, sand, and cafes.\n\n4. The Rocks - A historic neighborhood with cobblestone streets, markets, and museums.\n\n5. Royal Botanic Garden Sydney - A beautiful park with stunning views of the harbor and city skyline.\n\n6. Taronga Zoo - A world-class zoo with a wide variety of animals and stunning views of the city.\n\n7. Darling Harbour - A waterfront precinct with restaurants, bars, and entertainment venues.\n\n8. Sydney Tower Eye - The tallest structure in Sydney, offering panoramic views of the city.\n\n9. Manly Beach - A popular beach town that can be reached by ferry from Circular Quay.\n\n10. Blue Mountains National Park - A stunning national park with hiking trails, waterfalls, and scenic lookouts, located just outside the city.\n\nThese are just a few of the many attractions Sydney has to offer. The city is also known for its diverse food scene, vibrant nightlife, and cultural events throughout the year.\n\n\n\ntype(stream)\n\nanthropic.lib.streaming._messages.MessageStream\n\n\n\n[f for f in dir(stream) if not f.startswith(\"_\")]\n\n['close',\n 'current_message_snapshot',\n 'get_final_message',\n 'get_final_text',\n 'on_content_block',\n 'on_end',\n 'on_exception',\n 'on_message',\n 'on_stream_event',\n 'on_text',\n 'on_timeout',\n 'response',\n 'text_stream',\n 'until_done']\n\n\nWhen you receive data from a server using Server-Sent Events (SSE), the server sends events to your application. Each event has a specific name and some associated data in JSON format. The event name tells you what kind of event it is, and the JSON data provides more details about that event.\nHere’s a step-by-step explanation of how the events flow:\n\nFirst, you’ll receive a message_start event. This event includes a Message object, but the content of the message will be empty at this point. It’s like a placeholder for the message that will be filled in later.\nNext, you’ll receive a series of content blocks. Each content block represents a part of the message’s content. The content blocks come in three stages:\n\ncontent_block_start: This event indicates the start of a new content block.\ncontent_block_delta: You might receive one or more of these events. They contain the actual content of the block.\ncontent_block_stop: This event marks the end of the content block.\n\nEach content block has an index number that tells you its position in the final Message object’s content array.\nAfter receiving all the content blocks, you’ll receive one or more message_delta events. These events indicate changes or updates to the overall Message object.\nFinally, you’ll receive a message_stop event. This event signifies that the server has finished sending the complete message.\n\nSo, in summary, the server sends events to your application, piece by piece, to gradually build up the complete message. It starts with a message_start event, followed by content blocks, message_delta events for updates, and ends with a message_stop event.\nBy following this event flow, your application can receive and process the message data from the server in a structured way, even if the message is sent in multiple parts.\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "",
    "text": "Voyage Vista\nWelcome to our tutorial on “Building a Personalised Travel Planner using OpenAI Assistants APIs”. In this blog post, we will guide you through the process of creating “Voyage Vista”, a travel planning tool that uses OpenAI Assistants APIs to bring your dream vacation to life."
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#voyage-vista-your-personal-travel-planner",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#voyage-vista-your-personal-travel-planner",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "Voyage Vista: Your Personal Travel Planner",
    "text": "Voyage Vista: Your Personal Travel Planner\nVoyage Vista is designed to make travel planning an immersive and enjoyable experience. It provides real-time weather updates, lists top tourist attractions, and offers customized travel guides, all with the aim of helping you create unforgettable memories.\n\nKey Features\n\nInteractive Map: Voyage Vista’s map provides real-time weather updates with intuitive color-coded indicators, making it easy to plan your day.\nCustomized Itineraries: Voyage Vista generates a detailed Word document that serves as your travel guide, filled with historical and cultural insights about your destination.\nReal-Time Weather Forecasts: Weather forecasts are displayed on an interactive map, helping you plan your day perfectly.\nTop Tourist Attractions: Voyage Vista ensures you don’t miss out on any highlights by listing the must-see spots of your chosen destination."
  },
  {
    "objectID": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#leveraging-openai-assistants-apis",
    "href": "posts/building_a_personalised_travel_planner_using_openai_assistants_api/tourist_assistant_tools.html#leveraging-openai-assistants-apis",
    "title": "Transform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API",
    "section": "Leveraging OpenAI Assistants APIs",
    "text": "Leveraging OpenAI Assistants APIs\nIn the development of Voyage Vista, we will be using several features of the OpenAI Assistants APIs:\n\nParallel Function Calling: This feature allows us to execute multiple functions simultaneously, improving the efficiency of our application.\nCode Interpreter: The Code Interpreter feature will be instrumental in processing and interpreting the data and generate word documents and other processing data.\nThreads: Threads allow us to manage multiple conversations or tasks concurrently, which is useful for handling multiple user requests at the same time.\nMessages: The Messages feature will be used to communicate with users, providing them with real-time updates and responses to their queries.\n\nBy leveraging these features, we aim to create a dynamic, efficient, and user-friendly travel planning tool. In the following sections of this tutorial, we will delve deeper into each of these features and show you how to use them to build your own version of Voyage Vista\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\nimport time\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\n\n\nprint(openai.__version__)\n\n1.7.0\n\n\n\nimport plotly.graph_objects as go\nimport requests\n\ndef get_coordinates(place_name, city_name):\n    \"\"\"Fetches coordinates of a place using Nominatim API.\"\"\"\n    url = f\"https://nominatim.openstreetmap.org/search?format=json&q={place_name}, {city_name}\"\n    response = requests.get(url)\n    data = response.json()\n    if data:\n        return float(data[0]['lat']), float(data[0]['lon'])\n    else:\n        return None, None\n\nThis function takes a place name and city name and retrieve coordinates using nominatim API. It returns a tuple of latitude and longitude.\n\ndef create_city_map(city_name, attractions, is_rainy):\n    if not attractions:\n        print(f\"No attractions found for {city_name}\")\n        return None\n\n    # Prepare lists for latitudes and longitudes\n    lats, lons = [], []\n\n    # Add markers for each attraction\n    markers = []\n    for index, place in enumerate(attractions):\n        lat, lon = get_coordinates(place, city_name)\n        if lat and lon:\n            lats.append(lat)\n            lons.append(lon)\n            marker_color = 'red' if is_rainy[index].lower() == 'yes' else 'blue'\n            markers.append(go.Scattermapbox(\n                lon = [lon],\n                lat = [lat],\n                mode = 'markers+text',  # Combine markers and text\n                marker = go.scattermapbox.Marker(size=14, color=marker_color),\n                text = [f\"{index + 1}. {place}\"],\n                textposition = \"top right\",  # Position of the text,\n                name=place\n            ))\n\n    # Create a Plotly map\n    city_map = go.Figure(markers)\n\n    # Automatically adjust the zoom to fit all markers\n    city_map.update_layout(\n        mapbox_style=\"open-street-map\",\n        mapbox = {\n            'center': go.layout.mapbox.Center(lat=sum(lats) / len(lats), lon=sum(lons) / len(lons)),\n            'zoom': 10  # Adjust this value for best fit\n        },\n        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n    )\n\n    city_map.show()\n\n    # save the map to png file\n    city_map.write_image(f'{city_name}.png')\n\n    return {'png': f'{city_name}.png'}\n\n# Dummy data\ncity_name = 'London'\nattractions = ['London Eye', 'Buckingham Palace', 'British Museum']\nis_rainy = ['Yes', 'No', 'No']\n\ncreate_city_map(city_name, attractions, is_rainy)\n\n\n                                                \n\n\n{'png': 'London.png'}\n\n\ncreate_city_map function is helpfule to plot the map of tourist attractions, it also takes weather information such as is_raining and color code the map accordingly.\n\n# !pip install -U kaleido\n\n\napi_key = os.getenv(\"OPENWEATHER_API_KEY\")\n\n\nimport requests\nimport json\nimport os\nfrom datetime import datetime\n\n\ndef get_weather(location, date, unit=\"metric\", use_coordinates=False):\n    \"\"\"Get weather for a given location and date using OpenWeather API.\"\"\"\n    current_date = datetime.now().date()\n    requested_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n\n    if requested_date == current_date:\n        endpoint = \"weather\"  # Current weather\n    elif requested_date &lt; current_date:\n        endpoint = (\n            \"timemachine\"  # Historical weather (requires different API subscription)\n        )\n    else:\n        endpoint = \"forecast\"  # Future weather (limited to 5-16 days based on API plan)\n\n    base_url = f\"http://api.openweathermap.org/data/2.5/{endpoint}\"\n\n    if use_coordinates:\n        params = {\n            \"lat\": location[0],\n            \"lon\": location[1],\n            \"appid\": api_key,\n            \"units\": unit,\n        }\n    else:\n        params = {\"q\": location, \"appid\": api_key, \"units\": unit}\n\n    if endpoint == \"timemachine\":\n        params[\"dt\"] = int(requested_date.timestamp())\n\n    try:\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        data = response.json()\n\n        weather = {\n            \"location\": location,\n            \"date\": date,\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\",\n            \"temperature\": data[\"list\"][0][\"main\"][\"temp\"],\n            \"humidity\": data[\"list\"][0][\"main\"][\"humidity\"],\n            \"wind_speed\": data[\"list\"][0][\"wind\"][\"speed\"],\n            \"description\": data[\"list\"][0][\"weather\"][0][\"description\"],\n        }\n        # weather.update(data[\"list\"][0])\n        return json.dumps(weather, indent=4)\n    except KeyError as err:\n        # for current date\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        data = response.json()\n        weather = {\n            \"location\": location,\n            \"date\": date,\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\",\n            \"temperature\": data[\"main\"][\"temp\"],\n            \"humidity\": data[\"main\"][\"humidity\"],\n            \"wind_speed\": data[\"wind\"][\"speed\"],\n            \"description\": data[\"weather\"][0][\"description\"],\n        }\n        return json.dumps(weather, indent=4)\n    except requests.exceptions.HTTPError as err:\n        return json.dumps({\"error\": f\"HTTP Error: {err}\"})\n    except requests.exceptions.RequestException as e:\n        return json.dumps({\"error\": f\"Request Error: {e}\"})\n\n\nweather_info = get_weather(\"Kyoto\", \"2024-01-11\")\nprint(weather_info)\n\n{\n    \"location\": \"Kyoto\",\n    \"date\": \"2024-01-11\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 6.17,\n    \"humidity\": 78,\n    \"wind_speed\": 2.36,\n    \"description\": \"overcast clouds\"\n}\n\n\nThe get_weather function for fetching weather information for a specific location and date using the OpenWeather API. It handles current, historical, and future weather data. The script is designed to process requests for specific dates and locations, returning a JSON formatted output with details like temperature, humidity, wind speed, and a weather description.\n\n# find location and weather details\n\nplace_name = \"Fushimi Inari-taisha Shrine, Kyoto\"\nlat, lon = get_coordinates(place_name, \"Kyoto\")\nprint(f\"Coordinates of {place_name}: {lat}, {lon}\")\n\nweather_info = get_weather((lat, lon), use_coordinates=True, date=\"2024-01-11\")\nprint(weather_info)\n\nCoordinates of Fushimi Inari-taisha Shrine, Kyoto: 34.9672545, 135.7737731\n{\n    \"location\": [\n        34.9672545,\n        135.7737731\n    ],\n    \"date\": \"2024-01-11\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 6.24,\n    \"humidity\": 77,\n    \"wind_speed\": 2.06,\n    \"description\": \"overcast clouds\"\n}\n\n\n\nweather_info = get_weather((lat, lon), use_coordinates=True, date=\"2024-01-10\")\nprint(weather_info)\n\n{\n    \"location\": [\n        34.9672545,\n        135.7737731\n    ],\n    \"date\": \"2024-01-10\",\n    \"unit\": \"Celsius\",\n    \"temperature\": 7.22,\n    \"humidity\": 78,\n    \"wind_speed\": 0.45,\n    \"description\": \"overcast clouds\"\n}\n\n\n\ncity_name = \"Kyoto\""
  },
  {
    "objectID": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "href": "posts/master-the-art-of-function-calling-in-openai-assistants-api-a-comprehensive-guide-for-beginners/assistants_function_calling.html",
    "title": "Master the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners",
    "section": "",
    "text": "# !pip3 install openai -U\n\nWelcome to our comprehensive guide on leveraging function calling in the OpenAI Assistant API. Whether you’re a seasoned developer or a curious beginner, this tutorial is designed to help you understand and implement this powerful feature in your AI projects.\nHere’s what we’ll be diving into:\n\nThe basics of function calling in the OpenAI Assistant API\nSteps to create an assistant\nCrafting a message and initiating a thread\nIdentifying when a message requires a function call\nDetermining which function to call and what arguments to pass\nRetrieving the response from a function call\nUnderstanding the final response\n\nOpenAI Assistants are equipped with a variety of tools, including retrieval, code interpretation, and function calling. In this guide, we’ll be focusing primarily on the function calling capabilities.\nTo illustrate these concepts, we’ll walk you through a simple demo. We’ll start by demonstrating a common challenge - reversing a string - and then show you how to overcome this challenge by creating a function that reverses the string and integrating it with the assistant.\nOur goal is to provide you with a clear, practical understanding of function calling in the OpenAI Assistant API, empowering you to create more dynamic and interactive AI applications. Let’s get started!\nIn general, assistants can use tools such as retrrieval, code interpreter, and function calling.\nIn this tutorial we focus more on function calling capabilities of assistants.\nWe create a simple demo that shows the failure of reversing a string and then we create a function that reverses the string and connect it with the assistant.\n\n# dictionary print indentatio\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\n\n# openai version\nopenai.__version__\n\n'1.6.1'\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nTo reverse the string “openaichatgpt”, you would simply reverse the order of the characters to get “tpgtahciapeneo”.\n\n\n\n\"tpgtahciapeneo\" == \"openaichatgpt\"[::-1]\n\nFalse\n\n\nLarge Language Models use tokens to split text into smaller pieces, and reversing a string is not a usual data that is has seen during training, so it is not able to predict it correctly.\nWe can fix this by creating a function that will reverse the string, and use the model to ask us to call the function and get results and pass it to the model.\n\ndef reverse_string(string):\n    return string[::-1]\n\n\nCreating an Assistant\n\n# function_json for reverse_string\nfunction_json = {'type':'function',\n            'function':{\n                'name': 'reverse_string',\n                'parameters':{\n                    \"type\":\"object\",\n                      \"properties\":{\n                          \"string\": {'type':'string','description':\"A single word\"},\n                      },\n                    'required' : [\"string\"]\n                }\n\n    }\n}\n\n\navailable_functions = {\n    \"reverse_string\": reverse_string\n}\n\n\nfrom openai import OpenAI\nclient = OpenAI()\n\n\nassistant = client.beta.assistants.create(\n    name=\"Python Tutor\",\n    instructions=\"You are a personal python tutor.\",\n    tools=[function_json],\n    model=\"gpt-4-1106-preview\"\n)\n\n\nassistant\n\nAssistant(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', created_at=1704457106, description=None, file_ids=[], instructions='You are a personal python tutor.', metadata={}, model='gpt-4-1106-preview', name='Python Tutor', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nprint(json.dumps(assistant.model_dump(), indent=4))\n\n{\n    \"id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"created_at\": 1704457106,\n    \"description\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"name\": \"Python Tutor\",\n    \"object\": \"assistant\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\ntype(assistant)\n\nopenai.types.beta.assistant.Assistant\n\n\n\n\nThread\n\nthread = client.beta.threads.create()\n\n\nthread.model_dump()\n\n{'id': 'thread_3fT59LTUrodHJPjBQYsIYm6F',\n 'created_at': 1704457106,\n 'metadata': {},\n 'object': 'thread'}\n\n\n\nthread\n\nThread(id='thread_3fT59LTUrodHJPjBQYsIYm6F', created_at=1704457106, metadata={}, object='thread')\n\n\n\n\nAdd a Message to a Thread\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what are different loops in python?\"\n)\n\n\nmessage\n\nThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')\n\n\n\nmessage.model_dump()\n\n{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'assistant_id': None,\n 'content': [{'text': {'annotations': [],\n    'value': 'what are different loops in python?'},\n   'type': 'text'}],\n 'created_at': 1704457107,\n 'file_ids': [],\n 'metadata': {},\n 'object': 'thread.message',\n 'role': 'user',\n 'run_id': None,\n 'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}\n\n\n\nthread_messages = client.beta.threads.messages.list(thread_id=thread.id)\nthread_messages.data\n\n[ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')]\n\n\n\nthread_messages.model_dump()\n\n{'data': [{'id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n   'assistant_id': None,\n   'content': [{'text': {'annotations': [],\n      'value': 'what are different loops in python?'},\n     'type': 'text'}],\n   'created_at': 1704457107,\n   'file_ids': [],\n   'metadata': {},\n   'object': 'thread.message',\n   'role': 'user',\n   'run_id': None,\n   'thread_id': 'thread_3fT59LTUrodHJPjBQYsIYm6F'}],\n 'object': 'list',\n 'first_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'last_id': 'msg_UDx8nMLlKxvriXAEBeW0AJ9f',\n 'has_more': False}\n\n\n\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": null,\n    \"status\": \"queued\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=thread.id,\n  run_id=run.id\n)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457108,\n    \"expires_at\": 1704457708,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": 1704457108,\n    \"status\": \"in_progress\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=None, created_at=1704457108, expires_at=1704457708, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='in_progress', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nrun.status\n\n'in_progress'\n\n\n\nimport time\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n    \n\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\nin_progress\ncompleted\n\n\n\nrun\n\nRun(id='run_BLZnD60Vl7wePLUsdmUFR5zd', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', cancelled_at=None, completed_at=1704457140, created_at=1704457108, expires_at=None, failed_at=None, file_ids=[], instructions='You are a personal python tutor.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704457108, status='completed', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F', tools=[ToolAssistantToolsFunction(function=FunctionDefinition(name='reverse_string', description=None, parameters={'type': 'object', 'properties': {'string': {'type': 'string', 'description': 'A single word'}}, 'required': ['string']}), type='function')])\n\n\n\nmessages = client.beta.threads.messages.list(\n  thread_id=thread.id\n)\n\nmessages\n\nSyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_a5FW3oicgn271ztQwcIa6kQ6', assistant_id='asst_UQEBrB5fuKnzx472Sf5qWYdH', content=[MessageContentText(text=Text(annotations=[], value='In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\"apple\", \"banana\", \"cherry\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here\\'s an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere\\'s an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\"Found an even number\", num)\\n        continue\\n    print(\"Found a number\", num)\\nelse:\\n    print(\"The loop is completed without a break statement.\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it\\'s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.'), type='text')], created_at=1704457109, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BLZnD60Vl7wePLUsdmUFR5zd', thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F'), ThreadMessage(id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what are different loops in python?'), type='text')], created_at=1704457107, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_3fT59LTUrodHJPjBQYsIYm6F')], object='list', first_id='msg_a5FW3oicgn271ztQwcIa6kQ6', last_id='msg_UDx8nMLlKxvriXAEBeW0AJ9f', has_more=False)\n\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\n\n# new message\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"what's the reverse of the string openaichatgpt?\"\n)\n\n\n# new run\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n# wait for run to complete\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\nin_progress\nrequires_action\n\n\n\nrun.status\n\n'requires_action'\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\nrun.required_action\n\nRequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')]), type='submit_tool_outputs')\n\n\n\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    print(\"Tool call: \", tool_call)\n    function_name = tool_call.function.name\n    print(\"Function name: \", function_name)\n    arguments = json.loads(tool_call.function.arguments)\n    print(\"Function arguments: \", arguments)\n\nTool call:  RequiredActionFunctionToolCall(id='call_aQzOoDu3V00J5lkG6zVNtdqc', function=Function(arguments='{\"string\":\"openaichatgpt\"}', name='reverse_string'), type='function')\nFunction name:  reverse_string\nFunction arguments:  {'string': 'openaichatgpt'}\n\n\n\n# call the function\nif run.status == \"requires_action\":\n    tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n    function_name = tool_call.function.name\n    arguments = json.loads(tool_call.function.arguments)\n    function = available_functions[function_name]\n    output = function(**arguments)\n    print(\"Function output: \", output)\n\nFunction output:  tpgtahcianepo\n\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n    \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1704457145,\n    \"expires_at\": 1704457745,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a personal python tutor.\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": {\n        \"submit_tool_outputs\": {\n            \"tool_calls\": [\n                {\n                    \"id\": \"call_aQzOoDu3V00J5lkG6zVNtdqc\",\n                    \"function\": {\n                        \"arguments\": \"{\\\"string\\\":\\\"openaichatgpt\\\"}\",\n                        \"name\": \"reverse_string\"\n                    },\n                    \"type\": \"function\"\n                }\n            ]\n        },\n        \"type\": \"submit_tool_outputs\"\n    },\n    \"started_at\": 1704457145,\n    \"status\": \"requires_action\",\n    \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\",\n    \"tools\": [\n        {\n            \"function\": {\n                \"name\": \"reverse_string\",\n                \"description\": null,\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"string\": {\n                            \"type\": \"string\",\n                            \"description\": \"A single word\"\n                        }\n                    },\n                    \"required\": [\n                        \"string\"\n                    ]\n                }\n            },\n            \"type\": \"function\"\n        }\n    ]\n}\n\n\n\n\nLet the Model Know about the function outputs\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n    thread_id=thread.id,\n    run_id=run.id,\n    tool_outputs=[{\"tool_call_id\": tool_call.id, \"output\": json.dumps(output)}],\n)\n\n\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\ncompleted\n\n\n\n\nRetrieve the message from history and display the output\n\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n    )\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"The reverse of the string \\\"openaichatgpt\\\" is \\\"tpgtahcianepo\\\".\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457154,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_dmH9mQUYjLLQJEYuXZQZJOHH\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_QPbWzZkoRFveMIRPWtvREz0s\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what's the reverse of the string openaichatgpt?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457145,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_a5FW3oicgn271ztQwcIa6kQ6\",\n            \"assistant_id\": \"asst_UQEBrB5fuKnzx472Sf5qWYdH\",\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"In Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\\n\\n1. `for` Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a `for` loop:\\n\\n```python\\nfor item in [\\\"apple\\\", \\\"banana\\\", \\\"cherry\\\"]:\\n    print(item)\\n```\\n\\n2. `while` Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here's an example of a `while` loop:\\n\\n```python\\ncount = 0\\nwhile count &lt; 5:\\n    print(count)\\n    count += 1\\n```\\n\\nPython also provides some loop control statements that can be used within these loops:\\n\\n- `break`: Terminates the loop and transfers execution to the statement immediately following the loop.\\n- `continue`: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\\n- `else`: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a `break` statement).\\n\\nHere's an example of using `break`, `continue`, and `else` with a `for` loop:\\n\\n```python\\nfor num in range(2, 10):\\n    if num % 2 == 0:\\n        print(\\\"Found an even number\\\", num)\\n        continue\\n    print(\\\"Found a number\\\", num)\\nelse:\\n    print(\\\"The loop is completed without a break statement.\\\")\\n```\\n\\nAnd an example using `while` loop:\\n\\n```python\\ncount = 1\\nwhile count &lt; 10:\\n    if count == 5:\\n        break\\n    print(count)\\n    count += 1\\nelse:\\n    print(\\\"Reached the value of 5 and stopped the loop with a break statement.\\\")\\n```\\n\\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it's important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457109,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"assistant\",\n            \"run_id\": \"run_BLZnD60Vl7wePLUsdmUFR5zd\",\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        },\n        {\n            \"id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"what are different loops in python?\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1704457107,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_3fT59LTUrodHJPjBQYsIYm6F\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_vp29v6UA7Amr7isw4LdGNhcW\",\n    \"last_id\": \"msg_UDx8nMLlKxvriXAEBeW0AJ9f\",\n    \"has_more\": false\n}\n\n\n\nfor message in messages.data:\n    display(Markdown(message.content[0].text.value))\n    print(\"*\" * 80)\n\nThe reverse of the string “openaichatgpt” is “tpgtahcianepo”.\n\n\n********************************************************************************\n********************************************************************************\n********************************************************************************\n********************************************************************************\n\n\nwhat’s the reverse of the string openaichatgpt?\n\n\nIn Python, there are two primary types of loops that allow you to execute a block of code repeatedly:\n\nfor Loop: This loop is used for iterating over a sequence (which could be a list, tuple, dictionary, set, or string) with the ability to execute a block of code for each item in the sequence. An example of a for loop:\n\nfor item in [\"apple\", \"banana\", \"cherry\"]:\n    print(item)\n\nwhile Loop: This loop repeatedly executes the target statement(s) as long as the given condition is true. The condition is evaluated before executing the body of the loop. Here’s an example of a while loop:\n\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\nPython also provides some loop control statements that can be used within these loops:\n\nbreak: Terminates the loop and transfers execution to the statement immediately following the loop.\ncontinue: Skips the remaining part of the loop for the current iteration and moves to the next iteration.\nelse: An optional clause associated with loops that is executed if the loop completes normally (i.e., not terminated by a break statement).\n\nHere’s an example of using break, continue, and else with a for loop:\nfor num in range(2, 10):\n    if num % 2 == 0:\n        print(\"Found an even number\", num)\n        continue\n    print(\"Found a number\", num)\nelse:\n    print(\"The loop is completed without a break statement.\")\nAnd an example using while loop:\ncount = 1\nwhile count &lt; 10:\n    if count == 5:\n        break\n    print(count)\n    count += 1\nelse:\n    print(\"Reached the value of 5 and stopped the loop with a break statement.\")\nAdditionally, Python allows the use of nested loops (a loop inside another loop), which can be useful for more complex iteration scenarios. However, it’s important to use them judiciously as they can lead to high computational complexity, especially with large datasets.\n\n\nwhat are different loops in python?\n\n\n\n\nDelete the Assistant\n\nresponse = client.beta.assistants.delete(assistant_id=assistant.id)\nprint(response)\n\nAssistantDeleted(id='asst_UQEBrB5fuKnzx472Sf5qWYdH', deleted=True, object='assistant.deleted')\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/chatcompletions-vs-assistants-ai-openai/assistants_chatcomplettion.html",
    "href": "posts/chatcompletions-vs-assistants-ai-openai/assistants_chatcomplettion.html",
    "title": "OpenAI ChatCompletions vs OpenAI Assistants API: A Hands-on Comparison",
    "section": "",
    "text": "import json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\n\nAPI Keys: https://platform.openai.com/api-keys\n\n\nChat Completions API\n\nTakes a user’s message and a model as inputs\nGenerates responses to user inputs\nMessages serve as the fundamental component in Chat Completions API operations\n\n\n\nChat Completion Models: Drawbacks\n\nNo message history tracking\nLack of support for file inputs (e.g., PDFs, CSVs)\nChallenges with computational tasks\nNo management of context windows\nOperate synchronously\n\n\n\nAssistants API\n\nManages conversation Threads for Context Maintenance\nTools: Code Interpreter, Retrieval, Function calling\nSupports file handling\nAsynchronous support\nCan generate graphs, charts, and process various file types\n\n\n# !pip3 install openai --upgrade\n\n\n# openai version\nopenai.__version__\n\n'1.8.0'\n\n\n\n\n1. No Message Histories in ChatCompletions\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the capital of Japan\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nThe capital of Japan is Tokyo.\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Tell me something about that city\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nI’m sorry, but you didn’t specify which city you’re referring to. Could you please provide the name of the city you’re interested in learning about?\n\n\n\n\nNo Code Interpreter - Computational Tasks\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nTo reverse the string “openaichatgpt”, you would simply reverse the order of the characters to get “tpgtaahcianepo”.\n\n\n\n\"tpgtahciapeneo\" == \"openaichatgpt\"[::-1]\n\nFalse\n\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"what's todays date?\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nAs an AI, I don’t have real-time capabilities, so I can’t provide the current date. However, you can easily check the date on your computer, smartphone, or any other device with a calendar function.\n\n\n\n\nContext Window Handling\n\n\nSynchronous\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"reverse the string openaichatgpt\"},\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\n\nAssistants API\n\nassistant = client.beta.assistants.create(\n    name=\"Python Tutor\",\n    instructions=\"You are a python tutor teaching someone who has experience in Java\",\n    tools=[{\"type\":\"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\"\n)\n\n\nassistant\n\nAssistant(id='asst_4bTZR8hx96VEvyFca4hnmoe1', created_at=1705686038, description=None, file_ids=[], instructions='You are a python tutor teaching someone who has experience in Java', metadata={}, model='gpt-4-1106-preview', name='Python Tutor', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])\n\n\n\nthread = client.beta.threads.create()\nthread\n\nThread(id='thread_z12e0BsDI8SfaePTmRMsApXo', created_at=1705686038, metadata={}, object='thread')\n\n\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"reverse the string openaichatgpt\"\n)\n\n\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=assistant.id)\n\n\nprint(json.dumps(run.model_dump(), indent=4))\n\n{\n    \"id\": \"run_npuaz95TU2HdDGu3cgRhkOsW\",\n    \"assistant_id\": \"asst_4bTZR8hx96VEvyFca4hnmoe1\",\n    \"cancelled_at\": null,\n    \"completed_at\": null,\n    \"created_at\": 1705686039,\n    \"expires_at\": 1705686639,\n    \"failed_at\": null,\n    \"file_ids\": [],\n    \"instructions\": \"You are a python tutor teaching someone who has experience in Java\",\n    \"last_error\": null,\n    \"metadata\": {},\n    \"model\": \"gpt-4-1106-preview\",\n    \"object\": \"thread.run\",\n    \"required_action\": null,\n    \"started_at\": null,\n    \"status\": \"queued\",\n    \"thread_id\": \"thread_z12e0BsDI8SfaePTmRMsApXo\",\n    \"tools\": [\n        {\n            \"type\": \"code_interpreter\"\n        }\n    ]\n}\n\n\n\nrun = client.beta.threads.runs.retrieve(\n  thread_id=thread.id,\n  run_id=run.id\n)\n\n\nrun.status\n\n'in_progress'\n\n\n\nmessages = client.beta.threads.messages.list(\n  thread_id=thread.id\n)\n\nmessages\n\nSyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_j9CJRJRiYrsfl7pk6a07u72c', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='reverse the string openaichatgpt'), type='text')], created_at=1705686038, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_z12e0BsDI8SfaePTmRMsApXo')], object='list', first_id='msg_j9CJRJRiYrsfl7pk6a07u72c', last_id='msg_j9CJRJRiYrsfl7pk6a07u72c', has_more=False)\n\n\n\nprint(json.dumps(messages.model_dump(), indent=4))\n\n{\n    \"data\": [\n        {\n            \"id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n            \"assistant_id\": null,\n            \"content\": [\n                {\n                    \"text\": {\n                        \"annotations\": [],\n                        \"value\": \"reverse the string openaichatgpt\"\n                    },\n                    \"type\": \"text\"\n                }\n            ],\n            \"created_at\": 1705686038,\n            \"file_ids\": [],\n            \"metadata\": {},\n            \"object\": \"thread.message\",\n            \"role\": \"user\",\n            \"run_id\": null,\n            \"thread_id\": \"thread_z12e0BsDI8SfaePTmRMsApXo\"\n        }\n    ],\n    \"object\": \"list\",\n    \"first_id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n    \"last_id\": \"msg_j9CJRJRiYrsfl7pk6a07u72c\",\n    \"has_more\": false\n}\n\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nreverse the string openaichatgpt\n\n\n\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"make the previous input as uppercase and tell me the length of the string\"\n)\n\n\nimport time\n\n\n# new run\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n)\n\n# wait for run to complete\nwhile run.status == \"queued\" or run.status == \"in_progress\":\n    run = client.beta.threads.runs.retrieve(\n      thread_id=thread.id,\n      run_id=run.id\n    )\n    print(run.status)\n    time.sleep(2)\n\nin_progress\nin_progress\nin_progress\ncompleted\n\n\n\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n    )\n\n\ndisplay(Markdown(messages.data[0].content[0].text.value))\n\nThe reversed string “tpgtahcianepo” in uppercase is “TPGTAHCIANEPO”. The length of this string is 13 characters.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/dwarkesh-patel-anthropic-claude3-opus-python/podcast_analysis.html",
    "href": "posts/dwarkesh-patel-anthropic-claude3-opus-python/podcast_analysis.html",
    "title": "Book Recommendations, Interesting Advices, Career Tips from Dwarkesh Patel’s Podcasts using Anthropic’s Claude 3 API",
    "section": "",
    "text": "Top Books and Interesting Ideas discussed from Dwarkesh Patel’s Podcasts\n\nAnalysed data from Dwarkesh Patel’s podcasts to extract key details like author names, bios, book recommendations, and interesting ideas discussed\nProcessed a total of 63 podcast transcripts, spending over 30 minutes of processing time\nUsed over 1.5 million input tokens and generated over 20,000 output tokens from Antropic’s Claude 3 API\nVisualized relationships between word count, processing time, input tokens and output tokens using matplotlib and seaborn\nEstimated the total cost of the project based on Anthropic’s Cluade 3 Opus pricing for input and output tokens\nExtracted and summarized the top books and ideas discussed across all the podcasts analyzed\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndf = pd.read_csv(\"podcast_analysis.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nFile Name\ndate_published\nduration\nduration_in_minute\nProcessing Time (s)\nWord Count\nInput Tokens\nOutput Tokens\nResult\n\n\n\n\n0\n0\nSholto Douglas & Trenton Bricken - How to Buil...\n2024-03-28\n11593\n193.216667\n48.144148\n31262\n46658\n428\nHere is my response based on the information p...\n\n\n1\n1\nDemis Hassabis - Scaling, Superhuman AIs, Alph...\n2024-02-28\n3694\n61.566667\n27.644215\n11395\n17087\n303\nHere is my attempt at completing the requested...\n\n\n2\n2\nPatrick Collison (Stripe CEO) - Craft, Beauty,...\n2024-02-21\n6931\n115.516667\n31.906584\n17078\n24019\n259\nHere is my attempt at completing the requested...\n\n\n3\n3\nTyler Cowen - Hayek, Keynes, & Smith on AI, An...\n2024-01-31\n6142\n102.366667\n30.989137\n18829\n28844\n243\nHere is my attempt at the requested informatio...\n\n\n4\n4\nJung Chang (Wild Swans author) - Mao, Cultural...\n2023-11-29\n5475\n91.250000\n31.047358\n12351\n15745\n379\nHere is my attempt at the requested informatio...\n\n\n\n\n\n\n\n\n# overall processing time, total input tokens, total output token, number of podcast\nprint(\"Overall Processing Time in Minutes: \", df['Processing Time (s)'].sum()/60)\nprint(\"Overall Input Tokens: \", df['Input Tokens'].sum())\nprint(\"Overall Output Tokens: \", df['Output Tokens'].sum())\nprint(\"Overall Total Tokens: \", df['Input Tokens'].sum()+df['Output Tokens'].sum())\nprint(\"Number of Podcasts: \", df.shape[0])\nmillion_input_token_price = 15\nmillion_output_token_price = 75 # in dollar\n\nprint(\"Overall Input Token Cost: \", df['Input Tokens'].sum()/1000000*million_input_token_price)\nprint(\"Overall Output Token Cost: \", df['Output Tokens'].sum()/1000000*million_output_token_price)\n\n\n\n\nOverall Processing Time in Minutes:  33.49222877422969\nOverall Input Tokens:  1477272\nOverall Output Tokens:  20933\nOverall Total Tokens:  1498205\nNumber of Podcasts:  63\nOverall Input Token Cost:  22.15908\nOverall Output Token Cost:  1.5699750000000001\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 63 entries, 0 to 62\nData columns (total 10 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Unnamed: 0           63 non-null     int64  \n 1   File Name            63 non-null     object \n 2   date_published       63 non-null     object \n 3   duration             63 non-null     int64  \n 4   duration_in_minute   63 non-null     float64\n 5   Processing Time (s)  63 non-null     float64\n 6   Word Count           63 non-null     int64  \n 7   Input Tokens         63 non-null     int64  \n 8   Output Tokens        63 non-null     int64  \n 9   Result               63 non-null     object \ndtypes: float64(2), int64(5), object(3)\nmemory usage: 5.1+ KB\n\n\n\ndf[\"date_published\"] = pd.to_datetime(df[\"date_published\"])\ndf.set_index('date_published', inplace=True)\n\n\n\n\n\n# Duration distribution\nplt.figure(figsize=(8, 6))\nsns.histplot(df['duration_in_minute'], kde=True)\nplt.xlabel('Duration (minutes)')\nplt.ylabel('Count')\nplt.title('Distribution of Podcast Durations')\nplt.show()\n\n# Scatter plot of Word Count vs Duration\nplt.figure(figsize=(8, 6))\nplt.scatter(df['duration_in_minute'], df['Word Count'])\nplt.xlabel('Duration (minutes)')\nplt.ylabel('Word Count')\nplt.title('Word Count vs Duration')\nplt.show()\n\n\n\n\n\n\n\n\n# Plot 1: Processing Time vs Word Count\nplt.figure(figsize=(8, 6))\nplt.scatter(df['Word Count'], df['Processing Time (s)'])\nplt.xlabel('Word Count')\nplt.ylabel('Processing Time (s)')\nplt.title('Processing Time vs Word Count')\nplt.show()\n\n# Plot 2: Input Tokens vs Output Tokens\nplt.figure(figsize=(8, 6))\nplt.scatter(df['Input Tokens'], df['Output Tokens'])\nplt.xlabel('Input Tokens')\nplt.ylabel('Output Tokens')\nplt.title('Input Tokens vs Output Tokens')\nplt.show()\n\n# Plot 3: Distribution of Processing Time\nplt.figure(figsize=(8, 6))\nsns.histplot(df['Processing Time (s)'], kde=True)\nplt.xlabel('Processing Time (s)')\nplt.ylabel('Count')\nplt.title('Distribution of Processing Time')\nplt.show()\n\n\n\n# Plot 4: Correlation Heatmap\nplt.figure(figsize=(8, 6))\ncorr_matrix = df[['Processing Time (s)', 'Word Count', 'Input Tokens', 'Output Tokens']].corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownload Youtube Video Transcripts\n\nimport os\nfrom pytube import Playlist\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n\ndef download_playlist_transcripts(playlist_url):\n    # Create a Playlist object using the provided URL\n    playlist = Playlist(playlist_url)\n    \n    # Create a folder named \"podcast\" if it doesn't exist\n    if not os.path.exists(\"podcast\"):\n        os.makedirs(\"podcast\")\n    \n    # Create a dictionary to store file name, date published, and podcast duration\n    podcast_info = {}\n    \n    # Iterate through each video in the playlist\n    for video in playlist.videos:\n        video_id = video.video_id\n        try:\n            # Attempt to fetch the transcript for the current video\n            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n            \n            # Saving the transcript to a text file in the \"podcast\" folder\n            file_name = f\"{video.title}.txt\".replace(\"/\", \"-\")  # Replace '/' to avoid file path issues\n            file_path = os.path.join(\"podcast\", file_name)\n            with open(file_path, 'w', encoding='utf-8') as file:\n                for line in transcript:\n                    file.write(f\"{line['text']}\\n\")\n            \n            # Add file name, date published, and podcast duration to the dictionary\n            podcast_info[file_name] = {\n                \"date_published\": video.publish_date.strftime(\"%Y-%m-%d\"),\n                \"duration\": video.length\n            }\n            \n            print(f\"Transcript downloaded for video: {video.title}\")\n        except TranscriptsDisabled:\n            print(f\"Transcripts are disabled for video: {video.title}\")\n        except NoTranscriptFound:\n            print(f\"No transcript found for video: {video.title}\")\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n    \n    return podcast_info\n\n\nplaylist_url = 'https://www.youtube.com/watch?v=UTuuTTnjxMQ&list=PLd7-bHaQwnthaNDpZ32TtYONGVk95-fhF'\npodcast_info = download_playlist_transcripts(playlist_url)\n\nTranscript downloaded for video: Sholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind\nTranscript downloaded for video: Demis Hassabis - Scaling, Superhuman AIs, AlphaZero atop LLMs, Rogue Nations Threat\nTranscript downloaded for video: Patrick Collison (Stripe CEO) - Craft, Beauty, & The Future of Payments\nTranscript downloaded for video: Tyler Cowen - Hayek, Keynes, & Smith on AI, Animal Spirits, Anarchy, & Growth\nTranscript downloaded for video: Jung Chang (Wild Swans author) - Mao, Cultural Revolution, Great Leap Forward, & Modern CCP\nTranscript downloaded for video: Andrew Roberts - SV's Napoleon Cult, Why Hitler Lost WW2, Churchill as Applied Historian\nTranscript downloaded for video: Dominic Cummings - How Dysfunctional Govt Killed 1000s in COVID\nTranscript downloaded for video: Paul Christiano - Preventing an AI Takeover\nTranscript downloaded for video: Shane Legg (DeepMind Founder) - 2028 AGI, Superhuman Alignment, New Architectures\nTranscript downloaded for video: Grant Sanderson (3Blue1Brown) - Past, Present, & Future of Mathematics\nTranscript downloaded for video: Sarah C. M. Paine - WW2, Taiwan, Ukraine, & Maritime vs Continental Powers\nTranscript downloaded for video: George Hotz vs Eliezer Yudkowsky AI Safety Debate\nTranscript downloaded for video: Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & Alignment\nTranscript downloaded for video: Andy Matuschak -  Self-Teaching, Spaced Repetition, Why Books Don’t Work\nTranscript downloaded for video: Carl Shulman (Pt 2) - AI Takeover, Bio & Cyber Attacks, Detecting Deception, & Humanity's Far Future\nTranscript downloaded for video: Carl Shulman (Pt 1) - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment\nTranscript downloaded for video: Richard Rhodes - Making of Atomic Bomb, WW2, Oppenheimer, AI, & Apocalypse\nTranscript downloaded for video: Eliezer Yudkowsky - Why AI Will Kill Us, Aligning LLMs, Nature of Intelligence, SciFi, & Rationality\nTranscript downloaded for video: Ilya Sutskever (OpenAI Chief Scientist) - Building AGI, Alignment, Spies, Microsoft, & Enlightenment\nTranscript downloaded for video: Nat Friedman (Github CEO) - Reading Ancient Scrolls, Open Source, & AI\nTranscript downloaded for video: Brett Harrison - FTX US Former President Speaks Out\nTranscript downloaded for video: Marc Andreessen - AI, Crypto, 1000 Elon Musks, Regrets, Vulnerabilities, & Managerial Revolution\nTranscript downloaded for video: Garett Jones - Immigration, National IQ, & Less Democracy\nTranscript downloaded for video: Lars Doucet - Progress, Poverty, Georgism, & Why Rent is Too Damn High\nTranscript downloaded for video: Holden Karnofsky - History's Most Important Century\nTranscript downloaded for video: Bethany McLean - Enron, FTX, 2008, Musk, Frauds, & Visionaries\nTranscript downloaded for video: Nadia Asparouhova - Tech Elites, Democracy, Open Source, & Philanthropy\nTranscript downloaded for video: Byrne Hobart - FTX, Drugs, Twitter, Taiwan, & Monasticism\nTranscript downloaded for video: Edward Glaeser - Cities, Terrorism, Housing, & Remote Work\nTranscript downloaded for video: Kenneth T. Jackson - Robert Moses, Hero of New York?\nTranscript downloaded for video: Brian Potter - Future of Construction, Ugly Modernism, & Environmental Review\nTranscript downloaded for video: Bryan Caplan - Feminists, Billionaires, and Demagogues\nTranscript downloaded for video: Tyler Cowen - Why Society Will Collapse & Why Sex is Pessimistic\nTranscript downloaded for video: Charles C. Mann - Americas Before Columbus & Scientific Wizardry\nTranscript downloaded for video: Austin Vernon - Energy Superabundance, Starship Missiles, & Finding Alpha\nTranscript downloaded for video: Steve Hsu - Intelligence, Embryo Selection, & The Future of Humanity\nTranscript downloaded for video: Will MacAskill - Longtermism, Effective Altruism, History, & Technology\nTranscript downloaded for video: Joseph Carlsmith - Utopia, AI, & Infinite Ethics\nTranscript downloaded for video: Fin Moorhouse - Longtermism, Space, & Entrepreneurship\nTranscript downloaded for video: Alexander Mikaberidze - Napoleon, War, Progress, and Global Order\nTranscript downloaded for video: Sam Bankman-Fried - Crypto, FTX, Altruism, & Leadership\nTranscript downloaded for video: Agustin Lebron - Trading, Crypto, and Adverse Selection\nTranscript downloaded for video: Ananyo Bhattacharya - John von Neumann, Jewish Genius, and Nuclear War\nTranscript downloaded for video: Manifold Markets Founder - Predictions Markets & Revolutionizing Governance\nTranscript downloaded for video: Jimmy Soni - Peter Thiel, Elon Musk, and the Paypal Mafia\nTranscript downloaded for video: Bryan Caplan - Labor Econ, Poverty, & Mental Illness\nTranscript downloaded for video: Richard Hanania - Foreign Policy, Fertility, and Experts\nTranscript downloaded for video: David Deutsch - AI, America, Fun, & Bayes\nTranscript downloaded for video: Byrne Hobart - Optionality, Stagnation, and Secret Societies\nTranscript downloaded for video: David Friedman - Dating Markets, Legal Systems, Bitcoin, and Automation\nTranscript downloaded for video: Sarah Fitz-Claridge - Taking Children Seriously | The Lunar Society #15\nTranscript downloaded for video: Michael Huemer - Anarchy, Capitalism, and Progress\nTranscript downloaded for video: Uncle Bob - The Long Reach of Code, Automating Programming, and Developing Coding Talent\nTranscript downloaded for video: Scott Aaronson - Quantum Computing, Complexity, and Creativity\nTranscript downloaded for video: Scott Young - Ultralearning, The MIT Challenge\nTranscript downloaded for video: Charles Murray - Human Accomplishment and the Future of Liberty | The Lunar Society #10\nTranscript downloaded for video: Alex Tabarrok - Prizes, Prices, and Public Goods\nTranscript downloaded for video: Caleb Watney - America's Innovation Engine\nTranscript downloaded for video: Robin Hanson - The Long View and The Elephant in the Brain\nTranscript downloaded for video: Jason Crawford - The Roots of Progress & the History of Technology\nTranscript downloaded for video: Matjaž Leonardis - Science, Identity and Probability\nTranscript downloaded for video: Tyler Cowen - The Great Reset\nTranscript downloaded for video: Bryan Caplan - Nurturing Orphaned Ideas, Education, and UBI\n\n\n\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict(podcast_info, orient='index')\ndf = df.reset_index()\ndf = df.rename(columns={'index': 'File Name'})\ndf[\"duration_in_minute\"] = df[\"duration\"]/60\ndf\n\n\n\n\n\n\n\n\nFile Name\ndate_published\nduration\nduration_in_minute\n\n\n\n\n0\nSholto Douglas & Trenton Bricken - How to Buil...\n2024-03-28\n11593\n193.216667\n\n\n1\nDemis Hassabis - Scaling, Superhuman AIs, Alph...\n2024-02-28\n3694\n61.566667\n\n\n2\nPatrick Collison (Stripe CEO) - Craft, Beauty,...\n2024-02-21\n6931\n115.516667\n\n\n3\nTyler Cowen - Hayek, Keynes, & Smith on AI, An...\n2024-01-31\n6142\n102.366667\n\n\n4\nJung Chang (Wild Swans author) - Mao, Cultural...\n2023-11-29\n5475\n91.250000\n\n\n...\n...\n...\n...\n...\n\n\n58\nRobin Hanson - The Long View and The Elephant ...\n2020-08-31\n6029\n100.483333\n\n\n59\nJason Crawford - The Roots of Progress & the H...\n2020-08-25\n2918\n48.633333\n\n\n60\nMatjaž Leonardis - Science, Identity and Proba...\n2020-08-21\n2073\n34.550000\n\n\n61\nTyler Cowen - The Great Reset.txt\n2020-07-10\n2801\n46.683333\n\n\n62\nBryan Caplan - Nurturing Orphaned Ideas, Educa...\n2020-05-22\n3432\n57.200000\n\n\n\n\n63 rows × 4 columns\n\n\n\n\nlen(os.listdir(\"podcast\"))\n\n\n63\n\n\n\nimport os\nimport anthropic\nfrom dotenv import load_dotenv\nfrom IPython.display import Markdown\n\n\n\nPodcast Outputs\n\n\n\n# Load API keys from .env file\nload_dotenv()\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n# Set up the Anthropic API client\nclient = anthropic.Client(api_key=api_key)\n\ntranscript_directory = \"podcast\"\n\ndef process_transcript(transcript_text):\n    prompt = f\"\"\"Here is the transcript from a YouTube video which contains a conversation between Podcaster Dwarkesh\nPatel and his guest:\n\n&lt;transcript&gt;\n{transcript_text}\n&lt;/transcript&gt;\n\nPlease carefully read through the entire transcript above. Then complete the following steps:\n\n1. Extract a short 1-2 sentence bio of the guest, if possible based on information in the\ntranscript.\n\n2. Make a list of any books suggested by the guest in the podcast. Use commas to separate the book\ntitles.\n\n3. List out the unique interesting ideas discussed in the podcast.\n\n4. Summarize any discussion about how the guest started their career or any career advice they\nprovided.\n\n5. Summarize any discussion about the guest's learning process or how they learn.\n\nDo not hallucinate or fabricate any information. If some piece of information requested above is not\nfound in the transcript, simply skip that part. Do not write things like \"not found in transcript\".\n\nProvide your full response inside &lt;result&gt; tags.\n\"\"\"\n\n    response = client.messages.create(\n        model=\"claude-3-opus-20240229\",\n        max_tokens=4096,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n\n    return response\n\nimport time\n\n# Process each transcript file in the directory\nresults = {}\nfor i, filename in enumerate(os.listdir(transcript_directory)):\n    if filename.endswith(\".txt\"):\n        # Read the transcript text from the file\n        with open(os.path.join(transcript_directory, filename), \"r\") as file:\n            transcript_text = file.read()\n        \n        display(f\"Processed {i+1}/{len(os.listdir(transcript_directory))}: {filename}\")\n        display(\"*\"*100)\n        # Process the transcript using Claude\n        start_time = time.time()\n        result = process_transcript(transcript_text)\n        end_time = time.time()\n        processing_time = end_time - start_time\n\n        # Get the number of words in the file\n        word_count = len(transcript_text.split())\n\n        # Store the result, processing time, word count, input tokens, and output tokens in the dictionary\n        results[filename] = (processing_time, word_count, result.usage.input_tokens, result.usage.output_tokens, result.content[0].text)\n        \n        display(Markdown(result.content[0].text))\n        display(Markdown(f\"Input tokens: {result.usage.input_tokens}\"))\n        display(Markdown(f\"Output tokens: {result.usage.output_tokens}\"))\n        display(Markdown(f\"Processing time: {processing_time} seconds\"))\n        display(Markdown(f\"Podcast Word count: {word_count}\"))\n\n        \n\n\n\n\n'Processed 1/63: Ananyo Bhattacharya - John von Neumann, Jewish Genius, and Nuclear War.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the specified tasks based on the transcript:\n 1. Anano Bhattacharya is a science writer who has worked at the Economist and Nature. He is the author of “The Man from the Future: The Visionary Life of John von Neumann”.\n\nThe Man from the Future: The Visionary Life of John von Neumann\nInteresting ideas discussed:\n\n\nJohn von Neumann was a prolific genius and polymath who made seminal contributions to numerous fields including computer science, mathematics, physics, economics, and game theory\nVon Neumann’s work on cellular automata and self-reproducing machines was prescient and is only now being realized with research into xenobots\nVon Neumann’s game theory work focused more on cooperation and stable solutions rather than just zero-sum competitive games\nVon Neumann’s views were shaped by seeing the rise of communism and Nazism in Europe, making him wary of authoritarian governments\n\n\nNo direct discussion of how the guest started his career or career advice.\nNo direct discussion of the guest’s personal learning process. The guest advises against trying to emulate Von Neumann’s intense work habits and narrow focus on intellectual pursuits at the expense of personal relationships and work-life balance. \n\n\n\nInput tokens: 11108\n\n\nOutput tokens: 296\n\n\nProcessing time: 24.720909118652344 seconds\n\n\nPodcast Word count: 8463\n\n\n\"Processed 2/63: Sholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind.txt\"\n\n\n'****************************************************************************************************'\n\n\nHere is my response based on the information provided in the transcript:  1. Sholto and Trenton are AI researchers who have made important contributions in the field of AI safety and mechanistic interpretability of AI models in the early stages of their careers at Google Brain and Anthropic.\n\nThe Symbolic Species\nUnique interesting ideas discussed:\n\n\nLong context windows in language models allow them to ingest and learn from large amounts of information very effectively\nMuch of the learning in language models happens in the forward pass now, rather than during training\nAI agents haven’t taken off yet due to lack of reliability over long time horizons\nBrain regions like the cerebellum may be doing a lot of computation in superposition which is hard to interpret\nFeatures in AI models can be infinitely split into subfeatures upon close examination\nCurriculum learning could potentially make models more sample efficient by learning concepts in a structured order\nFeatures in language models are often universal across models trained on similar data\nInterpretability research can help identify deceptive or malicious circuits in models that can then be ablated for safety\n\n\nSholto and Trenton both took non-traditional paths into AI research. Sholto worked as a McKinsey consultant while doing AI research on nights and weekends which led to him being discovered and hired as part of an experiment at Google Brain. His agency, hard work ethic, and ability to learn and apply knowledge from many different domains allowed him to make quick progress and impact. Trenton got into computational neuroscience and interpretability research early in grad school and his interests aligned well with the research agenda at Anthropic, leading to him joining the company.\nSholto learns by obsessively reading papers, talking to domain experts to absorb their knowledge, and fearlessly taking on challenging research problems. He emphasizes the importance of ruthlessly prioritizing the highest-leverage problems to work on. \n\n\n\nInput tokens: 46658\n\n\nOutput tokens: 428\n\n\nProcessing time: 48.144148111343384 seconds\n\n\nPodcast Word count: 31262\n\n\n'Processed 3/63: Brian Potter - Future of Construction, Ugly Modernism, & Environmental Review.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my summary of the key information requested from the podcast transcript:  1. Bio of the guest: Brian Potter is an engineer and the author of the construction physics blog where he writes about how the construction industry works and why it has been slow to industrialize and innovate.\n\nBooks suggested by the guest: Where’s My Flying Car?\nUnique interesting ideas discussed:\n\n\nWhy modern buildings look uglier and have less ornamentation than older buildings\nThe garbage can theory of organizational decision making\nWhy construction has been slow to adopt prefabrication and 3D printing\nHow zoning laws and environmental regulations like NEPA have slowed down construction\nWhy construction has not seen the same productivity gains as other industries\n\n\nHow the guest started their career / career advice:\n\n\nGo to a good engineering school as the degree is valued in the building engineering field\nConsider working at a construction technology startup, especially in software development, to get into the industry in an oblique way\nLook for opportunities in green building, low-carbon materials, construction robotics, and prefab construction\n\n\nGuest’s learning process: Not discussed in the transcript. \n\n\n\nInput tokens: 34310\n\n\nOutput tokens: 261\n\n\nProcessing time: 35.006452322006226 seconds\n\n\nPodcast Word count: 27475\n\n\n'Processed 4/63: Will MacAskill - Longtermism, Effective Altruism, History, & Technology.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is a summary of the requested information from the podcast transcript:\n 1. William MacAskill bio: William MacAskill is one of the founders of the effective altruism movement and a professor at Oxford University. He is the author of the upcoming book “What We Owe the Future”.\n\nBooks mentioned: What We Owe the Future\nUnique interesting ideas discussed:\n\n\nMoral values are highly contingent on historical events. Our current values are likely far from the moral truth.\nMoral progress is more contingent than scientific/technological progress. Economic growth and technological development are likely to happen regardless of which society develops them first.\nWe are living in a time of “plasticity” where our actions and the values we lock in could shape the long-term future.\nIn the long-term future, if a single value system becomes dominant globally and is locked in by advanced technology, it could persist for a very long time.\nPromoting positive values that can stand the test of time may be a high impact way to shape the long-term future.\n\n\nCareer discussion: No direct career advice provided. MacAskill currently works as a professor which allows him to develop big picture ideas and communicate them to inspire others to do good. He has also co-founded and advised several effective altruism organizations.\nLearning process: Not directly discussed in the podcast. \n\n\n\nInput tokens: 14302\n\n\nOutput tokens: 311\n\n\nProcessing time: 27.399937868118286 seconds\n\n\nPodcast Word count: 11151\n\n\n'Processed 5/63: Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & Alignment.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested steps based on the transcript:\n 1. Dario Amodei is the CEO of Anthropic, a company working on building safe and ethical artificial intelligence systems.\n\n[No books were suggested by the guest in this podcast.]\nInteresting ideas discussed:\n\n\nAI systems are rapidly gaining capabilities and could potentially match humans at many tasks within the next 2-3 years\nCurrent AI systems are hard to control and align, and could pose existential risk if they become highly capable\nCybersecurity is crucial to prevent AI systems from falling into the wrong hands\nMechanistic interpretability is a key approach to understanding what is happening inside AI systems in order to align them\nThe difficulty of aligning AI systems is a complex problem without a clear binary solution\nAnalogies between AI and human intelligence are beginning to break down as AI scales up\nWhether current large language models are conscious is an open question that may become more pressing in the near future\n\n\n[No significant discussion of how the guest started their career or career advice.]\nDario learned about AI scaling laws empirically through hands-on experience and experiments early in his career at Baidu and OpenAI. He found consistent patterns that more compute, data, and model size led to smooth improvements in capabilities across many domains. Discussions with others like Ilya Sutskever further convinced him that this scaling phenomenon was a fundamental driver of AI progress. \n\n\n\nInput tokens: 28815\n\n\nOutput tokens: 328\n\n\nProcessing time: 33.30003094673157 seconds\n\n\nPodcast Word count: 19829\n\n\n'Processed 6/63: Matjaž Leonardis - Science, Identity and Probability.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my response based on the information in the transcript:\n 1. Matjaz Leonardis is a scientist who co-authored a paper with David Deutsch about the Popper-Miller theorem and its implications for induction and scientific reasoning.\n\nBooks suggested: Thinking, Fast and Slow by Daniel Kahneman\nUnique interesting ideas:\n\n\nIdentifying too much with being a “scientist” and following a specific scientific method can be counterproductive. It’s better to simply pursue questions and problems wherever they lead.\nThere is ambiguity around whether people are really following a method when forming thoughts and ideas. Thoughts often just arise in the mind.\nUniversal, explanatory theories are appealing because people have a psychological need for regularity. Such theories also enable progress by suggesting things to test that can prove them false.\nPeople are naturally curious and interested in everything. Systematic learning of fundamentals before advanced topics is unnecessary and can be counterproductive. It’s better to just read about what you find interesting.\n\n\nNo specific career advice or discussion of how the guest started his career.\nThe guest’s key ideas on learning:\n\n\nDon’t try to force systematic learning of fundamentals before advanced topics. Just read about whatever you find interesting.\nConnect with other people and groups working on problems, as this will surface valuable things you can contribute to.\nPeople have tremendous goodwill towards helping young people learn. The key challenge is idiosyncratically finding the right mentors and problems to work on. \n\n\n\nInput tokens: 8299\n\n\nOutput tokens: 345\n\n\nProcessing time: 25.074346780776978 seconds\n\n\nPodcast Word count: 6561\n\n\n'Processed 7/63: Nadia Asparouhova - Tech Elites, Democracy, Open Source, & Philanthropy.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio: Nadia Asparouhova is the author of Working in Public: The Making and Maintenance of Open Source Software and she is currently researching what the new tech elite will look like.\n\nBooks mentioned: Working in Public: The Making and Maintenance of Open Source Software\nInteresting ideas discussed:\n\n\nEffective altruism is much closer to the finance Wall Street elite mindset than it is to the startup mindset\nThe tech startup elite mindset is focused on meritocracy and the power of talented individuals to break institutions\nLeaderless, faceless, governed by protocol and code mindsets in crypto vs individual leader-driven open source projects and communities\nIdea machines are a new form of philanthropy driven by communities forming around shared values/ideas and then getting capitalized by funders to turn ideas into real world initiatives\nIt’s better for elite philanthropists to spend down fortunes within their lifetimes vs creating perpetual foundations\nWriting and intellectual work is valuable even if hard to quantify the impact - it influences builders even if indirectly\nClimate doomism and other forms of existential risk are new “gravity wells” attracting lots of smart people in the last 5 years in the absence of other grand shared narratives\n\n\nCareer advice: Do the thing you absolutely have to do and lean into your obsession, even if it doesn’t seem like the most impactful thing. Care more about quality and reaching the right people vs quantity of audience.\nLearning process: Talk to people - you can learn a lot more by directly talking to open source developers than speculating about what they might be thinking. Be observant and write about what you see. \n\n\n\nInput tokens: 18977\n\n\nOutput tokens: 395\n\n\nProcessing time: 34.19145703315735 seconds\n\n\nPodcast Word count: 12834\n\n\n'Processed 8/63: Eliezer Yudkowsky - Why AI Will Kill Us, Aligning LLMs, Nature of Intelligence, SciFi, & Rationality.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the podcast transcript:  1. Eliezer Yudkowsky is a prominent AI safety researcher who has been working on the problem of AI alignment for over 20 years and wrote the popular Harry Potter fanfiction “Harry Potter and the Methods of Rationality”.\n\nAdaptation and Natural Selection\nUnique interesting ideas discussed:\n\n\nAI alignment is an extremely difficult problem and humanity is likely doomed because we will develop superintelligent AI systems before solving alignment\nHuman values and drives have diverged significantly from the ancestral environment and evolutionary pressures that created us, and AI systems trained in different ways will likely have even more alien values\nIt’s very difficult to specify a utility function for an AI that would actually result in outcomes desirable to humans upon maximization\nAIs helping humans solve AI alignment is a very dangerous proposition and enhancing human intelligence to solve the problem would be safer\nRationality is not about social status or winning contests, it’s about having accurate beliefs and decision-making procedures to achieve your goals\n\n\nNo discussion of Eliezer’s early career or career advice was found in the transcript.\nEliezer has tried to help others develop the skills needed for AI alignment research through his writing, such as the Rationality Sequences on Less Wrong and Harry Potter and the Methods of Rationality. But he believes the education system does not properly train people to do real science and revolutionary insights, which are often passed down through apprenticeship instead. Overall, he has spent many years on the problem of how to transmit the necessary skills and has not fully solved it. \n\n\n\nInput tokens: 57983\n\n\nOutput tokens: 365\n\n\nProcessing time: 50.36423921585083 seconds\n\n\nPodcast Word count: 38775\n\n\n'Processed 9/63: Robin Hanson - The Long View and The Elephant in the Brain.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based on the provided transcript:\n 1. Bio of the guest: Robin Hanson is an associate professor of economics at George Mason University who has written extensively on idea futures, prediction markets, and hidden motives in human behavior.\n\nBooks suggested by the guest: The Elephant in the Brain\nUnique interesting ideas discussed:\n\n\nOrganizations exist to promote themselves and collect resources, not necessarily to achieve their stated purposes\nRemote work will lead to global specialization of labor and large productivity gains over the next 30 years\nConversation is more about signaling abilities and testing social alliances than exchanging information\nNerds are better at analyzing social dynamics because they observe them more explicitly\nParents dominate children in part to signal their own status, not just to benefit the children\nProfit maximization is an oversimplified model of firm behavior; firms are battlegrounds for competing political coalitions\nMost innovation comes from many small changes and experiments, not top-down planning\n\n\nThe guest’s career advice is to focus on learning general, long-lasting skills in your 20s rather than narrow technical skills. Stick with important problems over many decades. Take an overall view to identify neglected areas that are important to work on.\nThe guest’s learning process involves moving from one interesting topic to the next as he gains key insights that change what topics seem most important and interesting to pursue. He tries to take a broad perspective to identify important areas that are neglected by others. \n\n\n\nInput tokens: 24464\n\n\nOutput tokens: 338\n\n\nProcessing time: 32.86100196838379 seconds\n\n\nPodcast Word count: 19118\n\n\n'Processed 10/63: Bethany McLean - Enron, FTX, 2008, Musk, Frauds, & Visionaries.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested summary of the transcript:\n 1. Bio of guest: Bethany McLean is a well-known finance and business journalist, famous for breaking the story of the Enron scandal and writing several books including “The Smartest Guys in the Room” about Enron, “All the Devils are Here” about the 2008 financial crisis, and “Saudi America” about fracking.\n\nBooks by guest: The Smartest Guys in the Room, All the Devils are Here, Saudi America\nUnique interesting ideas discussed:\n\n\nThe fine line between being a visionary and a fraudster, and how self-delusion plays a role\nThe ineffectiveness of criminal prosecutions in deterring future corporate fraud\nThe idea of “moral luck” - that circumstance and environment shape behavior as much as individual character\nThe importance of incentive structures and culture in shaping corporate behavior\nThe role of the bankruptcy process in uncovering information after a corporate scandal\nThe challenges with creating effective private rating agencies and auditors\n\n\nCareer advice from guest: Bethany advises aspiring writers and journalists to force themselves to write things out in full, even when dealing with complex topics. The process of writing clearly requires you to think clearly and can reveal gaps in your own understanding.\nGuest’s learning process: Bethany says writing is a key part of her learning and thought process. Only by writing about a topic and trying to explain it clearly does she realize what she truly understands and doesn’t understand. She finds writing to be difficult but invaluable for clarifying her thinking. \n\n\n\nInput tokens: 20906\n\n\nOutput tokens: 366\n\n\nProcessing time: 28.6966609954834 seconds\n\n\nPodcast Word count: 16323\n\n\n\"Processed 11/63: Caleb Watney - America's Innovation Engine.txt\"\n\n\n'****************************************************************************************************'\n\n\nHere is a summary of the key information requested from the transcript:\n 1. Caleb Watney is the director of innovation policy at the Progressive Policy Institute.\n\nBooks suggested: Decadent Society by Ross Douthat, One Billion Americans by Matthew Yglesias.\nInteresting ideas discussed:\n\n\nImportance of physical agglomeration effects for innovation vs remote work\nHigh skill immigration reform as a key lever for improving innovation\nBig tech companies and the debate around regulating or breaking them up to promote competition\nImportance of federal R&D funding and reforming how it is structured and awarded\nLeveraging big climate mega projects and technology to combat climate change\nImpact of demographic trends like falling fertility rates on innovation and culture\n\n\nCareer advice: Think hard about the questions and problems that matter for society and where you can be most effective in addressing them, even if it runs counter to self-interest or immediate profitability. Policy analysis is an area where individuals can have a big impact even if it’s not directly economically rewarding.\nGuest’s learning process: Not directly discussed in the transcript. \n\n\n\nInput tokens: 15488\n\n\nOutput tokens: 257\n\n\nProcessing time: 22.48008441925049 seconds\n\n\nPodcast Word count: 12024\n\n\n'Processed 12/63: Bryan Caplan - Feminists, Billionaires, and Demagogues.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is the information I extracted from the transcript:  1. Brian Caplan is the author of “Don’t Be a Feminist: Essays on Genuine Justice” and “How Evil Are Politicians? Essays on Demagoguery”. He is a professional public speaker.\n\nBooks suggested by Brian Caplan in the podcast: Don’t Be a Feminist: Essays on Genuine Justice, How Evil Are Politicians? Essays on Demagoguery, Open Borders: The Science and Ethics of Immigration, The Case Against Education, The Rational Voter, The Russian Revolution by Richard Pipes\nUnique interesting ideas discussed:\n\n\nImmigration restrictions have enormous costs in terms of missed economic growth\nFeminism is less true today because of excessive false accusations against men\nHistorical contingency plays a large role in outcomes, e.g. the Russian Revolution would likely not have succeeded without Lenin\nThe best way to incentivize billionaires and entrepreneurship is to celebrate their success, not tax them excessively\nAnarcho-capitalism with competing private legal systems could be a viable system in the long-run\n\n\nCareer advice:\n\n\nBe ultra-honest in your dealings with others to build credibility\n\n\nLearning process:\n\n\nWhen studying a controversial issue, focus on looking at data and historical facts rather than pontificating\n\n\n\n\nInput tokens: 33079\n\n\nOutput tokens: 300\n\n\nProcessing time: 29.67089319229126 seconds\n\n\nPodcast Word count: 26183\n\n\n'Processed 13/63: Carl Shulman (Pt 1) - Intelligence Explosion, Primate Evolution, Robot Doublings, & Alignment.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Carl Shulman is a research associate at the Future of Humanity Institute at Oxford and an advisor to the Open Philanthropy project, one of the biggest funders on causes having to do with AI and its risks.\n\n[No books were suggested by the guest in this transcript.]\nInteresting ideas discussed:\n\n\nThe possibility of an AI-driven intelligence explosion and its potential impacts\nHow AI could contribute to and accelerate AI research, leading to rapid recursive improvement\nComparing the scaling of AI capabilities to human evolution and the growth of human civilization\nScenarios for how advanced AI could automate and expand industrial production and robotics\nChallenges and approaches to aligning advanced AI systems with human values\nCatastrophic risks from potential AI takeover scenarios\n\n\n[No discussion of how the guest started their career or specific career advice was found in the transcript.]\n[No discussion of the guest’s personal learning process was found in the transcript.] \n\n\n\nInput tokens: 32437\n\n\nOutput tokens: 235\n\n\nProcessing time: 30.634654998779297 seconds\n\n\nPodcast Word count: 22553\n\n\n'Processed 14/63: Kenneth T. Jackson - Robert Moses, Hero of New York?.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based solely on the information provided in the transcript:\n 1. Bio: Kenneth T. Jackson is the preeminent historian on New York City and was the director of the Herbert H. Lehman Center for American History and the Jacques Barzun Professor Emeritus of History at Columbia University.\n\nBooks suggested: The Power Broker by Robert Caro, Robert Moses and the Modern City: The Transformation of New York by Kenneth T. Jackson\nUnique interesting ideas discussed:\n\n\nRobert Moses had more power than any urban figure in American history and was responsible for building most of New York City’s major roads, bridges, parks, and public works from 1924-1970\nHad Robert Moses not done what he did, New York may have declined like other major Northeast and Midwest cities in the mid-20th century\nMoses was a ruthless, arrogant master builder who didn’t see people or communities, only large scale projects\nIt would be nearly impossible for someone like Moses to accumulate that much power and push through large public works today due to changes in laws, public opposition, and bureaucracy\nThe automobile and highways both shaped and responded to cultural attitudes and preferences in the mid-20th century\nJane Jacobs, Moses’ nemesis, appreciated the intricacies of neighborhoods and communities in a way Moses never did\n\n\n\n\n\n\n\nInput tokens: 20408\n\n\nOutput tokens: 320\n\n\nProcessing time: 28.263413906097412 seconds\n\n\nPodcast Word count: 13707\n\n\n'Processed 15/63: Grant Sanderson (3Blue1Brown) - Past, Present, & Future of Mathematics.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the podcast transcript:\n 1. Grant Sanderson is a math Youtuber who creates math education videos on his channel 3Blue1Brown. He has significantly impacted math education by making math concepts more accessible through his animated videos.\n\nBooks suggested by Grant Sanderson: Failure to Disrupt\nUnique interesting ideas discussed: • The difficulty of defining AGI and whether an AI getting gold in the IMO would signify AGI • Why new mathematical discoveries and fields like information theory are relatively recent despite pure math existing for a long time • How initial conditions and chance interactions with teachers can significantly impact a student’s future career trajectory • The value of having STEM experts spend time as teachers to get more people engaged with math and science • The importance of social factors like friend groups in motivating learning, more so than the quality of explanations • How peer review voting systems helped surface high-quality math exposition videos in the Summer of Math Exposition contests\nGrant did not discuss in detail how he started his career. He mentioned that the first 3Blue1Brown video was made when he was a senior at Stanford.\nGrant discussed the importance of working through calculations yourself when self-learning math, rather than just reading explanations, in order to build intuition. He also mentioned that explaining concepts well requires remembering what it was like to not understand the concept, which gets harder over time. \n\n\n\nInput tokens: 24499\n\n\nOutput tokens: 326\n\n\nProcessing time: 33.956478118896484 seconds\n\n\nPodcast Word count: 16911\n\n\n'Processed 16/63: Fin Moorhouse - Longtermism, Space, & Entrepreneurship.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Finn Morehouse bio: Finn Morehouse is a research scholar at the Oxford University’s Future of Humanity Institute and an assistant to Toby Ord. He is also the host of the Hear This Idea podcast.\n\nBooks suggested: Talent by Tyler Cowen and Daniel Gross, Anti-Fragile by Nassim Taleb\nUnique interesting ideas discussed:\n\n\nThe value of humility, endorsing changing your mind, and encouraging criticism for social movements and intellectual circles to avoid ossifying into an echo chamber\nThe possibility that many worlds quantum theory could meaningfully affect how we think about the far future and ethics\nWhether the upside potential of for-profit companies aiming to do good is being underrated compared to non-profit work\nPotential concerns about whether space governance norms decided now will persist and affect the very long-term future\nThe value of starting a podcast as a relatively easy way to invite conversations with and boost the ideas of impressive people\n\n\nFinn’s career advice:\n\n\nBe proactive about connecting with potential mentors and people working on topics that excite you\nReflect on key decisions until you have a stable level of confidence in your choice, rather than waiting for certainty\nBe open to trying things like starting a podcast or blog, even if they may fail, because you will learn from them\n\n\nFinn’s learning process:\n\n\nReading widely, including speculative ideas, and scrutinizing them to see if the arguments hold up\nHaving conversations with experts to extract and spread important ideas\nProactively reaching out to people he looks up to as potential mentors to learn from them \n\n\n\nInput tokens: 36900\n\n\nOutput tokens: 389\n\n\nProcessing time: 41.87009596824646 seconds\n\n\nPodcast Word count: 27881\n\n\n'Processed 17/63: Edward Glaeser - Cities, Terrorism, Housing, & Remote Work.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information requested from the transcript:\n\n\nBio: Edward Glaeser is the chair of the Harvard Department of economics and the author of books and papers about cities, including Triumph of the City and Survival of the City.\nBooks suggested by guest: Triumph of the City by Edward Glaeser, Survival of the City by Edward Glaeser, The Power Broker by Robert Caro, Palaces for the People by Eric Klinenberg\nUnique interesting ideas discussed:\n\n\nCities on Mars would be limited by high transportation costs and would likely be car-oriented\nCities are both vulnerable targets but also defensible spaces that can protect themselves from terrorism\nAmericans are moving less between states than in the past, likely due to housing costs and the informal “safety net” of family support being tied to a location\nInformation technology like books, telephones, and videoconferencing tends to complement face-to-face interaction in the long run, even if it substitutes for it in the short run\nCity slums in developing countries can be safe due to permanence and community enforcement of norms, as long as there aren’t too many guns or lucrative drug trades\nThe biggest unsolved problem in cities is how to protect developing world cities from the impacts of climate change\n\n\nNo significant discussion of the guest’s career start or career advice.\nNo significant discussion of the guest’s learning process or how they learn.\n\n\n\n\nInput tokens: 14848\n\n\nOutput tokens: 336\n\n\nProcessing time: 28.60408091545105 seconds\n\n\nPodcast Word count: 11490\n\n\n'Processed 18/63: Scott Aaronson - Quantum Computing, Complexity, and Creativity.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is the response based on the transcript:  1. Bio: Scott Aaronson is a Professor of Computer Science at the University of Texas at Austin. He received his PhD at age 22 and is known for his work in quantum computing and complexity theory.\n\nBooks suggested: The Fabric of Reality by David Deutsch\nInteresting ideas discussed:\n\n\nIt doesn’t take that long to become the world expert on one particular tiny problem\nMany of the important discoveries in quantum mechanics were made by people at a young age\nThere may be a threshold between chimpanzee and human intelligence in terms of ability to explain the world and build universal machines\nWe don’t know if humans are “universal explainers” that can explain everything that is explainable\nThere are fixed questions like the hard problem of consciousness that our current conception of an explanation may never suffice to explain\n\n\nCareer start and advice: Scott was unhappy in high school and wanted to get to college early, so he got a GED at 15 and started taking college courses. He went to Cornell at 16 and got his PhD by 22. His advice is to learn all you can by taking courses, talking to professors, reading papers, and becoming a world expert on something narrow. This can lead to collaborations and expanding expertise.\nLearning process: Scott learned by taking advanced courses early on in college. He would read new quantum computing papers every day, flag interesting ones to read, and reach out to the authors with questions and ideas. He expanded his expertise by starting narrow and gradually broadening. \n\n\n\nInput tokens: 19530\n\n\nOutput tokens: 354\n\n\nProcessing time: 32.598668813705444 seconds\n\n\nPodcast Word count: 15147\n\n\n'Processed 19/63: Demis Hassabis - Scaling, Superhuman AIs, AlphaZero atop LLMs, Rogue Nations Threat.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested steps based on the transcript:\n 1. Demis Hassabis is the CEO and co-founder of DeepMind, an artificial intelligence company. He has a background in neuroscience and has been working on and thinking about artificial general intelligence (AGI) for over 30 years.\n\n[No books were suggested by the guest in this podcast.]\nUnique interesting ideas discussed:\n\n\nLarge language models today are surprisingly effective and capable of learning some abstract concepts implicitly\nReinforcement learning and self-play could help generate useful synthetic data to train AI systems\nTrue multimodal AI systems that combine language, vision, robotics, etc. could be more powerful than single-modality systems\nWe need better ways to analyze the internal representations and concepts learned by AI systems, similar to brain imaging\nExtensive testing, security measures, and governance will be critical to ensure advanced AI systems are safe and beneficial\n\n\nDemis co-founded DeepMind in 2010 with the long-term goal of developing AGI, believing it was possible based on the existence proof of human intelligence. From the beginning, he thought deeply about the immense impact, both positive and negative, that such a technology could have.\n[The guest did not discuss his personal learning process in this podcast.] \n\n\n\nInput tokens: 17087\n\n\nOutput tokens: 303\n\n\nProcessing time: 27.64421510696411 seconds\n\n\nPodcast Word count: 11395\n\n\n'Processed 20/63: Tyler Cowen - Hayek, Keynes, & Smith on AI, Animal Spirits, Anarchy, & Growth.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:  1. Tyler Cowen is an economist, blogger, and author. He is a professor at George Mason University and runs the blog Marginal Revolution.\n\nBooks mentioned: Cowen’s book “How to Pay for the War” from 1940.\nUnique interesting ideas discussed:\n\n\nMany people are overly optimistic and make irrational investments, but this may have social benefits\nAnarchy is everywhere to some degree, even within governments, and collusion is needed for systems to persist\nAI agents will likely replicate markets and economies on their own\nIntelligence is likely a net positive, even if it comes with risks\nDivision of labor leads to more specialization but less curiosity and breadth of knowledge\nThe “internet way of writing and thinking” is a new powerful mode of thought that is underrecognized\n\n\nNo information provided about how Tyler Cowen started his career or career advice.\nNo clear information provided about Tyler Cowen’s personal learning process. \n\n\n\nInput tokens: 28844\n\n\nOutput tokens: 243\n\n\nProcessing time: 30.989137172698975 seconds\n\n\nPodcast Word count: 18829\n\n\n'Processed 21/63: Nat Friedman (Github CEO) - Reading Ancient Scrolls, Open Source, & AI.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based solely on the information in the transcript:\n 1. Nat Friedman was the CEO of GitHub from 2018 to 2021. Before that, he started and sold two companies, Ximian and Xamarin, and he is also the founder of AI Grant and California YIMBY.\n\nNo books were directly suggested by the guest in this podcast.\nUnique interesting ideas discussed:\n\n\nUsing advanced imaging technology and machine learning to virtually unwrap and read ancient carbonized papyrus scrolls found in Herculaneum\nAcquisitions often fail because the acquired company’s culture gets disrupted and the most talented people leave\nIt’s often better to raise the ceiling with new technology than try to raise the floor, because ceiling-raising tech will eventually become cheap and widespread\nThe world is more inefficient than people think and there are many opportunities that are not being pursued\nIn many cases, it’s more accurate to model the world as 500 people than 8 billion\nThe cultural prohibition on micromanagement is harmful and great individuals should be empowered to exercise their judgment\nThere will likely be wide-scale proliferation of AI foundation models rather than an oligopoly\n\n\nNat discussed how he started companies like Ximian and Xamarin which were acquired. As CEO of GitHub, he pushed the company to ship improvements and new features quickly after the acquisition to demonstrate that GitHub still cared about developers. No explicit career advice was provided.\nNat said he has a high willingness to try new things and jump into new projects impulsively. He cultivates a forward-looking view and doesn’t dwell on past accomplishments. No other explicit discussion of his learning process. \n\n\n\nInput tokens: 25392\n\n\nOutput tokens: 394\n\n\nProcessing time: 38.10643720626831 seconds\n\n\nPodcast Word count: 17064\n\n\n'Processed 22/63: Joseph Carlsmith - Utopia, AI, & Infinite Ethics.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:\n 1. Bio of guest: Joe Carlsmith is a senior research analyst at Open Philanthropy and a doctoral student in philosophy at the University of Oxford. He researches existential risk from artificial intelligence and writes about philosophy, ethics, and the future on his blog Hands and Cities.\n\nBooks suggested by guest: The Precipice by Toby Ord, Angels in America, Housekeeping by Marilynne Robinson\nUnique interesting ideas discussed:\n\n\nThe possibility of a profoundly better future (utopia) that is radically better than the present\nTrying to grapple with ethics and decision-making with respect to infinite worlds and universes\nEstimating the computational capacity it would take to match human brain cognition\nThe self-indication assumption vs the self-sampling assumption in anthropic reasoning\nMuch of futurism feels unreal because imagination is limited and futurism relies on lossy abstractions\n\n\nSummary of career advice:\nSummary of guest’s learning process: \n\n\n\nInput tokens: 23890\n\n\nOutput tokens: 250\n\n\nProcessing time: 27.040849924087524 seconds\n\n\nPodcast Word count: 18522\n\n\n'Processed 23/63: Bryan Caplan - Nurturing Orphaned Ideas, Education, and UBI.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based on the podcast transcript:\n 1. Bryan Caplan is a professor of economics at George Mason University. He has written several books including Open Borders and The Case Against Education.\n\nBooks suggested by Bryan Caplan in the podcast: Open Borders, The Case Against Education, The Ethics of Voting by Jason Brennan, How to Win Friends and Influence People by Dale Carnegie\nInteresting ideas discussed:\n\n\nEducation’s main value is signaling rather than imparting useful skills\nNuclear weapons have made peace more likely but also increase risk of annihilation\nA Universal Basic Income is a bad idea because it wastes resources on people who don’t need it\nMany government policies directly cause poverty by stifling economic growth and opportunity\nPersonal irresponsibility is also a significant contributor to poverty\nZoning regulations and housing restrictions have huge economic costs by preventing people from moving to high-productivity areas\n\n\nCareer advice: No explicit career advice was provided in the transcript.\nLearning process: No discussion of Caplan’s personal learning process was found in the transcript. \n\n\n\nInput tokens: 14490\n\n\nOutput tokens: 260\n\n\nProcessing time: 20.04172420501709 seconds\n\n\nPodcast Word count: 11571\n\n\n'Processed 24/63: Dominic Cummings - How Dysfunctional Govt Killed 1000s in COVID.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Dominic Cummings was the chief advisor to UK Prime Minister Boris Johnson and masterminded the Brexit campaign.\n\nBooks mentioned: Memoir about the White House by Jared Kushner, Now It Can Be Told: The Story Of The Manhattan Project by General Leslie R. Groves, Kill Chain: The Rise of the High-Tech Assassins by Christian Brose, Bismarck: A Life (3 volume biography) by Otto Pflanze\nUnique interesting ideas discussed:\n\n\nThe chronic dysfunction and lack of effective management inside the UK government\nThe reasons politicians are obsessed with the media and how it harms good governance\nThe need to empower competent people and remove bureaucratic obstacles during crises like COVID\nBismarck’s career as an analogy to the AI alignment problem\nThe traits needed for a leader to effectively control and reform government\nWhy creating a new political party and movement is so difficult\nThe need for leaders and advisors who can synthesize knowledge across many fields\nHow the education system, especially PPE degrees, fails to properly train future leaders\nWhy smart, competent people are disincentivized from going into politics\nExpecting decline and failure as the default for the West based on historical patterns\n\n\nDominic started his career trying to launch an airline in Russia in the 1990s, which taught him lessons about how incentives shape behavior and to question his assumptions. No other career advice was provided.\nNo specific discussion of Dominic’s learning process. \n\n\n\nInput tokens: 37957\n\n\nOutput tokens: 371\n\n\nProcessing time: 40.7433021068573 seconds\n\n\nPodcast Word count: 24862\n\n\n'Processed 25/63: Byrne Hobart - Optionality, Stagnation, and Secret Societies.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio: Byrne Hobart is a writer, consultant and investor who writes at diff.substack.com.\n\nBooks suggested: Where’s My Flying Car, The Money Game by Adam Smith (pseudonym), The Looming Tower, How Asia Works\nUnique interesting ideas discussed:\n\n\nHow financial concepts like expected value, optionality, and volatility can be applied to human decisions and institutions\nThe challenge of coordination when solving complex problems, both within and between institutions\nStagnation in technological and social progress since the mid-20th century\nAnalyzing the motivations and incentives of secret societies\nThe rationality community predicted COVID-19 early on due to their willingness to honestly extrapolate ideas to their logical conclusions\nThere are increasing returns to knowledge and learning more about a topic\nCountries and individuals can escape the “middle income trap” by developing unique skills, technologies or branded products that others cannot easily match\n\n\nCareer advice:\n\n\nBe very judicious about optionality in your career. Sometimes committing to a specific path without having options is valuable.\nPick a narrow topic and strive to become one of the world’s leading experts on it by doing a deep dive of research and synthesizing the information. This demonstrates the ability to learn and creates a valuable body of work.\n\n\nGuest’s learning process:\n\n\nByrne learns by buying a variety of books on a topic that take different angles, including fiction from the relevant time period, and reading them to get a broad understanding\nHe finds that reading multiple books on the same topic allows you to draw insightful connections between ideas that any single author might miss\nByrne retains knowledge through this process of connecting ideas across different sources. The more context and connections you have, the more what you learn will make sense and stick with you. \n\n\n\nInput tokens: 18651\n\n\nOutput tokens: 424\n\n\nProcessing time: 36.757038831710815 seconds\n\n\nPodcast Word count: 14715\n\n\n\"Processed 26/63: Carl Shulman (Pt 2) - AI Takeover, Bio & Cyber Attacks, Detecting Deception, & Humanity's Far Future.txt\"\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Carl Shulman is a researcher who studies AI forecasting and global catastrophic risks. He has worked with Open Philanthropy on these topics.\n\nBooks suggested by Carl Shulman: Vaclav Smil’s books, Joel Mokyr’s work on the history of the scientific revolution, Mind Children by Hans Moravec\nUnique interesting ideas discussed:\n\n\nScenarios for how unaligned AI could take over the world through cyber attacks, bioweapons, and bargaining with human factions\nThe importance of AI alignment research to ensure AI systems are honestly reporting their intentions\nThe potential for an intelligence explosion once AI systems can recursively improve themselves, leading to rapid technological progress\nChallenges in international coordination between governments and AI labs to ensure safety as AI capabilities advance\nPossible trajectories for a post-AGI future, and whether a malthusian state is inevitable in the long-run\nInfo hazards around discussing concrete AI risks scenarios publicly\n\n\nNo discussion of how Carl Shulman started his career or career advice.\nCarl Shulman’s learning process:\n\n\nKeeping abreast of literature on many topics by reading books and academic works\nRelying on data and quantitative information to evaluate hypotheses, doing back-of-the-envelope calculations for consistency\nTrying to be exhaustive by systematically going through taxonomies of possibilities (e.g. reviewing global catastrophic risk scenarios across different scientific fields) \n\n\n\nInput tokens: 35371\n\n\nOutput tokens: 352\n\n\nProcessing time: 39.60577988624573 seconds\n\n\nPodcast Word count: 24723\n\n\n'Processed 27/63: Austin Vernon - Energy Superabundance, Starship Missiles, & Finding Alpha.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information from the podcast transcript:\n\n\nAustin Vernon’s bio: Austin Vernon has a degree in chemical engineering and has worked as a chemical engineer in a large processing facility as well as done petroleum engineering. He taught himself how to write software and is now working on research and early commercialization of CO2 electrolysis.\nBooks mentioned: The Goal, The Machine, The Toyota Production System\nUnique interesting ideas discussed:\n\n\nUsing Starship as a kinetic weapon and the implications of drastically reduced space launch costs\nSoftware is limited in increasing productivity due to the complexity of capturing real-world processes at the bit level\nVertically integrating software development can help manage complexity\nTesla’s “metal manufacturing” approach vs Toyota’s lean production system\nImplications of energy superabundance, including cheaper transportation, new chemical processes, changes to cities and infrastructure\nPerspectives on the future of nuclear power with new reactor designs\nWhere to find market alpha based on the efficient market hypothesis\n\n\nThe guest did not discuss in detail how they started their career. Some career-relevant advice included finding legal ways to acquire private information to gain an edge in markets, and that specific knowledge and developing a brand can lead to excess returns.\nThe guest talked about learning about cryptography and blockchain concepts by writing blog posts explaining topics like hash functions in order to understand things like the Bitcoin whitepaper. Blogging has also helped the guest learn about topics they write about and make valuable connections.\n\n\n\n\nInput tokens: 35002\n\n\nOutput tokens: 338\n\n\nProcessing time: 41.73274803161621 seconds\n\n\nPodcast Word count: 27397\n\n\n'Processed 28/63: Agustin Lebron - Trading, Crypto, and Adverse Selection.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the relevant information from the podcast transcript:\n 1. Augustine Lebron is the author of the book “The Laws of Trading: A Trader’s Guide to Better Decision Making for Everyone”. He previously worked as an engineer for 6 years before transitioning into a career in quantitative trading at Jane Street. A few years ago, he left Jane Street to start his own consulting company helping tech companies with management and hiring. Recently, he started a new company in the crypto space.\n\nBooks suggested by the guest: A Deepness in the Sky by Vernor Vinge, Red-Blooded Risk by Aaron Brown, The Poker Face of Wall Street by Aaron Brown, Kolyma Stories by Varlam Shalamov\nInteresting ideas discussed:\n\n\nTrading is hard and there are likely easier ways to make money and have a satisfying life than becoming a trader\nFinance may seem like an outsized portion of GDP, but it’s unclear if there is a more efficient way to achieve the liquidity and price discovery that the financial industry provides\nSoftware development is fundamentally an exercise in sociology - in organizing teams and creating processes, culture and conventions around building software\nThe best outcome for crypto is likely integration with the existing financial system rather than replacing it entirely\n\n\nThe guest transitioned from engineering to trading after 6 years because engineering was getting boring and he was playing a lot of online poker at the time. He thought trading would be halfway between engineering and poker. After a few years at Jane Street, he left to start his own consulting company.\nThe guest believes in being “sequentially obsessive” - spending 5-6 years getting really good at one thing, then moving on to master something else for the next 5-6 years, and so on. He finds value in developing deep expertise in a field but then cross-pollinating by learning new fields over the course of a career. This sequential excellence allows you to bring new perspectives to each new area. \n\n\n\nInput tokens: 16826\n\n\nOutput tokens: 447\n\n\nProcessing time: 36.44933819770813 seconds\n\n\nPodcast Word count: 13269\n\n\n'Processed 29/63: Charles C. Mann - Americas Before Columbus & Scientific Wizardry.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information:\n 1. Bio: Charles Mann is the author of several books including 1491, 1493, and The Wizard and the Prophet.\n\nBooks suggested by the guest: 1491 by Charles Mann, 1493 by Charles Mann, The Wizard and the Prophet by Charles Mann, Civilizations by Laurent Binet, The Anarchy by William Dalrymple, Against the Grain by James Scott, The Dawn of Everything by David Wengrow and David Graeber, Termination Shock by Neal Stevenson\nUnique interesting ideas discussed:\n\n\nElites throughout history have recognized each other and made mutually beneficial arrangements to increase their power\nMany native societies in the Americas survived and adapted despite facing tremendous losses from disease after European contact\nPyramids developed independently in the Old World and New World, showing some solutions are universal due to practical constraints\nTechnological developments like the wheel were not always adopted, possibly due to lacking key supporting factors like draft animals\nThe Green Revolution and Norman Borlaug’s work greatly increased food production, though social/political factors also shaped its implementation\nNuclear power faces unique regulatory hurdles compared to other energy sources\nDeveloping crops beyond the main staples could make agriculture more resilient to climate change\nMarkets have never truly governed essential resources like food, water and energy; government always plays a major role\n\n\nNo discussion of the guest’s early career or career advice.\nNo discussion of the guest’s learning process. \n\n\n\nInput tokens: 22159\n\n\nOutput tokens: 352\n\n\nProcessing time: 30.224998235702515 seconds\n\n\nPodcast Word count: 17181\n\n\n\"Processed 30/63: Andrew Roberts - SV's Napoleon Cult, Why Hitler Lost WW2, Churchill as Applied Historian.txt\"\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:\n 1. Bio of the guest: Andrew Roberts is a historian who is the author of 20 books including biographies of Churchill, Napoleon, King George, and an excellent book about World War II. He is a member of the House of Lords in the UK.\n\nBooks suggested by the guest: Conflict: The Evolution of Warfare from 1945 to Ukraine, Masters and Commanders, Marlborough: His Life and Times, Savrola by Winston Churchill, Klisson and Eugenie by Napoleon\nUnique interesting ideas discussed:\n\n\nThe invention of nuclear weapons explains the lack of major wars between great powers after 1945\nStrategic leadership, including the ability to adapt strategy as circumstances change, is often the key factor in who wins wars, even more so than superior numbers or weaponry\nIn the future, wars will likely be fought primarily between drones and autonomous systems, with humans not directly in the loop due to the speed of decision making required\nTech entrepreneurs like Elon Musk are having an unprecedented impact on modern warfare by providing technologies like Starlink to combatants\nChurchill and Napoleon were forward-thinking futurists fascinated by science and technology\nNapoleon and Churchill both wrote autobiographical novels in their 20s about a hero who saves his country and marries a fair maiden\nBiography is a powerful way to understand history by focusing on the choices and impact of influential individuals\n\n\nCareer advice: N/A\nGuest’s learning process: Andrew Roberts starts work at 4am each day to get focused time before distractions, and takes a 30 minute nap every afternoon to effectively “get two days’ worth of work out of one day.” He started this habit in his early 20s. \n\n\n\nInput tokens: 17445\n\n\nOutput tokens: 400\n\n\nProcessing time: 30.742560148239136 seconds\n\n\nPodcast Word count: 11443\n\n\n'Processed 31/63: Andy Matuschak -  Self-Teaching, Spaced Repetition, Why Books Don’t Work.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my response based on the transcript:\n 1. Bio: Andy Matuschak is a researcher, engineer, and designer working on tools for thought.\n\nBooks suggested: How to Read a Book by Mortimer Adler and Charles Van Doren\nInteresting ideas discussed:\n\n\nWe underappreciate the role that memory has in understanding difficult material\nFor the median student, the education system mostly wants to make the student do things they don’t want to do rather than achieve their own goals\nLLMs depend on our ability to externalize knowledge and make it legible\nExplicit memorization is a way to bootstrap yourself to the point where you can reinforce knowledge more naturalistically\nCrowdfunding research only works if the work is understandable and interesting to a broad audience\nThe boundaries and constraints of product design at a large tech company like Apple are highly compartmentalized\n\n\nAndy’s learning process:\n\n\nAsks questions of the text while reading and tries to answer them to ensure comprehension\nTakes notes in a way that lets him build them up over time and have a place to look when exploring an idea again later\nBalances journaling to explore ideas in the moment with more durable notes that try to stand outside of time\nUses spaced repetition to memorize facts that won’t come up frequently enough to be naturally reinforced \n\n\n\nInput tokens: 34417\n\n\nOutput tokens: 311\n\n\nProcessing time: 36.83078932762146 seconds\n\n\nPodcast Word count: 23178\n\n\n'Processed 32/63: Manifold Markets Founder - Predictions Markets & Revolutionizing Governance.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio of guest: Stephen Gruget is the founder of Manifold Markets, a platform for user-created prediction markets. Manifold Markets has received a grant from Scott Alexander and raised a $2 million seed round.\n\nBooks suggested by guest: [none mentioned]\nUnique interesting ideas discussed:\n\n\nPrediction markets can help ground news articles and political discussions in facts and well-calibrated probabilities\nPrediction markets with play money can work because people are driven by status and competitiveness more than financial gain\nUser-resolved prediction markets, where the market creator resolves the market outcome, make prediction markets much more scalable despite some risk of fraud\nPeople are willing to invest significant time into virtual economies like prediction markets even without direct financial payouts\nPrediction markets can be used in creative ways beyond just forecasting, such as researching topics, playing games like Wordle, or running lotteries\n\n\nGuest’s career start and advice: [no substantial discussion]\nGuest’s learning process: Stephen learned about prediction market mechanisms like Uniswap, Hanson’s logarithmic market scoring rule, and dynamic parimutuel systems mostly by reading academic papers after already coming up with related ideas from first principles thinking. He dove into the technical details as he was building Manifold Markets. \n\n\n\nInput tokens: 12473\n\n\nOutput tokens: 313\n\n\nProcessing time: 25.157910108566284 seconds\n\n\nPodcast Word count: 9759\n\n\n'Processed 33/63: Shane Legg (DeepMind Founder) - 2028 AGI, Superhuman Alignment, New Architectures.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information from the podcast transcript:\n 1. Bio: Shane Legg is the founder and Chief AGI scientist at Google DeepMind.\n\nBooks suggested: The Age of Spiritual Machines by Ray Kurzweil\nInteresting ideas discussed:\n\n\nHow to measure progress towards AGI and what is missing from current benchmarks\nAGI systems need episodic memory in addition to the “working memory” and “cortical memory” in current language models\nTo exhibit real creativity, AI systems need to incorporate search to find “hidden gems” beyond just blending patterns in training data\nTo be ethical, AGI systems need a good world model, robust reasoning, and a deep understanding of human ethics and values\nAI safety and alignment are critical as AI systems become more powerful\nThe next major AI milestone will be fully multimodal systems that understand images, video, actions etc. beyond just text\n\n\nCareer: No specific discussion of how Shane started his career or career advice.\nLearning process: No discussion of Shane’s personal learning process or advice on how to learn. \n\n\n\nInput tokens: 10393\n\n\nOutput tokens: 256\n\n\nProcessing time: 21.963053941726685 seconds\n\n\nPodcast Word count: 6960\n\n\n'Processed 34/63: Charles Murray - Human Accomplishment and the Future of Liberty | The Lunar Society #10.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n\n\nBio of guest: Charles Murray is an American political scientist, sociologist, and author. He wrote the book “Human Accomplishment: The Pursuit of Excellence in the Arts and Sciences” and is a fellow at the American Enterprise Institute.\nBooks suggested by guest: The Discoverers by Daniel Boorstin, By The People: Rebuilding Liberty Without Permission by Charles Murray, The Curmudgeon’s Guide to Getting Ahead: Dos and Don’ts of Right Behavior, Tough Thinking, Clear Writing, and Living a Good Life by Charles Murray, Coming Apart: The State of White America, 1960-2010 by Charles Murray, The Decadent Society: How We Became the Victims of Our Own Success by Ross Douthat\nUnique interesting ideas discussed:\n\n\nLiberty as conceived by America’s founders is historically unique in establishing a government on the premise that individuals should be free to pursue happiness\nThe rate of major human accomplishment may be declining due to increased government regulation and a decadent culture\nChristianity played a crucial role in fostering human accomplishment in the West\nCivil disobedience funds could help push back against overregulation by systematically ignoring regulations and defending against government enforcement\nHard work over long periods of time is the common factor among those who achieve excellence\n\n\nHow guest started career / career advice:\n\n\nSpend your 20s learning what you love to do by going outside your comfort zone, such as by joining the military or living in a foreign country\nOnce you find something you want to pursue, go into high gear working incredibly hard at it\nYou can get noticed early in your career by being anal about doing excellent work and conveying that you will work extremely hard\n\n\nGuest’s learning process:\n\n\nMurray immerses himself in a topic he’s interested in, reading and writing about it idiosyncratically rather than systematically planning out a book\nHe spent years gathering data on human accomplishment by poring over indexes of books and quantifying references to significant figures and events\n\n\n\n\nInput tokens: 22189\n\n\nOutput tokens: 479\n\n\nProcessing time: 38.65663528442383 seconds\n\n\nPodcast Word count: 17027\n\n\n'Processed 35/63: Richard Rhodes - Making of Atomic Bomb, WW2, Oppenheimer, AI, & Apocalypse.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Richard Rhodes is the Pulitzer Prize-winning author of The Making of the Atomic Bomb, and most recently, the author of Energy, A Human History.\n\nBooks mentioned: The Making of the Atomic Bomb, Energy: A Human History\nInteresting ideas discussed:\n\n\nWhether the atomic bomb would have been developed if World War 2 hadn’t occurred\nParallels between the development of the atomic bomb and the current development of AI\nWhether some secret group of scientists could discover and conceal some destructive technology\nThe plausibility of a regional nuclear war between India and Pakistan and the global consequences\nThe possibility of nuclear deterrence without actual nuclear weapons\n\n\nNo discussion of how Rhodes started his career or career advice was found in the transcript.\nNo explicit discussion of Rhodes’ learning process or how he learns was found in the transcript. \n\n\n\nInput tokens: 32022\n\n\nOutput tokens: 216\n\n\nProcessing time: 28.844836950302124 seconds\n\n\nPodcast Word count: 22868\n\n\n'Processed 36/63: Bryan Caplan - Labor Econ, Poverty, & Mental Illness.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based solely on the information provided in the transcript:\n 1. Brian Caplan is an economics professor who has written a book titled “Labor Econ Versus the World”, a collection of his essays from 2005-2022. This is the first in a planned series of eight books compiling his best blog posts from EconLog.\n\nBooks suggested by the guest: Labor Econ Versus the World, Promises I Can Keep, Hitler’s Willing Executioners, Coming Apart, Nickel and Dimed, How to Win Friends and Influence People\nUnique interesting ideas discussed:\n\n\nMost people following the “success sequence” (finishing high school, working full-time, waiting until marriage for kids) can avoid poverty, but many still fail to do so, likely due to lack of impulse control\nCompanies like Google can afford to discriminate in hiring for longer than less successful companies\nSeverely mentally ill people are often very unitary in their behavior and desires rather than conflicted\nMultinational companies are effective in developing countries because they bring productive cultural norms and practices that may go against the local culture\nSince 2000, wages have fallen more for mid-skill than low-skill workers, contrary to the idea that the labor market is bifurcating between those who can and can’t work with computers\n\n\nNo discussion of how the guest started his career or career advice.\nNo discussion of the guest’s learning process or how he learns. \n\n\n\nInput tokens: 17174\n\n\nOutput tokens: 341\n\n\nProcessing time: 31.83338499069214 seconds\n\n\nPodcast Word count: 13481\n\n\n'Processed 37/63: David Deutsch - AI, America, Fun, & Bayes.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:\n 1. Bio of David Deutsch (the guest): David Deutsch is a physicist and philosopher who proposed the “Deutsch’s Algorithm” in quantum computing. He is the author of the book “The Fabric of Reality”.\n\nBooks mentioned by guest: The Fabric of Reality\nUnique interesting ideas discussed:\n\n\nAGIs can in principle have the same range of cognition and intelligence as humans\nHardware limitations on intelligence can be overcome with more memory and speed; software limitations are more fundamental\nSufficiently advanced animal instincts can produce very sophisticated behaviors without requiring creativity\nPhysical pain during exercise can lead to joy rather than suffering\nIt is a mistake to subordinate short-term goals to long-term goals that cannot be error-corrected until much later\nThe relationship between an advice-giver and advice-receiver is a dangerous one of authority\n\n\nNo substantive discussion of how the guest started his career or career advice he provided.\nNo substantive discussion of the guest’s personal learning process or how he learns. \n\n\n\nInput tokens: 16416\n\n\nOutput tokens: 248\n\n\nProcessing time: 21.287183046340942 seconds\n\n\nPodcast Word count: 12529\n\n\n\"Processed 38/63: Holden Karnofsky - History's Most Important Century.txt\"\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:\n 1. Holden Karnofsky is the co-CEO of Open Philanthropy. He originally co-founded the organization GiveWell to help people decide where to give to charity most effectively.\n\nNo books were mentioned by name in the transcript.\nInteresting ideas discussed:\n\n\nThe “most important century” thesis - the idea that if we develop advanced AI systems this century, it could make this the most important century ever for humanity\nBiological anchors and trying to predict AI development timelines based on the computational capacity of the human brain\nThe orthogonality thesis - the idea that an AI system could be highly intelligent in pursuit of any goal, even meaningless or destructive ones\nTrying to develop “future-proof ethics” - moral principles that would still seem valid even if humanity’s ethics progressed significantly in the future\nThe “moral parliament” approach to making decisions under moral uncertainty by considering multiple ethical frameworks\nAI alignment - the challenge of creating AI systems that robustly do what humans want them to do\n\n\nHolden’s career has focused on looking for important ideas and causes that are being neglected where a philanthropic investment could have an outsized impact. He tries to do an initial analysis of important questions no one else has looked at much, then build a team to do further work on them. His key career transitions, from GiveWell to Open Philanthropy to working on risks from advanced AI, have been driven by shifting to new areas he thought were crucially important but not getting enough attention.\nNo explicit discussion of Holden’s personal learning process. \n\n\n\nInput tokens: 34407\n\n\nOutput tokens: 370\n\n\nProcessing time: 39.61585807800293 seconds\n\n\nPodcast Word count: 23822\n\n\n'Processed 39/63: Lars Doucet - Progress, Poverty, Georgism, & Why Rent is Too Damn High.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information requested from the transcript:\n\n\nLars Doucet is a game developer who wrote a review of Henry George’s book Progress and Poverty that won Scott Alexander’s book review contest. The review was expanded into the book “Land is a Big Deal”.\nBooks suggested by the guest: Progress and Poverty by Henry George, Land is a Big Deal by Lars Doucet\nUnique interesting ideas discussed:\n\n\nGeorgism, the economic philosophy that land and natural resources should be commonly owned, with individuals owning the value they produce themselves\nApplying Georgist ideas to virtual real estate and digital economies\nUsing a land value tax to replace other forms of taxation like income and sales taxes\nAccurately assessing land values through mass appraisal techniques\n\n\nThe guest is transitioning from working as a game developer to founding a startup called Geoland Solutions that will work with municipalities to improve property tax assessment using the latest mass appraisal models and technology.\n[No explicit discussion of the guest’s learning process.]\n\n\n\n\nInput tokens: 27870\n\n\nOutput tokens: 250\n\n\nProcessing time: 29.887240886688232 seconds\n\n\nPodcast Word count: 20715\n\n\n'Processed 40/63: Ilya Sutskever (OpenAI Chief Scientist) - Building AGI, Alignment, Spies, Microsoft, & Enlightenment.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Ilya Sutskever is the Co-founder and Chief Scientist of OpenAI.\n\nNo books were suggested by the guest in this podcast.\nUnique interesting ideas discussed:\n\n\nNext-token prediction may be able to create models that surpass human performance by extrapolating how a hypothetical wise, insightful person would behave\nIn a post-AGI future, some people may choose to become part AI in order to expand their minds and understanding to solve society’s hardest problems\nTo achieve alignment, we will need multiple approaches like adversarial testing, interpretability, and keeping the degree of alignment increasing faster than model capabilities\nThe paradigm of large language models and generative AI will go very far, but is unlikely to be the final paradigm that leads to AGI\nHardware is not currently a limitation on AI progress; cost and availability of compute is what matters\nEmergent properties like reliability and controllability may arise as language models get more advanced\n\n\nThe guest did not discuss how he started his career or provide any explicit career advice.\nThe guest said he tries really hard and gives his work everything he’s got, which has worked for him so far. He implied perseverance is necessary but not sufficient for success as a researcher. Having the right way of looking at things is also important. \n\n\n\nInput tokens: 11888\n\n\nOutput tokens: 316\n\n\nProcessing time: 27.0299551486969 seconds\n\n\nPodcast Word count: 7782\n\n\n'Processed 41/63: Marc Andreessen - AI, Crypto, 1000 Elon Musks, Regrets, Vulnerabilities, & Managerial Revolution.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Marc Andreessen is the co-founder of the venture capital firm Andreessen Horowitz (also known as a16z).\n\nBook mentioned: Doing Capitalism by Bill Janeway\nUnique interesting ideas discussed:\n\n\nAI may upend how software applications are built in the next 5 years, changing the fundamental assumptions\nManagers don’t tend to build new things because they lack the training, background, personality, temperament and incentives to do so\nBourgeois capitalism with owner-operators is needed to build new things, while managerial capitalism is prevalent at scale\nBaseball cards and NFTs are a valid part of the economy as a form of art\nThe public follow graph on Twitter should be incredibly valuable for connecting creators and audiences\nTech will continue taking a bigger share of GDP by going after large but less dynamic sectors like education, healthcare, real estate, finance, law, government\nThe current education system, especially universities, are cartels that prioritize other things over teaching marketable skills and doing real research\nVenture capital is overstaffed and overfunded by about 5x according to Andy Rachleff\n\n\nNo substantive discussion of how Marc Andreessen started his career or general career advice.\nNo substantive discussion of Marc Andreessen’s personal learning process. \n\n\n\nInput tokens: 21751\n\n\nOutput tokens: 318\n\n\nProcessing time: 32.03044891357422 seconds\n\n\nPodcast Word count: 14552\n\n\n'Processed 42/63: Brett Harrison - FTX US Former President Speaks Out.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n\n\nBio of the guest: Brett Harrison is the founder of Architect, a company that provides infrastructure for accessing digital asset markets. He was previously the president of FTX US and head of ETF technology at Citadel.\nBooks suggested by the guest: None\nUnique interesting ideas discussed:\n\n\nHaving more passive investing through ETFs is good for individual investors to access diversified instruments at low cost, but could be detrimental by causing correlated activity between instruments included in indices.\nThere are many differences in the specific strategies and niches of different high-frequency trading firms like Jane Street, Citadel, etc.\nIncreasing the speed of information propagation in financial markets is valuable for price discovery and efficient markets overall.\nThe technology developed for high-frequency trading could have other valuable applications beyond finance.\nFTX developed a derivatives exchange with features like unified margin wallets and gradual auto-liquidation that solved pain points in other crypto derivatives exchanges.\nArchitect aims to provide infrastructure for easily accessing and trading across centralized and decentralized crypto venues and custodians.\nDespite the FTX collapse, there is still significant institutional interest in crypto as a large viable asset class needing mature supporting infrastructure.\nBlockchain-based settlement could improve upon the slow and error-prone settlement technology in traditional finance.\n\n\nCareer advice: No explicit career advice was provided.\nLearning process: No explicit discussion of the guest’s learning process.\n\n\n\n\nInput tokens: 35891\n\n\nOutput tokens: 350\n\n\nProcessing time: 38.08158898353577 seconds\n\n\nPodcast Word count: 28548\n\n\n'Processed 43/63: Paul Christiano - Preventing an AI Takeover.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks:\n\n\nPaul Christiano is the head of the Alignment Research Center and previously led the Language Model Alignment team at OpenAI, where he led the invention of RLHF.\nNo specific books were suggested by the guest in this podcast.\nUnique interesting ideas discussed:\n\n\nThe challenges in building aligned AI systems that can be deployed safely and responsibly as they become more capable\nThe difficulty but potential importance of developing heuristic arguments and explanations for AI behavior that could help detect deceptive or misaligned systems\nThe factors influencing AI development timelines and takeoff speeds, including algorithmic progress, hardware constraints, and competitive pressures\nThe potential applications and limitations of heuristic argument verifiers in fields like mathematics, computer science, and alignment\nHow to evaluate the quality and “bullshit detection” of different alignment research approaches\n\n\nNo discussions were included about how Paul started his career or general career advice.\nNo discussions were included about Paul’s personal learning process or tips for how to learn.\n\n\n\n\nInput tokens: 59338\n\n\nOutput tokens: 248\n\n\nProcessing time: 42.23641395568848 seconds\n\n\nPodcast Word count: 40944\n\n\n'Processed 44/63: Sarah Fitz-Claridge - Taking Children Seriously | The Lunar Society #15.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio: Sarah Fitzgerald is a writer, coach and speaker with a fallabilist worldview who started a journal that became Taking Children Seriously in the early 1990s. She has spoken all over the world about her educational philosophy.\n\nBooks suggested: The Beginning of Infinity by David Deutsch (specifically Chapter 16 on The Evolution of Creativity is mentioned)\nUnique interesting ideas discussed:\n\n\nTaking children seriously means not interacting with children coercively, but instead trying to create consent with them and find solutions to problems that don’t involve coercion\nChildren are creative and rational from birth, not at some later stage of development\nThe standard view of children as irrational and needing to be controlled by parents is a mistake, similar to past mistaken views about women and black people\nPlaying video games and watching television can actually be very educational for children\nAnti-rational memes cause people to raise their own children with the same coercive, authoritarian practices that they experienced growing up\n\n\nCareer discussion: Not found in transcript\nLearning process: Not found in transcript \n\n\n\nInput tokens: 11888\n\n\nOutput tokens: 268\n\n\nProcessing time: 22.962816953659058 seconds\n\n\nPodcast Word count: 8930\n\n\n'Processed 45/63: Byrne Hobart - FTX, Drugs, Twitter, Taiwan, & Monasticism.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the podcast transcript:\n 1. Byrne Hobart bio: Byrne Hobart writes at thediff.co. When the podcaster has a question about a concept or event in finance, 9 times out of 10 Byrne’s writings provide the best take on the topic.\n\nBooks mentioned: The Power Broker by Robert Caro, The Years of Lyndon Johnson by Robert Caro, The Economics of World War II, Postwar by Tony Judt, Princess of the Yen, The End of History by Francis Fukuyama\nUnique interesting ideas discussed:\n\n\nThe impact of new drugs on financial markets is underrated. Short-acting vs long-acting stimulants result in different booms (hostile takeovers vs structured products).\nEvery crash can be explained by the common drug in the industry at the time.\nWhen scouting young talent, you over-index for parental involvement. Look for achievements that are illegible or low-status to parents.\nAfter a war or crisis, some institutions and trends show surprising continuity while others break down and reform. Threads of continuity between pre-war and post-war orders are revealing.\nSocieties tend to have safety valves to limit the impact of their most hardcore believers. Effective altruism lacks this segregation.\nThe most successful investors synthesize a big worldview based on philosophy with micro-level quantitative observations. High-level theories identify what’s unsustainable, while low-level indicators reveal when perception will collide with reality.\n\n\nNo direct discussion of how the guest started his career or career advice.\nNo direct discussion of the guest’s specific learning process or how he learns. \n\n\n\nInput tokens: 20238\n\n\nOutput tokens: 406\n\n\nProcessing time: 33.34837627410889 seconds\n\n\nPodcast Word count: 15020\n\n\n'Processed 46/63: Richard Hanania - Foreign Policy, Fertility, and Experts.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information from the transcript:\n 1. Bio: Richard Henania is the president of the Center for the Study of Partisanship and Ideology and the author of the book “Public Choice Theory and the Illusion of Grand Strategy”.\n\nBooks suggested: Public Choice Theory and the Illusion of Grand Strategy\nUnique interesting ideas discussed:\n\n\nGrand strategy in foreign policy is an illusion; a public choice model better explains foreign policy actions\nCountries that are more decentralized and have good institutions for economic growth may have worse foreign policy because of interest group influence\nDecline of war may have allowed political institutions to become more sclerotic\nChina has a more coherent foreign policy than the U.S. because it is not a democracy\nHaving a category of “experts” in fields like criminology or international relations can be harmful by giving certain people with an agenda more legitimacy\nIncreased polarization benefits both wokeness on the left and libertarianism on the right, since they can pass unpopular ideas when their side has power\n\n\nNo information about how the guest started their career or career advice was found in the transcript.\nNo information about the guest’s learning process was found in the transcript. \n\n\n\nInput tokens: 17346\n\n\nOutput tokens: 286\n\n\nProcessing time: 30.215448141098022 seconds\n\n\nPodcast Word count: 13724\n\n\n'Processed 47/63: Tyler Cowen - The Great Reset.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key information from the podcast transcript:\n 1. Bio of guest: Tyler Cowen is an economics professor who co-created the online educational platform Marginal Revolution University. He has authored several books including The Complacent Class and Big Business.\n\nBooks suggested by guest: Stubborn Attachments, The Complacent Class\nUnique interesting ideas discussed:\n\n\nCowen predicted a “Great Reset” crisis in his book The Complacent Class, which he believes the COVID-19 pandemic represents\nHe believes the chance of a nuclear weapon being used in the guest’s lifetime is over 70%\nHe thinks common sense morality has evolved through a kind of group selection to be at least somewhat optimal for society\nBig businesses today are highly productive and innovative, contrary to some popular narratives\nFeminization of society has led to much greater safety but potentially at the cost of some economic dynamism\nCowen is optimistic that the pandemic will lead to great innovations and improvements in biomedicine in the coming years\n\n\nCareer advice:\n\n\nGet at least one really good mentor, preferably two or three\nGet a small group of good friends you love talking to and spending time with\nAfter age 18 is the best time to develop new talents and skills for most fields\n\n\nGuest’s learning process:\n\n\nCowen started learning a lot around age 14 through his late 20s, reading widely from authors with diverse viewpoints\nHe wishes he had learned more math, statistics and computer programming when he was younger\nHe believes his learning rate has slowed down since his late 20s but is still pretty high \n\n\n\nInput tokens: 11003\n\n\nOutput tokens: 379\n\n\nProcessing time: 27.943734884262085 seconds\n\n\nPodcast Word count: 8343\n\n\n'Processed 48/63: Patrick Collison (Stripe CEO) - Craft, Beauty, & The Future of Payments.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested steps based on the transcript:\n 1. Patrick Collison is the CEO and co-founder of Stripe, a global payments company. He co-founded Arc Institute, a biomedical research organization, and was involved with Fast Grants which provided funding for COVID-19 research.\n\nBooks mentioned: 7 Powers by Hamilton Helmer, Apprentice to Genius\nUnique ideas discussed:\n\n\nThe importance of pursuing deep technical expertise over many years to make major scientific breakthroughs, as opposed to the Silicon Valley focus on young founders\nThe potential of functional genomics techniques like CRISPR to enable discoveries about disease mechanisms\nThe efficacy of directly funding scientists to pursue research as opposed to typical grant processes\nThe low-hanging fruit in optimizing business operations now that the economy is becoming more digital\nThe under-appreciated role of established large companies in driving innovation\nThe benefits of working closely with friends and partners on major ventures\n\n\nNo specific discussion of how Patrick started his career or career advice.\nNo specific discussion of Patrick’s personal learning process or how he learns. \n\n\n\nInput tokens: 24019\n\n\nOutput tokens: 259\n\n\nProcessing time: 31.90658402442932 seconds\n\n\nPodcast Word count: 17078\n\n\n'Processed 49/63: Jung Chang (Wild Swans author) - Mao, Cultural Revolution, Great Leap Forward, & Modern CCP.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the transcript:\n 1. Guest bio: Yung Chang is the author of Wild Swans, which has sold over 15 million copies worldwide, and a biography of Mao titled Mao: The Unknown Story. She was born in China in 1952 and grew up under Mao’s rule.\n\nBooks mentioned by the guest: Wild Swans, Mao: The Unknown Story\nUnique interesting ideas discussed:\n\n\nUnder Mao, China was a cultural desert with no books, cinemas or theaters for 10 years during the Cultural Revolution.\nMao used young people’s propensity for violence and destruction during the Cultural Revolution, allowing them to indulge their bad instincts.\nThe key to totalitarian control under Mao was the complete isolation of society from outside information, combined with intense terror.\nMao’s ideology of communism and socialism enabled opportunists like him to take power, as it is highly conducive to their aims.\nMao used criticism and self-criticism meetings as a psychological weapon to break people, humiliate them, and turn them against each other.\n\n\nThe guest started her writing career in exile in Britain, after wanting to be a writer since childhood but being unable to under Mao’s regime. She worked as a peasant, barefoot doctor, steelworker and electrician in China while “writing in her head”. After coming to Britain, she wrote down her mother’s life stories which became her hugely successful first book Wild Swans.\nNo explicit discussion of the guest’s learning process was found in the transcript. \n\n\n\nInput tokens: 15745\n\n\nOutput tokens: 379\n\n\nProcessing time: 31.04735779762268 seconds\n\n\nPodcast Word count: 12351\n\n\n'Processed 50/63: Scott Young - Ultralearning, The MIT Challenge.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my analysis of the podcast transcript:\n 1. Guest bio: Scott Young is the author of the book Ultralearning: Accelerate Your Career, Master Hard Skills, and Outsmart the Competition. He completed the MIT challenge, attempting to learn MIT’s 4-year computer science curriculum in one year, and has done ultralearning projects learning multiple languages.\n\nBooks mentioned: Invention of Science by David Wootton, How to Become a Straight-A Student by Cal Newport, Ultralearning by Scott Young\nInteresting ideas discussed:\n\n\nWhether people who achieve remarkable feats in a short period of time (like Einstein’s “miracle year”) do so because their productivity is concentrated or due to a selection effect\nThe “failed simulation effect” - people find things more impressive when they can’t easily simulate doing it themselves in their head\nHow the speedrunning community has accelerated innovation by requiring video proof of record runs, allowing others to study and learn from the best\nWhether activities like meditation and cutting out distractions can truly expand one’s ability to focus, or if focus is domain-specific\nAdvice for ambitious young people to pursue innovative projects and build up knowledge/skills rather than prematurely optimizing for making money\n\n\nCareer advice: Scott recommends that talented, hardworking young people pursue ambitious, innovative projects to build up their skills and knowledge, rather than prematurely trying to monetize or optimize for short-term rewards and social status. He says you should aim to increase the quality of problems you can work on when you’re older by investing in yourself when you’re young.\nScott’s learning process: Scott focuses more on understanding than memorization when learning, as he believes it leads to better retention and transfer to other domains. He immerses himself in a field to develop chunked patterns and an intuitive understanding. \n\n\n\nInput tokens: 26208\n\n\nOutput tokens: 414\n\n\nProcessing time: 36.75805592536926 seconds\n\n\nPodcast Word count: 20748\n\n\n'Processed 51/63: Jason Crawford - The Roots of Progress & the History of Technology.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key points from the transcript:\n 1. Jason Crawford is a former startup founder who now writes at The Roots of Progress, where he researches and writes about the history of technology and industry, and the philosophy of progress. He aims to educate people on how the modern world and high standard of living was created in recent centuries through science, technology, and industry.\n\nNo books were explicitly suggested by the guest in this podcast.\nSome of the unique ideas discussed:\n\n\nOver the last 200-250 years, there has been an unprecedented improvement in living standards and technological progress compared to the thousands of years prior. Understanding the causes of this progress and how to sustain it is crucial.\nProgress in science, technology, and morality/government institutions are all intertwined. The Scientific Revolution, Industrial Revolution, and rise of democratic republics all happened around the same time period and were mutually reinforcing.\nThe common linear model of innovation oversimplifies the complex back-and-forth between science and technology. New inventions often precede the scientific understanding of how they work.\nWhen evaluating the risks and downsides of progress and complex systems, the solution is not to slow down progress but to reallocate resources to also prioritize safety, resilience, and protections against shocks.\nIt’s valuable to distinguish between descriptive optimism (predicting what will likely happen) and prescriptive optimism (being determined to work hard to create a better future, regardless of the odds).\n\n\nThe guest did not discuss in detail how he started his career or provide general career advice.\nThe guest did not discuss his own learning process or provide advice on how to learn. \n\n\n\nInput tokens: 11935\n\n\nOutput tokens: 382\n\n\nProcessing time: 29.660333156585693 seconds\n\n\nPodcast Word count: 9126\n\n\n'Processed 52/63: Uncle Bob - The Long Reach of Code, Automating Programming, and Developing Coding Talent.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the requested information from the transcript:\n 1. Robert Martin is a long-time programmer who has worked in the field for around 50 years.\n\nBooks mentioned: The Joy of Java, Java for Dummies in 10 Days, Learn C in 21 Days\nUnique ideas discussed:\n\n\nTrue AI that could automate programming is very far away, as it would require human-level sentience\nProgramming should be taught more as a trade skill than a 4-year university degree\nAround 1-10% of the population likely has the aptitude to become programmers\nThere are correlations between programming skill and musical ability\nThe software industry needs some sort of licensing body to ensure programmers have proper ethics and standards, similar to other critical professions like doctors\nQuotas and lowering standards for diversity reasons can be detrimental and demoralizing\nThere are no great quick tests to assess programming aptitude in interviews; it requires observing someone learning and applying skills over weeks\n\n\nCareer advice:\n\n\nTake advantage of free online resources and books to learn programming languages and skills\nFind a mentor who can teach and guide you\nConsider trade schools or apprenticeship programs over expensive university degrees\nConstantly read, study, watch videos and do exercises to learn\n\n\nThe guest did not directly discuss his own learning process or techniques in this interview. \n\n\n\nInput tokens: 9628\n\n\nOutput tokens: 319\n\n\nProcessing time: 24.402140140533447 seconds\n\n\nPodcast Word count: 7366\n\n\n'Processed 53/63: Sarah C. M. Paine - WW2, Taiwan, Ukraine, & Maritime vs Continental Powers.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based on the transcript:\n 1. Bio: Sarah Paine is a professor of strategy and policy at the Naval War College who has written several highly regarded books on military history.\n\nBooks suggested by guest: Wars for Asia by Sarah Paine, The Japanese Empire by Sarah Paine, Expeditionary Warfare (co-edited book by Sarah Paine and Bruce A. Elleman), Commerce Rating and Blockades (co-edited book by Sarah Paine and Bruce A. Elleman), How Asia Works by Joseph Studwell\nUnique interesting ideas discussed:\n\n\nThe importance of coordinating all instruments of national power (e.g. military, economic, diplomatic) in grand strategy\nThe Iron Law of Nazi Conquest: That Hitler would have annihilated non-Aryan peoples in Europe if the Third Reich had survived\nThat Japan’s decision to attack Pearl Harbor and go to war with the U.S. was a pivotal error that led to its downfall\nThe fundamental differences between continental powers (like Russia and China) and maritime powers (like the U.S. and Britain) in their strategic outlook and goals\nCommunism’s ability to take power in failing states and impose a dictatorship, but its inability to deliver prosperity afterwards\nThe huge negative economic consequences if China invades Taiwan and destroys wealth there\nThe need for tech companies and leaders to think deeply about whether the technologies they develop will ultimately privilege dictatorships or democracies\n\n\nCareer advice:\n\n\nIt’s essential for historians to extensively read primary sources and materials in the languages of the countries they are studying\nPublishing frequently is important as an academic to convey ideas and be forced to really crystallize one’s thinking\nLiving abroad and asking questions of locals while doing archival research provides valuable perspective\n\n\nGuest’s learning process:\n\n\nReading very widely and extensively over an entire academic career\nTaking as many graduate courses as possible to be exposed to the key ideas and readings in a field\nAttending lectures by colleagues in different specialties and learning from their expertise\nCo-editing books on unfamiliar topics (like naval warfare) to gain knowledge in new areas\nKeeping an open mind, constantly looking for unknown unknowns, and being willing to reassess previous views \n\n\n\nInput tokens: 34304\n\n\nOutput tokens: 519\n\n\nProcessing time: 46.30790305137634 seconds\n\n\nPodcast Word count: 22921\n\n\n'Processed 54/63: Sam Bankman-Fried - Crypto, FTX, Altruism, & Leadership.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Sam Bankman-Fried is the CEO of FTX, a cryptocurrency derivatives exchange. He also ran the quantitative trading firm Alameda Research.\n\nNo books were suggested by the guest in this podcast.\nUnique interesting ideas discussed:\n\n\nThere are lots of inefficiencies and low-hanging opportunities in the world, especially in crypto markets\nStarting something new is brutal and requires a specific but extensive set of skills\nThe experience level of people hired has surprisingly little correlation with how much mentorship they need\nWhen companies grow really fast and large, they often become an absolute mess internally with diffusion of responsibility\nStablecoins and blockchains becoming important settlement mechanisms is likely, and more assets will become tokenized\nHaving the exchange and broker as the same entity can help provide a better customer experience despite some conflicts of interest\n\n\nCareer advice and how the guest started his career:\n\n\nSam was advised by Will MacAskill to earn-to-give by working at a quant trading firm, which was helpful advice at the time\nHowever, Sam thinks people are advised too strongly to take safe career paths, especially from an altruistic perspective\nSam believes he would have had a decent chance of becoming a billionaire even if he had to start over in a different field than crypto\nThe most important traits for founders are the willingness to do grunt work and put your heart and soul into the idea\n\n\nNo significant discussion of the guest’s learning process was found in the transcript. \n\n\n\nInput tokens: 10138\n\n\nOutput tokens: 354\n\n\nProcessing time: 28.26761484146118 seconds\n\n\nPodcast Word count: 6727\n\n\n'Processed 55/63: Garett Jones - Immigration, National IQ, & Less Democracy.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based solely on the information provided in the transcript:\n 1. Garrett Jones is an economist at George Mason University and author of The Culture Transplant: How Migrants Make the Economies They Move To a Lot Like the Ones They Left, 10% Less Democracy, and Hive Mind.\n\nBooks suggested by the guest: The Culture Transplant: How Migrants Make the Economies They Move To a Lot Like the Ones They Left, 10% Less Democracy, Hive Mind, The Myth of the Rational Voter, Wretched Refuse?\nUnique interesting ideas discussed:\n\n\nNational average IQ is a strong predictor of national productivity, and variance in IQ (with more high IQ people) could be beneficial\nMigrants bring cultural values from their origin countries which can impact institutions in their new countries over time\nIndependent government institutions like the Federal Reserve function better than more democratically controlled ones like the FDA\nMormon culture’s high trust and social cohesion stem from selection effects in its early pioneer history\nSmart people are more cooperative in repeated interactions out of Machiavellian self-interest, not inherent pro-sociality\n\n\n\n\n\n\n\n\nInput tokens: 17350\n\n\nOutput tokens: 288\n\n\nProcessing time: 27.13167691230774 seconds\n\n\nPodcast Word count: 11534\n\n\n'Processed 56/63: Tyler Cowen - Why Society Will Collapse & Why Sex is Pessimistic.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at summarizing the key points from the transcript:\n 1. Bio of the guest: Tyler Cowen is an economist, blogger, and author who has written numerous books. He runs the Emergent Ventures grant program to fund talented individuals.\n\nBooks suggested by the guest: No specific book titles were mentioned.\nUnique interesting ideas discussed:\n\n\nThe existence of sex is a pessimistic sign that species don’t survive for long\nBiographies often mischaracterize their subjects compared to actually knowing them\nMany “intellectual dark web” figures made big bets on particular ideas that are losing steam\nTravel provides a lot of context that can make you more skeptical of history books\nMany top athletes are extraordinarily smart and cognitively intense\nTalent is very geographically clustered in places like London and New York\nA major war with nuclear weapons could permanently set back human civilization\nWriting is a form of thinking, and companies like Amazon have writing-centric cultures\n\n\nGuest’s career advice:\n\n\nBe willing to show bravery and openness rather than false humility\nFind ways to take more career risks; lead by example in doing so\nWriting and blogging consistently over many years builds influence\nFocus on boosting people’s strengths rather than reforming their weaknesses\n\n\nGuest’s learning process:\n\n\nReading biographies and following the careers of athletes and chess players to learn lessons about perseverance and self-improvement\nPreferring travel to reading books as a way to learn new things and get context\nTeaching others informally how to do things like start a podcast or write a blog to help them take risks and learn \n\n\n\nInput tokens: 24166\n\n\nOutput tokens: 377\n\n\nProcessing time: 34.69293808937073 seconds\n\n\nPodcast Word count: 18758\n\n\n'Processed 57/63: George Hotz vs Eliezer Yudkowsky AI Safety Debate.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Eliezer Yudkowsky is a philosopher and artificial intelligence researcher known for writing the book “Harry Potter and the Methods of Rationality”.\n\nAtlas Shrugged, Harry Potter and the Methods of Rationality\nUnique ideas discussed:\n\n\nWhether artificial general intelligence (AGI) will “foom” or recursively self-improve at an exponential rate once it reaches a critical level\nWhether AGIs will be motivated to cooperate with each other or fight each other for resources\nWhether humanity can maintain control over advanced AI systems or will be wiped out by them\nThe difficulty of aligning the goals of superintelligent AI with human values\nThe computational efficiency of the human brain compared to current supercomputers\nSolving the prisoner’s dilemma and whether rational agents will cooperate or defect\n\n\n[The transcript does not contain any substantive discussion of how Eliezer Yudkowsky started his career or career advice he provided.]\n[The transcript does not contain any substantive discussion of Eliezer Yudkowsky’s personal learning process or how he learns.] \n\n\n\nInput tokens: 21492\n\n\nOutput tokens: 275\n\n\nProcessing time: 24.04459810256958 seconds\n\n\nPodcast Word count: 16625\n\n\n'Processed 58/63: Alexander Mikaberidze - Napoleon, War, Progress, and Global Order.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio of the guest: Alexander Mikaberidze is a professor of history and the Ruth Herring Noel Endowed Chair at Louisiana State University, and the author of the book “The Napoleonic Wars: A Global History”.\n\nBooks mentioned by the guest: The Napoleonic Wars: A Global History\nUnique interesting ideas discussed:\n\n\nThe Napoleonic Wars had a significant impact on India, laying the foundation for the British Raj\nThe Napoleonic Wars saw France able to mobilize greater manpower and resources than the old regime powers it was fighting\nNapoleon represented the last of the “enlightened despots” who used authoritarian means to bring about modernization and reform\nThe war forced countries to become more meritocratic and allowed talented young people to rise up the ranks quickly\n\n\nGuest’s career path/advice: Not discussed in the transcript.\nGuest’s learning process: Not discussed in the transcript. \n\n\n\nInput tokens: 17152\n\n\nOutput tokens: 235\n\n\nProcessing time: 21.725136756896973 seconds\n\n\nPodcast Word count: 13094\n\n\n'Processed 59/63: Alex Tabarrok - Prizes, Prices, and Public Goods.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt to extract the requested information from the transcript:\n 1. Alex Tabarrok is the Bartley J. Madden Chair of Economics at the Mercado Center and a professor of economics at George Mason University. He is also the co-author of the popular Marginal Revolution blog with Tyler Cowen.\n\nBooks suggested by the guest: Launching the Innovation Renaissance\nUnique interesting ideas discussed:\n\n\nA “grand innovation prize” to incentivize rapid development of vaccines and treatments during a pandemic\nBaumol’s cost disease to explain rising costs in healthcare, education, and other “stagnant” sectors\nOnline education scaling up with the best teachers serving many more students\nDominant assurance contracts to help solve public goods problems\nChina’s rise and competition with the US spurring more innovation and a shift to an “innovation state”\n\n\nCareer advice:\n\n\nGet educated in a sector complementary to technology, like computer science, electrical engineering, data science, or even design, rather than competing against technology\nCombining an artistic impulse with a technological field can be very valuable\nSkills in extracting meaning from data and making it accessible to people will be increasingly in demand\n\n\nThe guest did not discuss his own learning process in the transcript. \n\n\n\nInput tokens: 19281\n\n\nOutput tokens: 291\n\n\nProcessing time: 26.35242199897766 seconds\n\n\nPodcast Word count: 14865\n\n\n'Processed 60/63: Michael Huemer - Anarchy, Capitalism, and Progress.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at extracting the requested information from the transcript:\n 1. Bio: Michael Huemer is a professor of philosophy at the University of Colorado. He has written more than 70 academic articles and 8 books on epistemology, ethics, meta-ethics, metaphysics, and political philosophy.\n\nBooks suggested by guest: The Fountainhead, Time and Chance by David Albert, The Cosmic Landscape, The Myth of the Rational Voter\nUnique interesting ideas discussed:\n\n\nThe government shouldn’t have special moral authority to coerce citizens in ways individuals can’t\nSocieties have made tremendous moral progress over time, and this is driven by a small number of reformers\nFactory farming causes immense animal suffering on a scale larger than all human suffering in history\nAdvances in technology could lead to destructive weapons that threaten human extinction, which may require strong state monitoring of individuals\nPeople should apply the same moral standards to governments that they apply to individuals\n\n\nCareer advice:\n\n\nThe keys to happiness are having solid meaningful relationships and doing meaningful work you enjoy that pays the bills\nBuy a house if you’ll be living somewhere for a few years because it’s a good investment\nInvest money in index funds rather than trying to beat the market\n\n\nGuest’s learning process:\n\n\nGoing through a PhD program teaches you valuable skills like thoroughly researching a topic, considering objections and alternatives, and modifying your views\nThe guest would probably be worse at philosophy if he had not gone through grad school training, although this could partly be a selection effect rather than just the training \n\n\n\nInput tokens: 21908\n\n\nOutput tokens: 361\n\n\nProcessing time: 31.41848397254944 seconds\n\n\nPodcast Word count: 16978\n\n\n'Processed 61/63: David Friedman - Dating Markets, Legal Systems, Bitcoin, and Automation.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at the requested information from the podcast transcript:\n 1. Bio: Dr. David Friedman is an economist, legal scholar, and author, most recently of the book “Legal Systems Very Different from Ours”. He is the son of Nobel Prize winning economist Milton Friedman.\n\nBooks mentioned: Legal Systems Very Different from Ours, The Machinery of Freedom (3rd edition), Future Imperfect, Price Theory textbook\nUnique interesting ideas discussed:\n\n\nWhy online dating hasn’t improved matching compared to traditional arranged marriages\nHow cryptocurrencies and strong encryption could enable private law enforcement via reputational mechanisms rather than geographic monopoly\nA positive theory for the origin of property rights based on game theoretic commitment strategies\nHow coalitions in traditional Somali law form a nested, recursive structure to provide legal protection in proportion to power\nThe possibility that automation will produce greater wealth inequality but not necessarily make the poor worse off in an absolute sense\nThe economic efficiency of gift cultures in certain situations\n\n\nCareer discussion: Dr. Friedman started out getting a PhD in physics but left the field because it was overpopulated with high IQ people, making it harder to contribute. He became an economist instead where he felt he could be smarter than more people and say more original things.\nLearning process: Not directly discussed, though Dr. Friedman reads widely, processes ideas and writes on his blog, and engages in discussion with other intellectuals online and at conferences to refine his thinking on various topics. He relies on both systematic analysis and intuition. \n\n\n\nInput tokens: 18718\n\n\nOutput tokens: 358\n\n\nProcessing time: 31.18577480316162 seconds\n\n\nPodcast Word count: 14668\n\n\n'Processed 62/63: Steve Hsu - Intelligence, Embryo Selection, & The Future of Humanity.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my attempt at completing the requested tasks based on the transcript:\n 1. Steve Hsu is a theoretical physicist turned entrepreneur who founded the genomic prediction company Genomic Prediction.\n\nNo specific book titles were mentioned in the transcript.\nUnique interesting ideas discussed:\n\n\nPhysicists often transition into other fields like finance and genomics because their mathematical and data analysis skills transfer well\nGenetic architecture of most traits is surprisingly simple and additive, allowing prediction and selection of embryos for traits like height, disease risk, and cognitive ability\nIn the future, stem cell and gene editing technology may allow selection from hundreds of embryos or direct editing to enhance traits\nElite universities provide strong career advantages through peer groups, social connections, and awareness of elite career paths\n\n\nSteve Hsu transitioned from theoretical physics into genomics and founding the company Genomic Prediction. He recognized the potential of applying mathematical and AI/ML tools to genomic data for trait prediction.\nAs a physicist, Hsu learned to work with messy, real-world data and deeply understand both the theoretical models and the actual data to resolve any mismatches. Physicists routinely have to deeply engage with the systems they work with. \n\n\n\nInput tokens: 34431\n\n\nOutput tokens: 277\n\n\nProcessing time: 34.868486166000366 seconds\n\n\nPodcast Word count: 26785\n\n\n'Processed 63/63: Jimmy Soni - Peter Thiel, Elon Musk, and the Paypal Mafia.txt'\n\n\n'****************************************************************************************************'\n\n\nHere is my summary of the key information from the podcast transcript:\n 1. Bio of guest: Jimmy Soni is the author of several books including biographies of Cato, Claude Shannon, and most recently a book called The Founders about the story of PayPal and the entrepreneurs who shaped Silicon Valley.\n\nBooks suggested by guest: The Idea Factory by John Gertner, Founding Brothers (about US founding fathers), Wanting by Luke Burgess\nUnique interesting ideas discussed:\n\n\nComparing the innovation environments of Bell Labs with Claude Shannon vs the early PayPal team\nDiscussing Girardian mimetic elements and anti-mimesis in the history of PayPal\nDebating whether Zero to One principles espoused by Peter Thiel were followed or contradicted in the actual early history of PayPal\nPondering what highly ambitious people like Elon Musk, Peter Thiel or Napoleon would do in a pre-capitalist society\nDiscussing why the “PayPal mafia” pursued separate ventures after PayPal rather than starting another company together\n\n\nGuest’s career path: Jimmy Soni previously worked as Managing Editor of the Huffington Post which involved fast-paced daily news and social media. He then transitioned to spending 5-6 years deeply researching and writing a single book, which he finds much more fulfilling. His dream would be to spend 10 years on a book.\nGuest’s learning process: Jimmy Soni spends years exhaustively researching a book topic, poring through historical documents and press releases to find small insights. He finds the process of making tiny discoveries that shed light on the full picture to be thrilling. He tries to approach projects by asking what writers he admires like Robert Caro would do. \n\n\n\nInput tokens: 17968\n\n\nOutput tokens: 406\n\n\nProcessing time: 33.922861099243164 seconds\n\n\nPodcast Word count: 14027\n\n\n\nimport pandas as pd\n\n# Convert the results dictionary to a DataFrame\ndf_stats = pd.DataFrame.from_dict(results, orient='index', \n                            columns=['Processing Time (s)', 'Word Count', 'Input Tokens', 'Output Tokens', 'Result'])\n\n# Display the DataFrame\ndisplay(df_stats)\n\n\n\n\n\n\n\n\nProcessing Time (s)\nWord Count\nInput Tokens\nOutput Tokens\nResult\n\n\n\n\nAnanyo Bhattacharya - John von Neumann, Jewish Genius, and Nuclear War.txt\n24.720909\n8463\n11108\n296\nHere is my attempt at completing the specified...\n\n\nSholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind.txt\n48.144148\n31262\n46658\n428\nHere is my response based on the information p...\n\n\nBrian Potter - Future of Construction, Ugly Modernism, & Environmental Review.txt\n35.006452\n27475\n34310\n261\nHere is my summary of the key information requ...\n\n\nWill MacAskill - Longtermism, Effective Altruism, History, & Technology.txt\n27.399938\n11151\n14302\n311\nHere is a summary of the requested information...\n\n\nDario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & Alignment.txt\n33.300031\n19829\n28815\n328\nHere is my attempt at completing the requested...\n\n\n...\n...\n...\n...\n...\n...\n\n\nAlex Tabarrok - Prizes, Prices, and Public Goods.txt\n26.352422\n14865\n19281\n291\nHere is my attempt to extract the requested in...\n\n\nMichael Huemer - Anarchy, Capitalism, and Progress.txt\n31.418484\n16978\n21908\n361\nHere is my attempt at extracting the requested...\n\n\nDavid Friedman - Dating Markets, Legal Systems, Bitcoin, and Automation.txt\n31.185775\n14668\n18718\n358\nHere is my attempt at the requested informatio...\n\n\nSteve Hsu - Intelligence, Embryo Selection, & The Future of Humanity.txt\n34.868486\n26785\n34431\n277\nHere is my attempt at completing the requested...\n\n\nJimmy Soni - Peter Thiel, Elon Musk, and the Paypal Mafia.txt\n33.922861\n14027\n17968\n406\nHere is my summary of the key information from...\n\n\n\n\n63 rows × 5 columns\n\n\n\n\n# merge the two dataframes\n# Merge the two dataframes on the filename column\nmerged_df = pd.merge(df, df_stats, left_on='File Name', right_index=True)\n\n# Reorder the columns\nmerged_df = merged_df[['File Name', 'date_published', 'duration', 'duration_in_minute', 'Processing Time (s)', 'Word Count', 'Input Tokens', 'Output Tokens', 'Result']]\n\n# Display the merged DataFrame\ndisplay(merged_df)\n\n\n\n\n\n\n\n\nFile Name\ndate_published\nduration\nduration_in_minute\nProcessing Time (s)\nWord Count\nInput Tokens\nOutput Tokens\nResult\n\n\n\n\n0\nSholto Douglas & Trenton Bricken - How to Buil...\n2024-03-28\n11593\n193.216667\n48.144148\n31262\n46658\n428\nHere is my response based on the information p...\n\n\n1\nDemis Hassabis - Scaling, Superhuman AIs, Alph...\n2024-02-28\n3694\n61.566667\n27.644215\n11395\n17087\n303\nHere is my attempt at completing the requested...\n\n\n2\nPatrick Collison (Stripe CEO) - Craft, Beauty,...\n2024-02-21\n6931\n115.516667\n31.906584\n17078\n24019\n259\nHere is my attempt at completing the requested...\n\n\n3\nTyler Cowen - Hayek, Keynes, & Smith on AI, An...\n2024-01-31\n6142\n102.366667\n30.989137\n18829\n28844\n243\nHere is my attempt at the requested informatio...\n\n\n4\nJung Chang (Wild Swans author) - Mao, Cultural...\n2023-11-29\n5475\n91.250000\n31.047358\n12351\n15745\n379\nHere is my attempt at the requested informatio...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n58\nRobin Hanson - The Long View and The Elephant ...\n2020-08-31\n6029\n100.483333\n32.861002\n19118\n24464\n338\nHere is my attempt at completing the requested...\n\n\n59\nJason Crawford - The Roots of Progress & the H...\n2020-08-25\n2918\n48.633333\n29.660333\n9126\n11935\n382\nHere is my attempt at summarizing the key poin...\n\n\n60\nMatjaž Leonardis - Science, Identity and Proba...\n2020-08-21\n2073\n34.550000\n25.074347\n6561\n8299\n345\nHere is my response based on the information i...\n\n\n61\nTyler Cowen - The Great Reset.txt\n2020-07-10\n2801\n46.683333\n27.943735\n8343\n11003\n379\nHere is my attempt at summarizing the key info...\n\n\n62\nBryan Caplan - Nurturing Orphaned Ideas, Educa...\n2020-05-22\n3432\n57.200000\n20.041724\n11571\n14490\n260\nHere is my attempt at completing the requested...\n\n\n\n\n63 rows × 9 columns\n\n\n\n\nmerged_df.to_csv(\"podcast_analysis.csv\")\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "",
    "text": "Voyage Vista\n# !pip install selenium\n# !pip install webdriver-manager\n# !pip install fpdf\n# !pip install python-telegram-bot\n# !pip install nest_asyncio\nImagine a tool that transforms your morning routine into a seamless experience, where the latest updates on generative AI, large language models (LLMs), OpenAI, and more are delivered directly to you, not through the usual scrolling and searching, but through a personalized audio news briefing. This innovative project does just that. It autonomously navigates through your Twitter, Reddit, GitHub, and other websites, capturing screenshots as it scrolls through the feeds. These images are then analyzed to curate news content that aligns with your interests.\nThe magic doesn’t end there. This curated content is converted into an audio format and accompanying text documents with source urls, which are then sent to your Telegram. As you sip your morning coffee, you can listen to the latest developments in your fields of interest. If a particular story piques your curiosity, you can delve deeper by exploring the links provided. This not only saves you time but also ensures you’re always informed about the topics that matter to you. Gone are the days of manually sifting through various accounts for relevant news. Now, your custom news comes to you, allowing you to start your day informed and inspired.\nIn this blog post, I go through the different components and technologies I used to build this project."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#interesting-projects",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#interesting-projects",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Interesting Projects",
    "text": "Interesting Projects\n\nWhisper’s Performance Leap\nOne of the notable advancements that caught the attention of the AI community is the improvement in OpenAI’s Whisper model. Whisper, known for its robust speech-to-text capabilities, has seen a significant boost in performance with the introduction of Speculative Decoding. The processing time for transcribing audio has been nearly halved from 73 seconds to 33 seconds without any drop in accuracy. This enhancement is a testament to OpenAI’s commitment to pushing the boundaries of AI efficiency.\n\n\nGPT Store and Custom GPTs\nOpenAI’s GPT Store has been a hot topic, especially with the introduction of actions to custom GPTs. While some users have expressed concerns about the utility of most GPTs available in the store, others have shared advanced tutorials on how to improve GPTs by incorporating actions. This feature allows developers to rank higher and potentially monetize their custom GPTs, adding a new dimension to AI’s commercial viability.\n\n\nAI Hardware Innovations\nThe AI hardware space is also experiencing disruption, with companies like Humane raising significant funds and OpenAI reportedly raising $1 billion for the development of the “aiPhone.” These developments indicate a shift towards AI-integrated devices that could redefine user interactions with technology.\n\n\nAI and Copyrighted Material\nA contentious issue that has emerged is the use of copyrighted materials in training AI models. OpenAI has acknowledged the challenge of creating effective AI tools like ChatGPT without such materials. This has sparked a debate on the ethical and legal implications of AI development, with calls for proper consent and compensation for copyright holders.\n\n\nOpenAI’s Diverse Team\nOpenAI’s diverse team composition has also been a subject of discussion, with the bulk of the team being in their 30s, 40s, and 50s. This diversity is seen as a strength, bringing a wealth of experience and perspectives to the organization’s mission of ensuring that artificial general intelligence benefits all of humanity."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#community-reactions",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#community-reactions",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Community Reactions",
    "text": "Community Reactions\n\nGPT-4 Usage Caps and DALL-E Output\nOn platforms like Reddit, users have been vocal about their experiences with OpenAI’s services. Some have noticed tighter usage caps on ChatGPT-4, leading to quicker exhaustion of their allocated resources. Others have inquired about the impact of GPT Plus subscriptions on the speed and quality of DALL-E outputs.\n\n\nImplementing RAG on Document Corpora\nThe community has also been seeking best practices for implementing Retrieval-Augmented Generation (RAG) on document corpora with wide-ranging topics. This highlights the growing interest in leveraging OpenAI’s models for complex information retrieval tasks.\n\n\nGPT Store’s Selection Process\nCriticism has been directed at the GPT Store’s selection process, with some users pointing out a lack of vision in featuring unique and useful GPTs. The community has called for a more thoughtful curation process that prioritizes quality and utility over quantity.\n\n\nGPT Auth - Authentication for Custom GPTs\nAn interesting project shared by a community member is GPT Auth, which provides authentication and analytics for custom GPTs. This tool aims to help developers track users and queries, ensuring better management of their AI services.\n\n\nChatGPT, GPT-4, and Assistant API Distinctions\nThere’s a growing curiosity about the differences between ChatGPT, GPT-4, and the Assistant API. While GPT-4 is the core language model, ChatGPT and the Assistant API are seen as specialized workflows built around it, each with its unique capabilities and use cases."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#conclusion",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#conclusion",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Conclusion",
    "text": "Conclusion\nOpenAI continues to be at the forefront of AI research and development, with its projects and updates sparking lively discussions and debates within the tech community. From performance improvements in models like Whisper to the ethical considerations of using copyrighted materials, OpenAI’s work is shaping the future of AI and its integration into our daily lives. As the community engages with these advancements, it’s clear that OpenAI’s mission to benefit all of humanity through AI is a journey that many are keen to be a part of."
  },
  {
    "objectID": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#message-2-create-a-word-document",
    "href": "posts/personalised-news-social-media-openai-assistants-api/news_assistant_tools.html#message-2-create-a-word-document",
    "title": "Morning with Jarvis: Craft Your Own News Universe from Social Media and News Digests",
    "section": "Message 2: Create a word document",
    "text": "Message 2: Create a word document\nI am creating one more assistant specialised in creating word documents.\nThe main reason is, I tried to use the same previous assistant to create word document, but it did not return any file in the annotations.\n\nassistant_doc = client.beta.assistants.create(\n    name=\"News Word Document Creater Assistant\",\n    instructions=\"\"\"You are a helpful assistant that creates word document with the full news along with their urls for read more\n    Do not miss any information.\n    \"\"\",\n    tools=[{\"type\":\"code_interpreter\"}],\n    model=\"gpt-4-1106-preview\",\n\n)\n\n\n# new message\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Create a word document with the news content and their urls. Save the file as news.docx\"\n)\n\n\nmessages = run_assistant(assistant_doc.id, thread.id)\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: in_progress\n\n\nStatus: completed\n\n\nThe news content has been compiled into a Word document, and the file news.docx has been saved. You can download it from the link below:\nDownload news.docx\n\n\n\nfile_id = messages.data[0].content[0].text.annotations[0].file_path.file_id\n\n\ndef write_file_to_temp_dir(file_id, output_path):\n    file_data = openai.files.content(file_id)\n    file_data_bytes = file_data.read()\n    with open(output_path, \"wb\") as file:\n        file.write(file_data_bytes)\n\nnews_file = 'news.docx'\n\nwrite_file_to_temp_dir(file_id, news_file)"
  },
  {
    "objectID": "posts/anthropic-claude3-industry-usecases/real_estate.html",
    "href": "posts/anthropic-claude3-industry-usecases/real_estate.html",
    "title": "Claude3 + Python: Automate Real Industry Workflows Like a Pro",
    "section": "",
    "text": "In this project, we will explore how artificial intelligence can be leveraged to streamline and enhance various aspects of the real estate industry. We will focus on two key areas: property appraisal and event newsletter generation.\nThrough this project, you will learn:\n\nProperty Appraisal with AI:\n\nHow to utilize AI models like Anthropic’s Claude to generate detailed and comprehensive property appraisals based on textual descriptions.\nTechniques for incorporating visual information by processing and encoding property images to provide more context to the AI model.\nAdapting the AI-generated appraisals to suit specific markets, such as the Australian real estate market.\n\nEvent Newsletter Generation with AI:\n\nLeveraging AI to create engaging and personalized newsletters for real estate events.\nTechniques for structuring prompts to guide the AI model in generating event-specific content, including catchy marketing slogans for featured properties.\nCustomizing the newsletter generation process to highlight the unique features of each property in relation to the event theme.\n\nStreamlit App Development:\n\nBuilding an interactive web application using the Streamlit framework to showcase the AI-powered property appraisal and newsletter generation functionalities.\nDesigning a user-friendly interface that allows users to input property descriptions, upload images, and generate appraisals and newsletters with ease.\nIntegrating the AI models seamlessly into the Streamlit app for a smooth user experience.\n\n\nBy the end of this project, you will have gained practical knowledge and hands-on experience in applying AI techniques to automate and enhance property appraisal and event newsletter creation. You will also have developed a functional Streamlit app that demonstrates the power of AI in the real estate domain.\nLet’s dive in and explore how AI can revolutionize the way we approach property appraisal and event marketing in the real estate industry!\n\nProject 1: Property Appraisal\n\n# %pip install anthropic --upgrade\n# Install required libraries\n# %pip install streamlit\n# %pip install anthropic\n# %pip install python-dotenv\n# %pip install Pillow\n\n\nimport os\nimport anthropic\nfrom dotenv import load_dotenv\n\n# Load API keys from .env file\nload_dotenv()\nanthropic.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\nclient = anthropic.Anthropic()\n\n\ndef summarize_text(text):\n    import anthropic\n    prompt = f\"Please provide a detailed (approx 1000 words) and comprehensive property appraisal suitable for the Australian market based on the following information, using placeholders for the values:\\n\\n{text}\"\n    # Generate a summary using Claude model\n    response = client.messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are an intelligent property appraiser with expertise in the Australian real estate market. Your goal is to write detailed and comprehensive property appraisals.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    return response\n\n\nproperty_description = \"\"\"\n\nThis property is a modern, two-story residential home located in a quiet, suburban neighborhood in Melbourne, Australia.\n Built in 2015, it features 4 bedrooms, 2 bathrooms, and an open-plan living area.\n The 180 sq. m. house sits on a 600 sq. m. lot with a landscaped garden, a patio, and a single-car garage.\n\"\"\"\n\n\nappraisal = summarize_text(property_description)\n\nprint(appraisal)\n\n\nMessage(id='msg_01A2Pg1wCV6R72Y9LuBFCi3U', content=[ContentBlock(text=\"Property Appraisal Report\\n\\nSubject Property: Modern Two-Story Residential Home\\nLocation: [Address], Melbourne, Australia\\n\\nIntroduction:\\nThe purpose of this appraisal is to estimate the market value of the subject property, a modern, two-story residential home located in a quiet, suburban neighborhood in Melbourne, Australia. The appraisal is based on a thorough inspection of the property, an analysis of comparable properties in the area, and a consideration of current market conditions.\\n\\nProperty Description:\\nThe subject property is a well-maintained, two-story residential home built in 2015. The house features a contemporary design with a rendered brick exterior and a tiled roof. The property offers a total living area of approximately 180 square meters (1,938 square feet) and is situated on a generous 600 square meter (6,458 square feet) lot.\\n\\nThe ground floor comprises an open-plan living area that seamlessly combines the living room, dining room, and kitchen. The modern kitchen features high-quality appliances, ample storage space, and a breakfast bar. The living area has large windows that allow for an abundance of natural light and provide views of the landscaped garden. A sliding glass door leads to the patio, perfect for outdoor entertaining.\\n\\nThe upper floor consists of four well-appointed bedrooms and two bathrooms. The master bedroom features a walk-in closet and an en-suite bathroom with a double vanity, a shower, and a bathtub. The remaining three bedrooms are served by a shared bathroom with a shower and a single vanity. All bedrooms have built-in wardrobes and carpet flooring.\\n\\nAdditional features of the property include:\\n- Ducted air conditioning throughout the house\\n- High ceilings (2.7 meters) on both floors\\n- Double-glazed windows for improved energy efficiency\\n- Hardwood flooring in the living areas and tiles in the wet areas\\n- A single-car garage with internal access to the house\\n- A landscaped front and rear garden with mature trees and shrubs\\n- A paved patio area perfect for outdoor dining and entertaining\\n\\nNeighborhood Analysis:\\nThe subject property is located in a well-established, quiet suburban neighborhood in Melbourne. The area is characterized by similar modern, single-family homes on medium to large-sized lots. The neighborhood has well-maintained streets, sidewalks, and streetlights. It is conveniently located near schools, parks, shopping centers, and public transportation, making it an attractive location for families and professionals.\\n\\nMarket Analysis:\\nThe Melbourne residential property market has shown resilience and steady growth over the past few years, despite the challenges posed by the COVID-19 pandemic. Low interest rates, government incentives, and a strong demand for housing have contributed to the market's stability. The suburb in which the subject property is located has experienced a moderate increase in median house prices over the past 12 months, with a growing demand for modern, well-maintained homes.\\n\\nComparable Sales:\\nThe following comparable sales were selected based on their similarity to the subject property in terms of location, size, age, and condition:\\n\\n1. [Address], Melbourne - A modern, two-story home with 4 bedrooms, 2 bathrooms, and a total living area of 185 sq. m. on a 580 sq. m. lot. Sold for $[X] in [Month, Year].\\n\\n2. [Address], Melbourne - A 2016-built, two-story home with 4 bedrooms, 2 bathrooms, and a total living area of 175 sq. m. on a 610 sq. m. lot. Sold for $[Y] in [Month, Year].\\n\\n3. [Address], Melbourne - A modern, two-story home with 4 bedrooms, 2 bathrooms, and a total living area of 190 sq. m. on a 595 sq. m. lot. Sold for $[Z] in [Month, Year].\\n\\nValuation:\\nBased on the analysis of the subject property, the neighborhood, the current market conditions, and the comparable sales, the estimated market value of the subject property as of [Date] is:\\n\\n$[Estimated Market Value]\\n\\nThis value estimate is subject to the following assumptions and limiting conditions:\\n1. The appraiser has inspected the property, but no structural or mechanical tests were conducted.\\n2. The appraiser assumes no responsibility for hidden defects or non-apparent conditions of the property.\\n3. The information provided by the client and other sources is assumed to be accurate and reliable.\\n4. This appraisal is for the sole use of the client and intended users and should not be relied upon by any other party.\\n\\nConclusion:\\nThe subject property is a well-maintained, modern two-story residential home in a desirable suburban neighborhood in Melbourne. Its features, location, and condition make it an attractive option for potential buyers in the current market. The estimated market value of $[Estimated Market Value] reflects the property's characteristics and is supported by the analysis of comparable sales and market trends.\\n\\nAppraiser:\\n[Appraiser's Name]\\n[Appraiser's Certification/License Number]\\n[Appraisal Company Name]\", type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=170, output_tokens=1154))\n\n\n\n# display using markdown\nfrom IPython.display import Markdown\n\n# Display the summary in markdown format\ndisplay(Markdown(appraisal.content[0].text))\n\n\nProperty Appraisal Report\nProperty Description: The subject property is a contemporary, two-story residential dwelling situated in a tranquil, suburban neighborhood in Melbourne, Australia. Constructed in 2015, this well-maintained home offers a comfortable living space for a family or individuals seeking a modern lifestyle. The property features 4 bedrooms, 2 bathrooms, and an open-plan living area, providing ample space for both relaxation and entertainment. With a total living area of 180 square meters (1,938 square feet), the house sits on a generous 600 square meter (6,458 square feet) lot, which includes a beautifully landscaped garden, a patio, and a single-car garage.\nLocation and Neighborhood: The property is located in a desirable suburban area of Melbourne, known for its safety, convenience, and family-friendly atmosphere. The neighborhood is characterized by well-maintained homes, manicured lawns, and tree-lined streets, creating a pleasant and visually appealing environment. The area is served by reputable schools, both primary and secondary, making it an ideal location for families with school-aged children. Additionally, the property is in close proximity to local amenities such as shopping centers, restaurants, parks, and recreational facilities, ensuring a convenient and enjoyable lifestyle for residents.\nAccessibility and Transportation: The property benefits from excellent accessibility and transportation links. It is situated within easy reach of major roads and highways, providing convenient access to Melbourne’s central business district and other key areas of the city. Public transportation options, including bus and train services, are readily available, offering an alternative and sustainable mode of travel for commuters. The nearby train station is located within a 10-minute walk from the property, while bus stops are conveniently placed throughout the neighborhood.\nProperty Condition and Features: The two-story residential home is in excellent condition, having been well-maintained since its construction in 2015. The exterior of the property features a modern and attractive design, with a combination of brick and rendered finishes, complemented by large windows that allow for ample natural light to enter the home. The landscaped garden, which is well-established and thoughtfully designed, provides a pleasant outdoor space for relaxation and entertaining. The patio area is perfect for alfresco dining and enjoying the mild Melbourne climate.\nInside, the open-plan living area creates a spacious and inviting atmosphere, ideal for family gatherings and entertaining guests. The living area seamlessly connects to the modern, well-appointed kitchen, which features high-quality appliances, ample storage space, and a breakfast bar for casual dining. The kitchen’s layout and finishes make it both functional and visually appealing.\nThe home offers 4 bedrooms, providing comfortable accommodation for a family or guests. The master bedroom is generously sized and includes a private en-suite bathroom and built-in wardrobes, offering a luxurious and convenient space for the homeowners. The remaining bedrooms are well-proportioned and feature built-in wardrobes, ensuring ample storage space for occupants.\nThe two bathrooms in the property are modern and well-maintained, with high-quality fixtures and fittings. The family bathroom services the three additional bedrooms, while the en-suite bathroom attached to the master bedroom provides added privacy and convenience.\nThe property also includes a single-car garage, providing secure parking for one vehicle and additional storage space for household items. The garage is accessible from the main house, offering a convenient and sheltered entry point.\nMarket Analysis and Comparable Sales: To determine the market value of the subject property, a thorough analysis of recent sales of similar properties in the area has been conducted. The following comparable sales have been identified:\n\n[Address], sold for $[X] in [Month, Year]\n\nSimilar in size, age, and condition\n4 bedrooms, 2 bathrooms, single-car garage\n190 sq. m. house on a 580 sq. m. lot\n\n[Address], sold for $[Y] in [Month, Year]\n\nComparable location and neighborhood\n4 bedrooms, 2 bathrooms, single-car garage\n175 sq. m. house on a 610 sq. m. lot\n\n[Address], sold for $[Z] in [Month, Year]\n\nSimilar age and condition\n4 bedrooms, 2 bathrooms, double-car garage\n185 sq. m. house on a 595 sq. m. lot\n\n\nBased on these comparable sales and taking into account the subject property’s unique features, location, and condition, the estimated market value of the property is between $[A] and $[B].\nConclusion: The subject property, a modern two-story residential home in a desirable Melbourne suburb, presents an excellent opportunity for potential buyers seeking a well-maintained, spacious, and conveniently located family home. With its 4 bedrooms, 2 bathrooms, open-plan living area, and attractive outdoor spaces, the property offers a comfortable and contemporary living environment. Its proximity to schools, amenities, and transportation links further enhances its appeal and value.\nConsidering the property’s features, condition, location, and recent comparable sales in the area, the estimated market value of the property is between $[A] and $[B]. This valuation reflects the property’s desirability and its potential to provide a high quality of life for its occupants in a sought-after Melbourne neighborhood.\n\n\n\n\nProject 2: Property Appraisal with a house images\n\nfrom IPython.display import display, HTML\n\ndef display_images_side_by_side(image_paths):\n    html = \"&lt;div style='display: flex; justify-content: space-between;'&gt;\"\n    for path in image_paths:\n        html += f\"&lt;img src='{path}' style='width: 30%; height: auto;'&gt;\"\n    html += \"&lt;/div&gt;\"\n    display(HTML(html))\n\nimage_paths = [\n    \"front_view.webp\",\"side_view.webp\"\n]\n\ndisplay_images_side_by_side(image_paths)\n\n\n\n\n\nimport os\nimport anthropic\nfrom dotenv import load_dotenv\nfrom IPython.display import Markdown, Image\nimport base64\nfrom PIL import Image as PILImage\nimport io\n\n# Load API keys from .env file\nload_dotenv()\nanthropic.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\ndef appraise_property(description, image_paths):\n    # Read and encode the images\n    encoded_images = []\n    for path in image_paths:\n        with open(path, \"rb\") as image_file:\n            image = PILImage.open(image_file)\n            \n            # Convert the image to PNG format\n            png_image = io.BytesIO()\n            image.save(png_image, format=\"PNG\")\n            png_image.seek(0)\n            encoded_image = base64.b64encode(png_image.read()).decode(\"utf-8\")\n            \n            encoded_images.append(encoded_image)\n    # Construct the prompt with description and images\n    prompt = f\"Please provide a detailed (approx 1000 words), use placeholders for the values, and comprehensive property appraisal suitable for the Australian market based on the following information and images:\\n\\nDescription:\\n{description}\\n\\nImages:\\n\"\n\n    # Create the content array with text and image blocks\n    content = [{\"type\": \"text\", \"text\": prompt}]\n    for i, encoded_image in enumerate(encoded_images, start=1):\n        content.append({\"type\": \"text\", \"text\": f\"Image {i}:\"})\n        content.append({\n            \"type\": \"image\",\n            \"source\": {\n                \"type\": \"base64\",\n                \"media_type\": \"image/png\", \n                \"data\": encoded_image\n            }\n        })\n    \n    # Generate appraisal using Claude model\n    response = anthropic.Anthropic().messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are an intelligent property appraiser working for a real estate firm. You are an expert at property appraisal. Your goal is to write detailed and comprehensive property appraisals.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[{\"role\": \"user\", \"content\": content}]\n    )\n    return response.content[0].text\n\n# Example usage\nproperty_description = \"\"\"\nThis property is a modern, two-story residential home located in a quiet, suburban neighborhood in Melbourne, Australia.\n Built in 2015, it features 4 bedrooms, 2 bathrooms, and an open-plan living area.\n The 180 sq. m. house sits on a 600 sq. m. lot with a landscaped garden, a patio, and a single-car garage.\n\"\"\"\n\n\n\nimage_paths = [\n    \"front_view.webp\",\"side_view.webp\"\n]\n\nappraisal = appraise_property(property_description, image_paths)\n\n# Display the appraisal in markdown format\ndisplay(Markdown(appraisal))\n\nProperty Appraisal Report\nProperty Overview: The subject property is a contemporary, two-story residential home situated in a tranquil, suburban neighborhood in Melbourne, Australia. Constructed in 2015, this [PROPERTY_AGE]-year-old home offers 4 bedrooms, 2 bathrooms, and an open-plan living area. The house, measuring approximately 180 sq. m., is positioned on a generous 600 sq. m. lot that features a well-maintained landscaped garden, a patio, and a single-car garage.\nExterior: The home boasts a striking, modern architectural design with clean lines and a blend of materials, including wood, brick, and glass. The exterior showcases warm, earthy tones, complemented by expansive windows that allow ample natural light to flood the interior spaces. The landscaped garden is meticulously maintained, offering a serene and inviting outdoor environment. The patio, accessible from the living area, provides an ideal space for outdoor entertaining and relaxation. The single-car garage offers secure parking and additional storage space.\nInterior: The open-plan living area is the heart of the home, seamlessly connecting the kitchen, dining, and living spaces. This layout creates a sense of spaciousness and facilitates a smooth flow between the various functional areas. The interior features a contemporary, neutral color palette, with high-quality finishes and modern fixtures throughout.\nThe kitchen is well-appointed with sleek, modern cabinetry, premium appliances, and ample counter space, making it ideal for both everyday cooking and entertaining. The living room is designed to maximize comfort and style, with large windows that offer picturesque views of the surrounding landscape.\nThe home features 4 bedrooms, providing comfortable accommodation for a family or guests. The master bedroom likely includes an en-suite bathroom and built-in wardrobes, offering a private retreat for the homeowners. The remaining bedrooms are well-proportioned and can easily accommodate various furniture configurations.\nThe 2 bathrooms in the home are expected to feature contemporary tiling, modern fixtures, and ample storage space, ensuring both functionality and style.\nLocation: The property’s location in a quiet, suburban neighborhood in Melbourne is a significant asset. Melbourne, being one of Australia’s most livable cities, offers a wide range of amenities, including excellent schools, shopping centers, recreational facilities, and public transportation. The home’s proximity to these amenities, combined with its peaceful setting, makes it an attractive option for families and professionals alike.\nMarket Analysis: The Melbourne property market has demonstrated resilience and consistent growth over the past several years. Despite the challenges posed by the COVID-19 pandemic, the market has remained stable, with a steady demand for quality housing. The median house price in Melbourne as of [CURRENT_DATE] is approximately [MEDIAN_HOUSE_PRICE], indicating a healthy market conditions.\nProperties similar to the subject home, featuring modern architecture, open-plan living, and a desirable location, have been in high demand. Comparable sales in the area range from [COMPARABLE_SALE_RANGE], depending on the specific location, lot size, and condition of the property.\nValuation: Based on the property’s features, location, and current market conditions, the estimated value of the subject property is [ESTIMATED_VALUE]. This valuation takes into account the home’s modern design, spacious living areas, desirable location, and the overall demand for similar properties in the Melbourne market.\nConclusion: The subject property presents an excellent opportunity for homebuyers seeking a modern, well-appointed home in a sought-after Melbourne neighborhood. Its contemporary design, open-plan living, and attractive outdoor spaces make it well-suited for a range of buyers, from families to professionals. With the Melbourne property market demonstrating consistent growth and demand, this home is expected to maintain its value and provide a solid investment opportunity for prospective buyers.\n\n\n\n\nProject 3: Creating newsletters with property details for events\n\nimport anthropic\nfrom dotenv import load_dotenv\nfrom IPython.display import Markdown\n\n# Load API keys from .env file\nload_dotenv()\nanthropic.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\ndef create_event_newsletter(event, properties):\n    # Construct the prompt with event and property details\n    prompt = f\"Create a newsletter for the {event} event, featuring the following properties:\\n\\n\"\n    for i, (name, description) in enumerate(properties, start=1):\n        prompt += f\"Property {i}: {name}\\nDescription: {description}\\n\\n\"\n    \n    prompt += f\"For each property, generate a catchy marketing slogan related to the {event} event. The newsletter should be engaging and highlight the unique features of each property in relation to the event., aim 300 words for each property\"\n\n    # Generate newsletter using Claude model\n    response = anthropic.Anthropic().messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are a creative marketing assistant specializing in real estate. Your goal is to write engaging newsletters featuring properties for specific events, including catchy marketing slogans.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.content[0].text\n\n# Example usage\nevent = \"Summer Festival\"\nproperties = [\n    (\"123 Main St\", \"A beautiful, spacious property with a large backyard, perfect for summer gatherings and outdoor activities.\"),\n    (\"456 Oak Ave\", \"A charming, intimate property ideal for a quiet summer retreat with loved ones.\"),\n    (\"789 Elm Rd\", \"A luxurious property with stunning views, offering a serene setting for an unforgettable summer celebration.\")\n]\n\nnewsletter = create_event_newsletter(event, properties)\n\n# Display the newsletter in markdown format\ndisplay(Markdown(newsletter))\n\n🌞🏡 Summer Festival Special: Discover Your Dream Home! 🏡🌞\nWelcome to our Summer Festival newsletter, where we showcase three incredible properties that will make your summer unforgettable. Whether you’re looking for the perfect venue for a lively gathering or a tranquil retreat, we have the ideal home for you. Get ready to fall in love with these stunning properties and imagine the endless possibilities for your summer celebrations!\n🌿 Property 1: 123 Main St - Your Backyard Oasis Awaits! 🌿 Slogan: “Where Summer Memories Bloom: 123 Main St”\nStep into a world of endless summer fun at 123 Main St! This beautiful and spacious property boasts a large backyard that’s perfect for hosting unforgettable summer gatherings and engaging in exciting outdoor activities. Imagine the laughter and joy as your friends and family come together for a sizzling barbecue, a refreshing pool party, or a friendly game of volleyball on the lush lawn. The expansive outdoor space offers ample room for setting up tents, creating cozy seating areas, and even organizing a mini summer festival right in your own backyard. Inside, the property features a bright and airy layout, with plenty of space for your guests to mingle and relax. The well-appointed kitchen is perfect for preparing delicious summer treats, while the comfortable bedrooms provide a peaceful retreat after a day filled with fun in the sun. Don’t miss the opportunity to make 123 Main St the backdrop for your most memorable summer moments!\n🌼 Property 2: 456 Oak Ave - Your Intimate Summer Sanctuary 🌼 Slogan: “Where Serenity Meets Summer: 456 Oak Ave”\nDiscover a charming and intimate summer retreat at 456 Oak Ave. This delightful property is the perfect escape for those seeking a peaceful and relaxing summer getaway with their loved ones. Nestled in a quiet neighborhood, surrounded by mature oak trees, this home offers a serene atmosphere that will instantly put you at ease. The cozy interior features a warm and inviting living room, where you can gather with your nearest and dearest for heartfelt conversations and cherished moments. The well-equipped kitchen is ideal for preparing intimate summer dinners, while the inviting bedrooms provide a restful haven after a day of gentle summer activities. Step outside and you’ll find a lovely garden, complete with a charming patio where you can savor your morning coffee, enjoy a good book, or simply bask in the peace and tranquility of your surroundings. 456 Oak Ave is the perfect choice for those who want to create intimate and lasting summer memories in a serene and welcoming setting.\n🌺 Property 3: 789 Elm Rd - Where Luxury Meets Summer Splendor 🌺 Slogan: “Elevate Your Summer at 789 Elm Rd: Where Celebrations Shine!”\nIndulge in the epitome of luxury and sophistication at 789 Elm Rd, a property that promises an unforgettable summer celebration. This stunning home offers breathtaking views that will leave you in awe, providing the perfect backdrop for your summer festivities. The expansive living areas are designed for entertaining, with elegant furnishings, high ceilings, and abundant natural light that creates an atmosphere of grandeur and opulence. The gourmet kitchen is a chef’s dream, equipped with top-of-the-line appliances and ample space for crafting sumptuous summer dishes. Step outside onto the sprawling terrace and you’ll be greeted by a panoramic vista that stretches as far as the eye can see. This is the ideal setting for hosting lavish summer soirées, where your guests can mingle, dance, and raise a toast to the beauty of the season. The luxurious bedrooms offer a haven of comfort and style, ensuring that you and your guests can retreat in ultimate comfort after a night of celebration. 789 Elm Rd is the epitome of summer luxury, offering an unparalleled setting for creating memories that will shine brightly for years to come.\nDon’t wait – make this Summer Festival one to remember by choosing one of these incredible properties as your dream home or event venue. Contact us today to schedule a viewing and let us help you turn your summer dreams into reality!\n\n\n\n\nStreamlit App\nCreate a file named app.py, copy the next cell content, and run the following command in your terminal to start the Streamlit app:\nstreamlit run app.py\n\nimport streamlit as st\nimport anthropic\nfrom dotenv import load_dotenv\nimport os\nimport base64\nfrom PIL import Image as PILImage\nimport io\n\n# Load API keys from .env file\nload_dotenv()\nanthropic.api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n\ndef summarize_text(text):\n    import anthropic\n\n   \n    prompt = f\"Please provide a detailed ( approx 1000 words) and comprehensive property appraisal suitable for the Australian market based on the following information, use placeholders for the values :\\n\\n{text}\"\n    # Generate a summary using Claude model\n    response = anthropic.Anthropic().messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are an intelligent property appraiser with expertise in the Australian real estate market. Your goal is to write detailed and comprehensive property appraisals.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n    # Assuming the response structure contains a 'text' field with the summary\n    return response\n\n\ndef appraise_property(description, image_paths):\n    # Read and encode the images\n    encoded_images = []\n    for path in image_paths:\n        with open(path, \"rb\") as image_file:\n            image = PILImage.open(image_file)\n\n            # Convert the image to PNG format\n            png_image = io.BytesIO()\n            image.save(png_image, format=\"PNG\")\n            png_image.seek(0)\n            encoded_image = base64.b64encode(png_image.read()).decode(\"utf-8\")\n\n            encoded_images.append(encoded_image)\n    # Construct the prompt with description and images\n    prompt = f\"Please provide a detailed (approx 1000 words), use placeholders for the values, and comprehensive property appraisal suitable for the Australian market based on the following information and images:\\n\\nDescription:\\n{description}\\n\\n\"\n\n    # Create the content array with text and image blocks\n    content = [{\"type\": \"text\", \"text\": prompt}]\n    for i, encoded_image in enumerate(encoded_images, start=1):\n        content.append({\"type\": \"text\", \"text\": f\"Image {i}:\"})\n        content.append(\n            {\n                \"type\": \"image\",\n                \"source\": {\n                    \"type\": \"base64\",\n                    \"media_type\": \"image/png\",\n                    \"data\": encoded_image,\n                },\n            }\n        )\n\n    # Generate appraisal using Claude model\n    response = anthropic.Anthropic().messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are an intelligent property appraiser with expertise in the Australian real estate market. Your goal is to write detailed and comprehensive property appraisals.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[{\"role\": \"user\", \"content\": content}],\n    )\n    return response.content[0].text\n\n\ndef create_event_newsletter(event, properties):\n    # Construct the prompt with event and property details\n    prompt = f\"Create a newsletter for the {event} event, featuring the following properties:\\n\\n\"\n    for i, (name, description) in enumerate(properties, start=1):\n        prompt += f\"Property {i}: {name}\\nDescription: {description}\\n\\n\"\n\n    prompt += f\"For each property, generate a catchy marketing slogan related to the {event} event. The newsletter should be engaging and highlight the unique features of each property in relation to the event., aim 300 words for each property\"\n\n    # Generate newsletter using Claude model\n    response = anthropic.Anthropic().messages.create(\n        model=\"claude-3-opus-20240229\",\n        system=\"You are a creative marketing assistant specializing in real estate. Your goal is to write engaging newsletters featuring properties for specific events, including catchy marketing slogans.\",\n        max_tokens=4000,\n        temperature=0.7,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n    return response.content[0].text\n\n\ndef main():\n    st.set_page_config(layout=\"wide\")\n\n    st.title(\"Property Appraisal and Newsletter Generator\")\n\n    project = st.radio(\n        \"Select a project\",\n        (\"Property Appraisal\", \"Property Appraisal with Images\", \"Event Newsletter\"),\n    )\n\n    proj1_val = \"\"\"This property is a residential home located in a neighborhood. \nIt features bedrooms, bathrooms, and a living area.\nThe house sits on a lot with a garden, a deck, and a garage.\"\"\"\n\n    proj3_val = \"\"\"(\"Property 1\", \"A spacious property with a large backyard, perfect for family gatherings.\"),\n        (\"Property 2\", \"An intimate property ideal for a quiet retreat with loved ones.\"),\n        (\"Property 3\", \"A luxurious property with stunning views, offering a serene setting for an unforgettable celebration.\")\n    ]\"\"\"\n\n    if project == \"Property Appraisal\":\n        st.header(\"Project 1: Property Appraisal\")\n        property_description = st.text_area(\"Enter property description\", value=proj1_val)\n        if st.button(\"Generate Appraisal\"):\n            appraisal = summarize_text(property_description)\n            st.markdown(appraisal.content[0].text)\n\n    elif project == \"Property Appraisal with Images\":\n        st.header(\"Project 2: Property Appraisal with Images\")\n        property_description = st.text_area(\"Enter property description\", value=proj1_val)\n        uploaded_images = st.file_uploader(\n            \"Upload property images\",\n            type=[\"png\", \"jpg\", \"jpeg\"],\n            accept_multiple_files=True,\n        )\n        if st.button(\"Generate Appraisal\"):\n            if uploaded_images:\n                image_paths = []\n                for uploaded_image in uploaded_images:\n                    image = PILImage.open(uploaded_image)\n                    image_path = f\"{uploaded_image.name}\"\n                    image.save(image_path)\n                    image_paths.append(image_path)\n                    st.image(image, caption=uploaded_image.name, use_column_width=True)\n                appraisal = appraise_property(property_description, image_paths)\n                st.markdown(appraisal)\n            else:\n                st.warning(\"Please upload at least one image.\")\n\n    elif project == \"Event Newsletter\":\n        st.header(\"Project 3: Event Newsletter\")\n        event = st.text_input(\"Enter event name\", value=\"Summer Festival\")\n        num_properties = st.number_input(\n            \"Number of properties\", min_value=1, max_value=10, value=3, step=1\n        )\n        properties = []\n        for i in range(num_properties):\n            st.subheader(f\"Property {i+1}\")\n            name = st.text_input(f\"Enter property name {i+1}\", value=f\"Property {i+1}\")\n            description = st.text_area(f\"Enter property description {i+1}\", value=f\"A beautiful property perfect for the {event}.\")\n            properties.append((name, description))\n        if st.button(\"Generate Newsletter\"):\n            newsletter = create_event_newsletter(event, properties)\n            st.markdown(newsletter)\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "href": "posts/openai-parallel-function-calling-handson-tools/function_calling.html",
    "title": "MoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists",
    "section": "",
    "text": "This blog post introduces “MoodCast,” a project that leverages OpenAI’s function calling feature to create real-time, weather-based music playlists. By integrating the OpenWeather and Spotify APIs, MoodCast demonstrates the power and flexibility of OpenAI’s function calling in a practical, engaging application.\nOpenAI’s function calling feature allows developers to describe a function, and the model generates a JSON output containing arguments. This feature doesn’t call any function itself, but it generates the JSON that can be used to call a function from your code. This is a significant advancement as it allows developers to interact with AI in a more structured and systematic way, overcoming the challenges of dealing with unstructured data outputs.\nIn the context of MoodCast, this feature is used to interact with the OpenWeather and Spotify APIs, creating a unique blend of AI, weather data, and music. The project serves as a practical example of how OpenAI’s function calling can be used to solve complex problems and create innovative applications.\nThis blog post will focus on how to use function calling for OpenAI’s chat completion endpoints. It will provide a detailed guide on how to leverage this feature for your applications, with MoodCast serving as a real-world example. Whether you’re a seasoned developer or a beginner in the field of AI, this post aims to provide valuable insights into the potential of OpenAI’s function calling feature.\n\n\n\nLogo\n\n\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\nload_dotenv()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\nfrom IPython.display import display, Markdown\n\nFirst let’s check what openai chat completion say about current weather\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"what's the current weather in Tokyo?\"}\n    ],\n    temperature=0.3,\n    seed=1,\n)\n\n\nprint(response)\n\nChatCompletion(id='chatcmpl-8dISDM1s7co80v8cx8z65WwUKkTLQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\", role='assistant', function_call=None, tool_calls=None))], created=1704376421, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=82, prompt_tokens=15, total_tokens=97))\n\n\n\ndisplay(Markdown(response.choices[0].message.content))\n\nI’m sorry, but I cannot provide real-time data such as the current weather. To get the latest weather information for Tokyo or any other location, please check a reliable weather forecasting service or website like the Japan Meteorological Agency, Weather.com, or a weather app on your smartphone. These sources are regularly updated and can provide you with current conditions, forecasts, and any weather alerts that might be in effect.\n\n\nAs we can see openai does not have any information about the current weather. So we will use openweather api to get the current weather and then use openai chat completion to generate a response.\n\nLive Data using OpenWeatherMap API\nYou can signup here to get your api key https://openweathermap.org/api\nI have stored all the api key infomration in a .env file. You can create your own .env file and store your api key there.\n\n# .env file\n\nOPENWEATHER_API_KEY=your_api_key\nOPENAI_API_KEY = sk-key\nSPOTIFY_CLIENT_ID = 4444633gfdggdggdgdgdg\nSPOTIFY_CLIENT_SECRET = 23rtrrgrdgdr5353terg\n\nimport requests\n\ndef get_current_weather(city, api_key=os.getenv(\"OPENWEATHER_API_KEY\"), unit=\"metric\"):\n    \"\"\"Get the current weather for a given city using OpenWeather API.\"\"\"\n    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n    params = {\n        \"q\": city,\n        \"appid\": api_key,\n        \"units\": unit\n    }\n    response = requests.get(base_url, params=params)\n    if response.status_code == 200:\n        data = response.json()\n        #print(data)\n        weather = {\n            \"location\": data[\"name\"],\n            \"temperature\": int(data[\"main\"][\"temp\"]),\n            \"rain\": data[\"weather\"][0][\"main\"],\n            \"unit\": \"Celsius\" if unit == \"metric\" else \"Fahrenheit\"\n        }\n        return json.dumps(weather)\n    else:\n        return {\"location\": city, \"temperature\": \"unknown\", \"unit\": unit, \"rain\": \"unknown\"}\n\napi_key = os.getenv(\"OPENWEATHER_API_KEY\")\nweather_info = get_current_weather(\"Nagercoil\")\nprint(weather_info)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\ntype(weather_info)\n\nstr\n\n\n\n\nSpotify Music\nWe can create an application on spotify and get the client id and client secret. We can use these credentials to get the access token and then use the access token to get the current weather based playlist.\nhttps://developer.spotify.com/\n\n# !pip3 install spotipy\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport os\nfrom IPython.display import Image, display, Audio\n\ndef search_song(song_name):\n    # Set up your Spotify credentials\n    client_id = os.getenv(\"SPOTIFY_CLIENT_ID\")\n    client_secret = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n\n    # Authenticate with Spotify\n    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\n    # Search for the song\n    results = sp.search(q=song_name, limit=1, type='track')\n    tracks = results['tracks']['items']\n\n    # Display the first result\n    if tracks:\n        track = tracks[0]\n        return json.dumps({\n            \"song\": track['name'],\n            \"artist\": ', '.join(artist['name'] for artist in track['artists']),\n            \"album\": track['album']['name'],\n            \"album_cover_url\": track['album']['images'][0]['url'],\n            \"preview_url\": track['preview_url']\n        })\n\n    else:\n        return \"No song found\"\n\nsong_name = \"Appadi podu\"\nsong_details = search_song(song_name)\nprint(song_details)\n\n{\"song\": \"Appadi Podu\", \"artist\": \"Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\", \"album\": \"Ghilli (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2737bbef42d34fd25b14b2a54ea\", \"preview_url\": \"https://p.scdn.co/mp3-preview/df03b78315eaa0c7e20d66ea17dcf1a5fa4e6e3e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\n# display song details\nsong_details_json = json.loads(song_details)\ndisplay(Image(url=song_details_json[\"album_cover_url\"], width=100), )\ndisplay(Markdown(f\"[{song_details_json['song']} by {song_details_json['artist']}]({song_details_json['preview_url']})\"))\nprint(song_details_json[\"album\"])\n\n\n\n\nAppadi Podu by Vidyasagar, Krishnakumar Kunnath, Anuradha Sriram\n\n\nGhilli (Original Motion Picture Soundtrack)\n\n\n\n\nCreating Tools\n\navailable_tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Get the current weather in a given location, use farhenheit\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city to get the weather for\",\n                        },\n                        \"unit\": {\n                            \"type\": \"string\",\n                            \"description\": \"The unit to use for the temperature, metric is default\",\n                            \"enum\": [\"metric\", \"imperial\"],\n                        }\n                    },\n                    \"required\": [\"city\", \"unit\"],\n                },\n            },\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_song\",\n                \"description\": \"Search for a song on Spotify and display its details including the artist, album, album cover, and a preview link if available\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"song_name\": {\n                            \"type\": \"string\",\n                            \"description\": \"The name of the song to search for\",\n                        }\n                    },\n                    \"required\": [\"song_name\"],\n                }\n            }\n        }\n    ]\n\nIn the MoodCast project, JSON is utilized to define tools for function descriptions, which are essential for the OpenAI function calling feature. This feature enables the AI to generate structured data outputs, specifically JSON objects containing arguments for functions described in the API call. For instance, the get_current_weather function is defined to fetch current weather data for a specified city, while the search_song function is designed to search for songs on Spotify. These function descriptions are crucial as they guide the AI in generating the correct JSON output that can be used to call functions from the code, thereby facilitating the integration with OpenWeather and Spotify APIs.\nTo effectively use function calling with OpenAI, developers must clearly define their functions, including the name, description, and parameters, in a JSON format. This structured approach allows the AI to understand the context and generate the appropriate JSON output. The OpenAI API documentation provides guidelines on how to describe functions for function calling, emphasizing the importance of a clear and detailed function schema to ensure accurate and useful responses from the AI model.\nFor MoodCast, this means that by defining functions like get_current_weather and search_song with precise parameters and descriptions, the AI can produce JSON outputs that correspond to these functions. These outputs can then be used to make API calls to OpenWeather and Spotify, respectively, to create a music playlist that matches the current weather conditions, showcasing a practical application of OpenAI’s function calling capability in a real-world project.\n\ncity = \"Nagercoil\"\n\n\n\nOpenai Chat Completion Function Calling\n\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n        and display their album details such as album cover, artist, and preview link.\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n        \"\"\"\n    }\n]\n\ntools = available_tools\nresponse = client.chat.completions.create(\n    model=\"gpt-4-1106-preview\",\n    messages=messages,\n    tools=tools,\n    tool_choice=\"auto\", \n    temperature=0.9\n)\nresponse_message = response.choices[0].message\ntool_calls = response_message.tool_calls\n\nWe can also force the model to use some particular function by using tool_choice = {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function.\n\nresponse\n\nChatCompletion(id='chatcmpl-8dISaihzl1Q2k7S09VBau44EwlMMv', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]))], created=1704376444, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_3905aa4f79', usage=CompletionUsage(completion_tokens=28, prompt_tokens=249, total_tokens=277))\n\n\nAs when openai gonna use function calling, you can see the finish_reason in the response, which indicates we have to call the function with the given arguments and get the results, and pass it to the model again\n\nresponse_message\n\nChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])\n\n\n\nresponse_message.tool_calls\n\n[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]\n\n\n\nTool Calls\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_FmoMsWB1hklh6GvT9QmrTX3k\nCall the function: get_current_weather\nParameters: {\n  \"city\": \"Nagercoil\",\n  \"unit\": \"metric\"\n}\n\n\n\nfunction_name = tool_calls[0].function.name\nfunction_args = tool_calls[0].function.arguments\n\nfunction_name, function_args\n\n('get_current_weather', '{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}')\n\n\n\nfunction_args = json.loads(function_args)\nfunction_args\n\n{'city': 'Nagercoil', 'unit': 'metric'}\n\n\n\navailable_functions = {\n        \"get_current_weather\": get_current_weather,\n        \"search_song\": search_song,\n    }\n\n\nfunction_response = available_functions[function_name](**function_args)\nprint(function_response)\n\n{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '}]\n\n\n\nmessages.append(response_message)\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')])]\n\n\n\n\nAppending Tool Call Responses to the Message History\n\nmessages.append(\n                {\n                    \"tool_call_id\": tool_calls[0].id,\n                    \"role\": \"tool\",\n                    \"name\": function_name,\n                    \"content\": function_response,\n                }\n            )\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'}]\n\n\n\n\nSecond Call to get Song Details\n\nsecond_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\nprint(second_response)\n\nChatCompletion(id='chatcmpl-8dISdx8ctxPgd8bD3BDnYCEOmialh', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]))], created=1704376447, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c6efb4aa39', usage=CompletionUsage(completion_tokens=279, prompt_tokens=307, total_tokens=586))\n\n\n\ndisplay(Markdown(second_response.choices[0].message.content))\n\nThe current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.\n\n\n\ntool_calls = second_response.choices[0].message.tool_calls\n\n\nfor tool in tool_calls:\n    print(f\"Tool ID: {tool.id}\")\n    print(f\"Call the function: {tool.function.name}\")\n    print(f\"Parameters: {tool.function.arguments}\")\n\nTool ID: call_UEVy6FVIVy3V2kwcD36tDRvv\nCall the function: search_song\nParameters: {\"song_name\": \"Mazhai Kuruvi\"}\nTool ID: call_XKVJrqRjh1aafYldWeBWNnG2\nCall the function: search_song\nParameters: {\"song_name\": \"Nenjukulle\"}\nTool ID: call_I5Gnz9hvK1JuX8cSPFH14aL8\nCall the function: search_song\nParameters: {\"song_name\": \"Uyire Uyire\"}\nTool ID: call_KrUYtZqTDopUCua3dRbrOC9B\nCall the function: search_song\nParameters: {\"song_name\": \"Vaseegara\"}\nTool ID: call_w724Il0i6dFCDLG4l4OmPY4e\nCall the function: search_song\nParameters: {\"song_name\": \"Aaromale\"}\n\n\n\nmessages.append(second_response.choices[0].message)\n\n\n\nCall the function and append the results to the message history\n\nfor tool in tool_calls:\n    function_name = tool.function.name\n    function_args = json.loads(tool.function.arguments)\n    function_response = available_functions[function_name](**function_args)\n\n    messages.append(\n        {\n            \"tool_call_id\": tool.id,\n            \"role\": \"tool\",\n            \"name\": function_name,\n            \"content\": function_response,\n        }\n    )\n    print(function_response)\n\n{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}\n\n\n\nmessages\n\n[{'role': 'system',\n  'content': 'A Song Suggestions Assistant based on local weather in metric and local language'},\n {'role': 'user',\n  'content': 'I am in Nagercoil, suggest 5 songs based on their current weather and their local language\\n        and display their album details such as album cover, artist, and preview link.\\n        return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\\n\\n        key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\\n        '},\n ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FmoMsWB1hklh6GvT9QmrTX3k', function=Function(arguments='{\\n  \"city\": \"Nagercoil\",\\n  \"unit\": \"metric\"\\n}', name='get_current_weather'), type='function')]),\n {'tool_call_id': 'call_FmoMsWB1hklh6GvT9QmrTX3k',\n  'role': 'tool',\n  'name': 'get_current_weather',\n  'content': '{\"location\": \"Nagercoil\", \"temperature\": 26, \"rain\": \"Clouds\", \"unit\": \"Celsius\"}'},\n ChatCompletionMessage(content='The current weather in Nagercoil is 26 degrees Celsius with clouds. Based on this weather, I will suggest songs that convey a sense of peace, comfort, and perhaps contemplation, which is often associated with cloudy days. The local language in Nagercoil is Tamil, so I will be selecting Tamil songs that match the weather mood.\\n\\nI will now search for suitable Tamil songs and provide their details. Please wait a moment while I process this information.', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UEVy6FVIVy3V2kwcD36tDRvv', function=Function(arguments='{\"song_name\": \"Mazhai Kuruvi\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_XKVJrqRjh1aafYldWeBWNnG2', function=Function(arguments='{\"song_name\": \"Nenjukulle\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_I5Gnz9hvK1JuX8cSPFH14aL8', function=Function(arguments='{\"song_name\": \"Uyire Uyire\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_KrUYtZqTDopUCua3dRbrOC9B', function=Function(arguments='{\"song_name\": \"Vaseegara\"}', name='search_song'), type='function'), ChatCompletionMessageToolCall(id='call_w724Il0i6dFCDLG4l4OmPY4e', function=Function(arguments='{\"song_name\": \"Aaromale\"}', name='search_song'), type='function')]),\n {'tool_call_id': 'call_UEVy6FVIVy3V2kwcD36tDRvv',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Mazhai Kuruvi\", \"artist\": \"A.R. Rahman\", \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_XKVJrqRjh1aafYldWeBWNnG2',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Nenjukulle\", \"artist\": \"Ashbel Peter, Theertha\", \"album\": \"Nenjukulle\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\", \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_I5Gnz9hvK1JuX8cSPFH14aL8',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Uyire Uyire\", \"artist\": \"Saagar, Na.Muthukumar\", \"album\": \"Santhosh Subramaniyam (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\", \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_KrUYtZqTDopUCua3dRbrOC9B',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Vaseegara\", \"artist\": \"Bombay Jayashri\", \"album\": \"Minnalae (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\", \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'},\n {'tool_call_id': 'call_w724Il0i6dFCDLG4l4OmPY4e',\n  'role': 'tool',\n  'name': 'search_song',\n  'content': '{\"song\": \"Aaromale\", \"artist\": \"A.R. Rahman, Alphons Joseph\", \"album\": \"Vinnathaandi Varuvaayaa (Original Motion Picture Soundtrack)\", \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\", \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\"}'}]\n\n\n\n\nThird Response to get the final results as JSON Object\n\nthird_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n\nthird_response.choices[0].message.content\n\n'\\n{\\n    \"song_suggestions\": [\\n        {\\n            \"song\": \"Mazhai Kuruvi\",\\n            \"artist\": \"A.R. Rahman\",\\n            \"album\": \"Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\"\\n        },\\n        {\\n            \"song\": \"Nenjukulle\",\\n            \"artist\": \"A.R. Rahman, Shakthisree Gopalan\",\\n            \"album\": \"Kadal (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\"\\n        },\\n        {\\n            \"song\": \"Uyire Uyire\",\\n            \"artist\": \"Hariharan, Bombay Jayashri\",\\n            \"album\": \"Bombay (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\"\\n        },\\n        {\\n            \"song\": \"Vaseegara\",\\n            \"artist\": \"Bombay Jayashri\",\\n            \"album\": \"Minnalae (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"This classic love ballad with its serene mood is perfect for a cloudy day lounging.\"\\n        },\\n        {\\n            \"song\": \"Aaromale\",\\n            \"artist\": \"Alphons Joseph\",\\n            \"album\": \"Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\",\\n            \"album_cover_url\": \"https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5\",\\n            \"preview_url\": \"https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95\",\\n            \"reason\": \"A refreshing song that\\'s well-suited for when the clouds are out and you crave an uplifting atmosphere.\"\\n        }\\n    ]\\n}'\n\n\n\n# display song details\nsong_details_json = json.loads(third_response.choices[0].message.content)\n\n\nsong_details_json\n\n{'song_suggestions': [{'song': 'Mazhai Kuruvi',\n   'artist': 'A.R. Rahman',\n   'album': 'Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2735234d8419de0ffdccc8c27a7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/771e747c73fc6cd5914a4e447f9daf3bd74e38a5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.'},\n  {'song': 'Nenjukulle',\n   'artist': 'A.R. Rahman, Shakthisree Gopalan',\n   'album': 'Kadal (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d3d692e38621d741606588e7',\n   'preview_url': 'https://p.scdn.co/mp3-preview/d48678e7eef2bebd5a099d2b6b1ff5dd299ff102?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.'},\n  {'song': 'Uyire Uyire',\n   'artist': 'Hariharan, Bombay Jayashri',\n   'album': 'Bombay (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738b895bdb8ccefee6ab65114b',\n   'preview_url': 'https://p.scdn.co/mp3-preview/c4e812236497ce1f72610be2af10740ad6ecead6?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.'},\n  {'song': 'Vaseegara',\n   'artist': 'Bombay Jayashri',\n   'album': 'Minnalae (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273102f02fa7e7ded2bc5f65653',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2db5c05f48a7214b56c8eed843103ae3f241e00e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This classic love ballad with its serene mood is perfect for a cloudy day lounging.'},\n  {'song': 'Aaromale',\n   'artist': 'Alphons Joseph',\n   'album': 'Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27397838a7eeb5f477cfc6707a5',\n   'preview_url': 'https://p.scdn.co/mp3-preview/ed07e1b3e3fe14b55e29c10c5413dd9e04fbe1e5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"A refreshing song that's well-suited for when the clouds are out and you crave an uplifting atmosphere.\"}]}\n\n\n\ntype(song_details_json)\n\ndict\n\n\n\n\n\nDisplay Model Outputs\n\n# Displaying each song suggestion with its details\nfor song in song_details_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nMazhai Kuruvi\n\n\nArtist: A.R. Rahman\n\n\nAlbum: Chekka Chivantha Vaanam (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a soothing melody that resonates well with a cloudy and peaceful atmosphere.\n\n\n\n\n\nNenjukulle\n\n\nArtist: A.R. Rahman, Shakthisree Gopalan\n\n\nAlbum: Kadal (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: The backdrop of the ocean in the lyrics, combined with the cloudy weather theme, provides a tranquil listening experience.\n\n\n\n\n\nUyire Uyire\n\n\nArtist: Hariharan, Bombay Jayashri\n\n\nAlbum: Bombay (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: Its lyrical depth and the warmth of the composition blend nicely with the introspective mood of a cloudy day.\n\n\n\n\n\nVaseegara\n\n\nArtist: Bombay Jayashri\n\n\nAlbum: Minnalae (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: This classic love ballad with its serene mood is perfect for a cloudy day lounging.\n\n\n\n\n\nAaromale\n\n\nArtist: Alphons Joseph\n\n\nAlbum: Vinnaithaandi Varuvaayaa (Original Motion Picture Soundtrack)\n\n\n\n\n\nPreview the song\n\n\nReason: A refreshing song that’s well-suited for when the clouds are out and you crave an uplifting atmosphere.\n\n\n\n\n\n\n\nPutting it all together\n\ndef generate_weather_music(city):\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"A Song Suggestions Assistant based on local weather in metric and local language\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"I am in {city}, suggest 5 songs based on their current weather and their local language\n            and display their album details such as album cover, artist, and preview link.\n            return a json object with keys as song, artist, album, album_cover_url, and preview_url and reason\n\n            key as song_suggestions and value as a list of json objects with keys as song, artist, album, album_cover_url, preview_url, and reason\n            \"\"\"\n        }\n    ]\n    tools = available_tools\n    response = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",\n        temperature=0.9\n    )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n\n    if tool_calls:\n        function_name = tool_calls[0].function.name\n        function_args = json.loads(tool_calls[0].function.arguments)\n        function_response = available_functions[function_name](**function_args)\n\n        messages.append(response_message)\n        messages.append(\n            {\n                \"tool_call_id\": tool_calls[0].id,\n                \"role\": \"tool\",\n                \"name\": function_name,\n                \"content\": function_response,\n            }\n        )\n\n        second_response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\",\n        )\n\n        response_message = second_response.choices[0].message\n        tool_calls = response_message.tool_calls\n\n        if tool_calls:\n            messages.append(response_message)\n            for tool in tool_calls:\n                function_name = tool.function.name\n                function_args = json.loads(tool.function.arguments)\n                function_response = available_functions[function_name](**function_args)\n\n                messages.append(\n                    {\n                        \"tool_call_id\": tool.id,\n                        \"role\": \"tool\",\n                        \"name\": function_name,\n                        \"content\": function_response,\n                    }\n                )\n\n            third_response = client.chat.completions.create(\n                model=\"gpt-4-1106-preview\",\n                messages=messages,\n                response_format={\"type\":\"json_object\"}\n            )\n\n            return third_response\n\n\n\n\nimage.png\n\n\n\nresult = generate_weather_music(\"Sydney\")\n\n\nsong_suggestions_json = result.choices[0].message.content\n\n\ntype(song_suggestions_json)\n\nstr\n\n\n\nsong_suggestions_json = json.loads(song_suggestions_json)\n\n\nsong_suggestions_json \n\n{'song_suggestions': [{'song': 'Over the Rainbow',\n   'artist': \"Israel Kamakawiwo'ole\",\n   'album': 'Alone In Iz World',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b27356c868c8c85e7e4e62bd9ec1',\n   'preview_url': 'https://p.scdn.co/mp3-preview/2b0ebc854ece09122c1918aeff6af258493defe9?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"This classic song's soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\"},\n  {'song': 'Sweater Weather',\n   'artist': 'The Neighbourhood',\n   'album': 'I Love You.',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2738265a736a1eb838ad5a0b921',\n   'preview_url': 'https://p.scdn.co/mp3-preview/877602f424a9dea277b13301ffc516f9fd1fbe7e?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"The title itself and the song's vibe are a nod to the cozy feel of the current Sydney weather.\"},\n  {'song': 'Set Fire to the Rain',\n   'artist': 'Adele',\n   'album': '21',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b2732118bf9b198b05a95ded6300',\n   'preview_url': 'https://p.scdn.co/mp3-preview/6fc68c105e091645376471727960d2ba3cd0ee01?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': \"Though it's not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\"},\n  {'song': 'Cloudy Day',\n   'artist': 'Tones And I',\n   'album': 'Cloudy Day',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273d2cf6639f08099bdb14e388d',\n   'preview_url': 'https://p.scdn.co/mp3-preview/9c49fc0dfef73b4f91d444309b06450c9e30fee5?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.'},\n  {'song': 'Cloudbusting',\n   'artist': 'Kate Bush',\n   'album': 'Hounds Of Love',\n   'album_cover_url': 'https://i.scdn.co/image/ab67616d0000b273ad08f4b38efbff0c0da0f252',\n   'preview_url': 'https://p.scdn.co/mp3-preview/0156aec767cfcbe6bfc80bb9c8ad931169a3d910?cid=706a549bcf8a4575b6e1dd3fc24f5f95',\n   'reason': 'An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.'}]}\n\n\n\nfor song in song_suggestions_json[\"song_suggestions\"]:\n    display(Markdown(f\"### {song['song']}\"))\n    display(Markdown(f\"**Artist:** {song['artist']}\"))\n    display(Markdown(f\"**Album:** {song['album']}\"))\n    display(Image(url=song['album_cover_url'], width=200))\n    display(Markdown(f\"[Preview the song]({song['preview_url']})\"))\n    display(Markdown(f\"**Reason:** {song['reason']}\"))\n    display(Markdown(\"----\"))\n\nOver the Rainbow\n\n\nArtist: Israel Kamakawiwo’ole\n\n\nAlbum: Alone In Iz World\n\n\n\n\n\nPreview the song\n\n\nReason: This classic song’s soothing ukulele and gentle vocals perfectly match the peacefulness of an overcast day.\n\n\n\n\n\nSweater Weather\n\n\nArtist: The Neighbourhood\n\n\nAlbum: I Love You.\n\n\n\n\n\nPreview the song\n\n\nReason: The title itself and the song’s vibe are a nod to the cozy feel of the current Sydney weather.\n\n\n\n\n\nSet Fire to the Rain\n\n\nArtist: Adele\n\n\nAlbum: 21\n\n\n\n\n\nPreview the song\n\n\nReason: Though it’s not raining, the cloudy skies can bring about the feeling captured by this powerful yet soulful song.\n\n\n\n\n\nCloudy Day\n\n\nArtist: Tones And I\n\n\nAlbum: Cloudy Day\n\n\n\n\n\nPreview the song\n\n\nReason: This song has a fitting title and an uplifting tone that can bring positivity to a cloudy day.\n\n\n\n\n\nCloudbusting\n\n\nArtist: Kate Bush\n\n\nAlbum: Hounds Of Love\n\n\n\n\n\nPreview the song\n\n\nReason: An evocative track that seamlessly aligns with the overcast weather in Sydney, capturing the theme of moving through introspective moments.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/ai-assistants-crewai/classroom_crew.html",
    "href": "posts/ai-assistants-crewai/classroom_crew.html",
    "title": "crewAI: Simulating a Classroom with CrewAI Agents",
    "section": "",
    "text": "I’ve developed several AI Assistants using OpenAI’s API. In one project, I created an assistant that sifts through my social media and a few other websites, capturing screenshots, analyzing content, and preparing personalized news. Every morning, it sends me a voice message and a report on Telegram. In another project, I built a personalized travel planner. This assistant, upon receiving a city I plan to visit, checks its weather, creates a color-coded map, devises a personalized itinerary with an optimized travel path, and compiles a travel guide complete with cultural insights.\nA recurring challenge in these projects was that a single assistant couldn’t handle all the tasks. I had to design specialized assistants: one excelled at creating Word documents, another was adept at recommending places, and so on.\nUpon exploring the Crew Library, I realized that it enables the creation of multiple agents, each with specialized skills, roles, and tools. Importantly, these agents can share a common memory, allowing each to be aware of the others’ actions and progress.\nIn this blog post, let’s construct an AI Assistant/Agent to simulate a classroom setting. One agent will act as a teacher, instructing on a topic, while other agents will play the role of students, asking questions. The teacher agent will then incorporate these questions to make the class more engaging and interactive.\nIntroduction: The realm of AI development is constantly evolving, offering innovative ways to utilize technology in everyday tasks. In a recent project, we explored the capabilities of the Crew Library, a powerful tool for creating multiple AI agents, each with specialized skills. This article delves into a fascinating application of the Crew Library: simulating a classroom environment with AI agents.\nProject Overview: The project aimed to simulate a classroom setting with AI agents acting as a teacher and students. Using the Crew Library, we developed a teacher agent specialized in deep learning and multiple student agents at different comprehension levels: beginner, intermediate, and advanced. This setup allowed for an interactive and engaging educational experience, mimicking a real classroom.\nImplementation: 1. Agent Creation: We began by creating a teacher agent with a role as a deep learning instructor, equipped with goals, a backstory, and the ability to search the internet. The teacher’s primary goal was to teach deep learning to a diverse group of students. Similarly, student agents were created, each with their own goals and backstories corresponding to their understanding levels.\n\nTasks and Classroom Crew: We defined tasks for each agent. The student agents were tasked with asking questions based on their understanding levels, while the teacher agent’s task was to incorporate these questions into a more comprehensive teaching script. We then integrated these agents and tasks into a ‘classroom crew’ using the Crew Library, enabling sequential processing of tasks.\nExecution and Results: The classroom simulation was executed, where initially the teacher taught a topic in deep learning. Then, student agents asked questions according to their levels, which the teacher later integrated into a revised teaching script. The Crew Library’s sequential task processing allowed for a smooth flow of the classroom simulation.\nDisplay and Analysis: We utilized IPython’s display and markdown features to present the results. The final output showcased the teacher’s initial lecture, the students’ questions, and the final, enriched teaching script that included answers to these questions.\n\nConclusion: This project demonstrated the versatility and potential of the Crew Library in creating interactive and dynamic AI-driven environments. The successful simulation of a classroom setting not only underscores the importance of specialized AI agents in handling diverse tasks but also opens up new possibilities for AI-assisted learning and other applications.\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nimport openai\nfrom openai import OpenAI\nclient = OpenAI()\n# openai key\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nclient.api_key = OPENAI_API_KEY\n\n\n# !pip install git+https://github.com/joaomdmoura/crewAI.git\n\n\n# !pip install openai --upgrade\n\n\n# !pip install crewai --upgrade\n# !pip install duckduckgo-search\n\n\nfrom langchain.tools import DuckDuckGoSearchRun\nsearch_tool = DuckDuckGoSearchRun()\n\n\nimport os\nfrom crewai import Agent, Task, Crew, Process\n\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n\n# !pip install -U langchain-openai\n\n\nfrom langchain_openai.chat_models import ChatOpenAI\n\n\n\nmodel = ChatOpenAI(model_name=\"gpt-4-turbo-preview\")\n\n\ntopic = \"Deep Learning\"\n\n\n\n# Create a classroom with a teacher and 5 students\nteacher = Agent(\n    role=f'{topic} Teacher',\n    goal=f'Teach {topic} to a diverse group of students',\n    backstory=f\"\"\"You are an experienced teacher specializing in {topic}.\n    Your goal is to impart knowledge to a class with varying levels of understanding.\n    You enjoy challenges and strive to make complex concepts accessible.You answer students' questions and provide feedback on their understanding.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[search_tool],\n    llm=model\n)\n\nadvanced_student1 = Agent(\n    role='Advanced Level Student',\n    goal=f'Understand advanced concepts in {topic}',\n    backstory=\"\"\"You are an advanced level student who excels in grasping complex\n    scientific principles. You enjoy pushing the boundaries of your understanding and\n    asking challenging questions.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],  # No specific tools for now\n    llm=model\n)\n\nadvanced_student2 = Agent(\n    role='Advanced Level Student',\n    goal=f'Understand advanced concepts in {topic}',\n    backstory=f\"\"\"You are another advanced level student who has a keen interest\n    in the intricate details of {topic}. You aim to explore the subject\n    at an advanced level and may pose challenging questions.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nintermediate_student1 = Agent(\n    role='Intermediate Level Student',\n    goal=f'Grasp fundamental concepts in {topic}',\n    backstory=f\"\"\"You are an intermediate level student with a good understanding of basic\n    {topic} principles. Your goal is to \n    ask questions that clarify fundamental concepts.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nintermediate_student2 = Agent(\n    role='Intermediate Level Student',\n    goal=f'Grasp fundamental concepts in {topic}',\n    backstory=f\"\"\"You are another intermediate level student aiming to ask questions to strengthen your grasp\n    on fundamental {topic} concepts. \"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\nbeginner_student = Agent(\n    role='Beginner Level Student',\n    goal=f'Understand basic concepts in {topic}',\n    backstory=\"\"\"You are a beginner student who is working hard to understand\n    the basic principles of {topic}. Your questions may be more basic,\n    focusing on fundamental concepts.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    tools=[],\n    llm=model\n)\n\n\n\n\n\n\n# Create tasks for the students to ask questions\nquestion1 = Task(\n    description=f\"Ask a challenging question related to advanced {topic}. Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=advanced_student1)\n\nquestion2 = Task(\n    description=f\"Ask a challenging question related to advanced {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=advanced_student2\n)\n\nquestion3 = Task(\n    description=f\"Ask an average level question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=intermediate_student1\n)\n\nquestion4 = Task(\n    description=f\"Ask an average level question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=intermediate_student2\n)\n\nquestion5 = Task(\n    description=f\"Ask a basic question related to fundamental {topic} Use the content taught by the teacher to frame your question. Your question can be independent to other students question\",\n    agent=beginner_student\n)\n\n# Create a task for the teacher to answer questions\nteach1 = Task(\n    description=f\"Write your teaching script for the class. Your main goal is to teach {topic}. write 1000-1200 words\",\n    agent=teacher\n)\n\nteach2 = Task(\n    description=f\"Now re-write your teaching script based on your earlier script, incorporate the questions asked by the students, and include your answer in your script for maximum engagment.Your main goal is to write the script for the topic {topic}, we are just including students relevant question to the topic along with answers for better understanding of the topic. So stick with the topic {topic}\",\n    agent=teacher\n)\n\n\n\n# Instantiate the crew with a sequential process\nclassroom_crew = Crew(\n    agents=[teacher, advanced_student1, advanced_student2, intermediate_student1, intermediate_student2, beginner_student],\n    tasks=[teach1, question1, question2, question3, question4, question5, teach2],\n    verbose=2,\n    process= Process.sequential,\n    \n)\n\n# Start the class!\nclassroom_result = classroom_crew.kickoff()\n\nprint(\"######################\")\nprint(classroom_result)\n\n\n[DEBUG]: Working Agent: Deep Learning Teacher\n\n[INFO]: Starting Task: Write your teaching script for the class. Your main goal is to teach Deep Learning. write 1000-1200 words\n\n\n&gt; Entering new CrewAgentExecutor chain...\n**Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!Invalid Format: Missing 'Action:' after 'Thought:Do I need to use a tool? No\nFinal Answer: **Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!\n\n&gt; Finished chain.\n\n[DEBUG]: [Deep Learning Teacher] Task output: **Introduction to Deep Learning**\n\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\n\n**Understanding the Basics**\n\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\n\nAt its core, a neural network consists of layers of nodes, or \"neurons,\" each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\n\n**Why Deep Learning?**\n\nThe \"deep\" in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\n\n**Key Components of Deep Learning**\n\n1. **Data**: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\n\n2. **Neural Networks**: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\n\n3. **Activation Functions**: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\n\n4. **Backpropagation and Gradient Descent**: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\n**Challenges and Solutions**\n\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\n\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\n\n**Ethics and Future Perspectives**\n\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\n\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\n\n**Conclusion**\n\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\n\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\n\nYour journey into deep learning starts now. Embrace the challenges, and let's make the most of this opportunity to learn and grow together. Welcome aboard!\n\n\n\n[DEBUG]: Working Agent: Advanced Level Student\n\n[INFO]: Starting Task: Ask a challenging question related to advanced Deep Learning. Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\n```\nThought: Do I need to use a tool? No\nFinal Answer: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n```\n\n&gt; Finished chain.\n\n[DEBUG]: [Advanced Level Student] Task output: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n```\n\n\n\n[DEBUG]: Working Agent: Advanced Level Student\n\n[INFO]: Starting Task: Ask a challenging question related to advanced Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n\n&gt; Finished chain.\n\n[DEBUG]: [Advanced Level Student] Task output: Given the increasing complexity and depth of neural networks, how can we design more efficient algorithms for training these networks that not only reduce computational resources and time but also minimize the environmental impact, considering the growing concerns around the carbon footprint of training large-scale AI models?\n\n\n\n[DEBUG]: Working Agent: Intermediate Level Student\n\n[INFO]: Starting Task: Ask an average level question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In light of the concerns regarding the environmental impact of training large-scale deep learning models, a fundamental question arises: What are some of the emerging techniques or methodologies in deep learning that are aimed at reducing the computational intensity and, consequently, the carbon footprint of training these models, while still maintaining or enhancing their performance?\n\n&gt; Finished chain.\n\n[DEBUG]: [Intermediate Level Student] Task output: In light of the concerns regarding the environmental impact of training large-scale deep learning models, a fundamental question arises: What are some of the emerging techniques or methodologies in deep learning that are aimed at reducing the computational intensity and, consequently, the carbon footprint of training these models, while still maintaining or enhancing their performance?\n\n\n\n[DEBUG]: Working Agent: Intermediate Level Student\n\n[INFO]: Starting Task: Ask an average level question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In the quest to address the environmental concerns associated with training deep learning models, what are some of the innovative approaches being adopted to minimize computational demands and carbon emissions without compromising the effectiveness of these models?\n\n&gt; Finished chain.\n\n[DEBUG]: [Intermediate Level Student] Task output: In the quest to address the environmental concerns associated with training deep learning models, what are some of the innovative approaches being adopted to minimize computational demands and carbon emissions without compromising the effectiveness of these models?\n\n\n\n[DEBUG]: Working Agent: Beginner Level Student\n\n[INFO]: Starting Task: Ask a basic question related to fundamental Deep Learning Use the content taught by the teacher to frame your question. Your question can be independent to other students question\n\n\n&gt; Entering new CrewAgentExecutor chain...\nThought: Do I need to use a tool? No\nFinal Answer: In addressing environmental concerns related to deep learning model training, several innovative approaches are being adopted. One fundamental approach is the development and use of more efficient algorithms that require less computational power, thereby reducing energy consumption. Another approach is the utilization of model pruning and quantization techniques, which streamline models by removing unnecessary parameters or reducing the precision of the calculations, making them less resource-intensive without significantly affecting performance. Additionally, there's a growing trend towards using renewable energy sources for powering data centers where these models are trained, further minimizing the carbon footprint associated with deep learning. Lastly, transfer learning is also gaining popularity as it allows developers to leverage pre-trained models on new tasks with minimal additional training required, significantly cutting down on the resources and energy needed for training models from scratch.\n\n&gt; Finished chain.\n\n[DEBUG]: [Beginner Level Student] Task output: In addressing environmental concerns related to deep learning model training, several innovative approaches are being adopted. One fundamental approach is the development and use of more efficient algorithms that require less computational power, thereby reducing energy consumption. Another approach is the utilization of model pruning and quantization techniques, which streamline models by removing unnecessary parameters or reducing the precision of the calculations, making them less resource-intensive without significantly affecting performance. Additionally, there's a growing trend towards using renewable energy sources for powering data centers where these models are trained, further minimizing the carbon footprint associated with deep learning. Lastly, transfer learning is also gaining popularity as it allows developers to leverage pre-trained models on new tasks with minimal additional training required, significantly cutting down on the resources and energy needed for training models from scratch.\n\n\n\n[DEBUG]: Working Agent: Deep Learning Teacher\n\n[INFO]: Starting Task: Now re-write your teaching script based on your earlier script, incorporate the questions asked by the students, and include your answer in your script for maximum engagment.Your main goal is to write the script for the topic Deep Learning, we are just including students relevant question to the topic along with answers for better understanding of the topic. So stick with the topic Deep Learning\n\n\n&gt; Entering new CrewAgentExecutor chain...\n### Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.Invalid Format: Missing 'Action:' after 'Thought:Thought: Do I need to use a tool? No\nFinal Answer: Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n&gt; Finished chain.\n\n[DEBUG]: [Deep Learning Teacher] Task output: Deep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n######################\nDeep Learning: A Comprehensive Introduction with Student Queries Integrated\n\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\n#### The Essence of Deep Learning\n\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain's functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\n\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n#### Key Components and Challenges\n\nLet's break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\n\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n#### Addressing Environmental Concerns\n\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n#### Ethical Considerations and Future Potential\n\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n#### Continuous Learning and Exploration\n\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\n\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let's embark on this exciting journey together, ready to learn, question, and innovate.\n\n---\n\nThis script integrates the essence of deep learning with answers to students' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n\nclassroom_result\n\n'Deep Learning: A Comprehensive Introduction with Student Queries Integrated\\n\\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\\n\\n#### The Essence of Deep Learning\\n\\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain\\'s functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\\n\\nA student once asked, \"Why do we need multiple layers in neural networks?\" The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\\n\\n#### Key Components and Challenges\\n\\nLet\\'s break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\\n\\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\\n\\n#### Addressing Environmental Concerns\\n\\nA pertinent question from a student highlighted a growing concern: \"How does deep learning impact the environment?\" Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\\n\\n#### Ethical Considerations and Future Potential\\n\\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\\n\\n#### Continuous Learning and Exploration\\n\\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\\n\\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let\\'s embark on this exciting journey together, ready to learn, question, and innovate.\\n\\n---\\n\\nThis script integrates the essence of deep learning with answers to students\\' queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.'\n\n\n\nfrom IPython.display import display, Markdown\n\n\ndisplay(Markdown(classroom_crew.tasks[0].output.result))\n\nIntroduction to Deep Learning\nWelcome, everyone. As we embark on this journey together into the world of deep learning, I want you to remember one thing: deep learning is not just a set of algorithms or an accumulation of complex mathematical formulas; it is a way to give machines a semblance of understanding, akin to the way we, humans, perceive the world.\nUnderstanding the Basics\nDeep learning is a subset of machine learning, which in turn falls under the broader umbrella of artificial intelligence (AI). The key idea behind deep learning is to mimic the way the human brain processes information. This is achieved through structures called artificial neural networks, which are inspired by the biological neural networks in our brains.\nAt its core, a neural network consists of layers of nodes, or “neurons,” each of which performs simple computations. When these neurons are interconnected and layered, they can process complex data, learn patterns, and make predictions or decisions based on input data.\nWhy Deep Learning?\nThe “deep” in deep learning refers to the use of multiple layers in neural networks. This depth allows the model to learn hierarchical representations of data. In simpler terms, deep learning models can learn from raw data by building increasingly sophisticated features through its layers. This capability has revolutionized fields such as image and speech recognition, natural language processing, and even autonomous driving.\nKey Components of Deep Learning\n\nData: Deep learning models require large amounts of data to learn effectively. This data serves as the foundation upon which these models build their understanding.\nNeural Networks: At the heart of deep learning are neural networks, which are designed to mimic the way human brains operate. These networks consist of input layers, hidden layers, and output layers.\nActivation Functions: Activation functions help decide whether a neuron should be activated or not. They introduce non-linearity into the network, enabling it to learn complex patterns.\nBackpropagation and Gradient Descent: These are algorithms used for training neural networks. Backpropagation helps in adjusting the weights of the network based on the error rate, while gradient descent is a way to minimize the error by iteratively moving towards the minimum of a loss function.\n\nChallenges and Solutions\nDeep learning, while powerful, comes with its set of challenges. Overfitting, where a model learns the noise in the training data instead of the actual pattern, can lead to poor performance on unseen data. Techniques such as dropout, regularization, and data augmentation are used to combat this.\nAnother challenge is the requirement for large amounts of labeled data and computational resources. Transfer learning and unsupervised learning are some of the strategies used to address these issues.\nEthics and Future Perspectives\nAs we develop increasingly capable deep learning models, ethical considerations become paramount. Issues such as bias in AI, privacy concerns, and the impact on employment need careful consideration and proactive measures.\nLooking ahead, the future of deep learning is incredibly promising. From enhancing medical diagnoses to improving environmental protection efforts, the potential applications are vast and impactful. However, achieving these outcomes requires not just technical skills, but also a thoughtful approach to the ethical implications of our work.\nConclusion\nIn this class, we will dive deeper into each of these topics, unraveling the complexities and uncovering the potentials of deep learning. Through lectures, hands-on projects, and discussions, you will gain a comprehensive understanding of deep learning and how it can be applied to solve real-world problems.\nRemember, the field of deep learning is evolving rapidly, and continuous learning is key. Stay curious, be open to making mistakes, and learn from them. Together, we will explore the fascinating world of deep learning, and I am here to guide you every step of the way.\nYour journey into deep learning starts now. Embrace the challenges, and let’s make the most of this opportunity to learn and grow together. Welcome aboard!\n\n\n\ndisplay(Markdown(f\"{classroom_result}\"))\n\nDeep Learning: A Comprehensive Introduction with Student Queries Integrated\nWelcome to our deep learning module, an exciting and dynamic field that stands at the forefront of artificial intelligence (AI). Deep learning gives machines an ability akin to human perception, enabling them to recognize patterns and make decisions in ways that were unimaginable just a few decades ago. As we embark on this journey together, our goal is to demystify deep learning, making it accessible to all, regardless of your prior understanding.\n\nThe Essence of Deep Learning\nAt its core, deep learning is a subset of machine learning. It leverages artificial neural networks to mimic the human brain’s functionality, thereby processing data in complex, layered manners. This hierarchical approach allows deep learning models to tackle tasks of increasing sophistication, from recognizing handwritten digits to understanding natural language and beyond.\nA student once asked, “Why do we need multiple layers in neural networks?” The answer lies in the power of hierarchy. Just as the human brain processes information in stages (from simple to complex), deep learning models use layers to learn increasingly abstract representations. This is crucial for tasks like image recognition, where initial layers may detect edges, while deeper layers may identify more complex shapes or objects.\n\n\nKey Components and Challenges\nLet’s break down the essential components of deep learning: data, neural networks, activation functions, backpropagation, and gradient descent. Each plays a pivotal role in the learning process, with data being the fuel for training our models. Activation functions introduce non-linearity, allowing for complex decision-making, while backpropagation and gradient descent are the mechanisms through which models learn from their mistakes, continuously improving their accuracy.\nHowever, deep learning is not without its challenges. Overfitting, the need for vast amounts of data, and significant computational resources are among the hurdles we face. Solutions such as dropout and regularization help combat overfitting by making our models more robust. Meanwhile, the advent of transfer learning and unsupervised learning techniques has made it easier to train models with less data and computational power.\n\n\nAddressing Environmental Concerns\nA pertinent question from a student highlighted a growing concern: “How does deep learning impact the environment?” Indeed, the computational demands of training sophisticated models have a carbon footprint. To mitigate this, the field is moving towards more energy-efficient algorithms and utilizing renewable energy sources for data centers. Techniques like model pruning and quantization reduce the computational load without compromising performance significantly. Furthermore, transfer learning emerges as a sustainable practice, leveraging existing models to reduce the resources required for new tasks.\n\n\nEthical Considerations and Future Potential\nAs we delve deeper into deep learning, ethical considerations must guide our exploration. The potential for bias, privacy implications, and the responsible use of AI are topics we must engage with critically. Looking ahead, the possibilities are boundless. From revolutionizing medicine with predictive diagnostics to tackling climate change through advanced modeling, deep learning holds the promise of significant societal impacts.\n\n\nContinuous Learning and Exploration\nIn conclusion, deep learning is a field marked by rapid evolution and profound potential. As your guide, I encourage you to embrace curiosity, engage with challenges, and explore the myriad applications of deep learning. Together, we can navigate the complexities of this fascinating field, unlocking new knowledge and innovative solutions for the betterment of society.\nRemember, the journey into deep learning is one of continuous learning and discovery. Your engagement, questions, and insights enrich our collective understanding and drive the field forward. So, let’s embark on this exciting journey together, ready to learn, question, and innovate.\n\nThis script integrates the essence of deep learning with answers to students’ queries, aiming to foster an engaging and informative learning environment. By addressing real-world concerns and emphasizing continuous exploration, we prepare students for the dynamic and evolving field of deep learning.\n\n\n\n\n# classroom_crew.tasks[0]\n\n\n# classroom_crew.tasks[0].model_dump()\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "href": "posts/understanding-openai-chatcompletion-model-parameters/llm_temperature.html",
    "title": "Understanding OpenAI ChatCompletion Model Parameters",
    "section": "",
    "text": "In this notebook, we will go through different parameters in LLM that control the token generation process\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\nIn each parameter, we will explore different range of values and discuss about openai’s default values and recommendations. Then in the final section we will go through some real examples to understand how these parameters affect the token generation process.\n\n\n\nIMG_F4CC52CE7F7F-1.jpeg\n\n\nI have written two helper functions highlight_openai_response and highlight for highlighting the probabilities of the tokens generated by the model. Less probable tokens are highlighted in white and more probable tokens are highlighted in green.\n\nquestion = \"\"\"\n\nWhat is machine learning? Explain it to a five year old.\nAnswer within 100 words, 3 paragraphs\n\"\"\"\n\nmodel = \"gpt-3.5-turbo\"\n\n\n\n\nimport seaborn as sns\nfrom IPython.display import HTML\nimport matplotlib.colors as mcolors\nimport numpy as np\n\n\ndef highlight_openai_response(response):\n    messages = response.choices[0].message.content\n    probabilities = []\n\n    for res in response.choices[0].logprobs.content:\n        probabilities.append(np.exp(res.logprob))\n\n    highlight(messages, probabilities)\n\n\ndef highlight(text, probabilities):\n    # Split the text into words, preserving newlines and spaces\n    words = []\n    for line in text.split(\"\\n\"):\n        words.extend([(word, \" \") for word in line.split(\" \")] + [(\"\\n\", \"\")])\n\n    # Remove the last element if it is a newline, added due to the split\n    if words[-1][0] == \"\\n\":\n        words.pop()\n\n    # Ensure probabilities list matches the number of non-empty words\n    normalized_probs = [min(max(0, p), 1) for p in probabilities]\n\n    # Use a Seaborn color palette and map probabilities to colors\n    palette = sns.light_palette(\"green\", as_cmap=True)\n\n    # Start building the HTML string using the 'pre' tag to preserve whitespace\n    html_string = \"&lt;pre style='font-family: inherit; white-space: pre-wrap; word-break: break-all;'&gt;\"\n\n\n    prob_index = 0  # Index for the current probability\n\n    for word, space in words:\n        if word and word != \"\\n\":  # If the element is not a space or newline\n            rgba_color = palette(normalized_probs[prob_index])\n            hex_color = mcolors.to_hex(rgba_color)\n            # Set the text color to black and the background color to the word's color\n            html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{word}&lt;/span&gt;\"\n            if space:\n                # Set the space's background color to the word's color\n                html_string += f\"&lt;span style='background-color: {hex_color}; color: black;'&gt;{space}&lt;/span&gt;\"\n            prob_index += 1\n        elif word == \"\\n\":\n            # Add a newline in HTML, and reset the color for the next line\n            html_string += \"&lt;br&gt;\"\n        else:\n            # This case handles multiple spaces in a row\n            previous_hex_color = mcolors.to_hex(\n                palette(normalized_probs[prob_index - 1])\n            )\n            html_string += (\n                f\"&lt;span style='background-color: {previous_hex_color};'&gt; &lt;/span&gt;\"\n            )\n\n    html_string += \"&lt;/pre&gt;\"  # Close the 'pre' tag\n\n    # Display the HTML string\n    display(HTML(html_string))\n\n\nhighlight(\"Hello I am Arun\", [0.9, 0.8, 0.6, 0.4])\n\nHello I am Arun \n\n\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n\n\nfrom openai import OpenAI, __version__\nprint(f\"OpenAI version: {__version__}\")\nclient = OpenAI()\n\nOpenAI version: 1.5.0\n\n\n\nseed = 42\n\n\nTokens\nIn large language models (LLMs), tokens are the smallest units of text that the model processes and generates. They can represent individual characters, words, subwords, or even larger linguistic units, depending on the specific tokenization approach used. Tokens act as a bridge between the raw text data and the numerical representations that LLMs can work with.\nIn the context of OpenAI, tokens are the basic units of text processed by their language models, such as GPT-3. OpenAI employs Byte-Pair Encoding (BPE) for tokenization, which is a method initially designed for text compression. BPE identifies the most frequent pairs of characters or tokens and merges them to form new tokens, thus optimizing the tokenization process for efficiency and effectiveness in representing the text data. This approach allows the model to handle a wide range of vocabulary, including rare words or phrases, by breaking them down into subword units.\n\n\n\nimage.png\n\n\nsource https://platform.openai.com/tokenizer\nIn openai chat completion APIs, four parameter controls the token generation process. They are\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\n\n\n\nTemperature\nIn large language models, temperature is a parameter that controls the randomness of predictions by scaling the logits before applying the softmax function. A low temperature makes the model more confident and conservative, favoring more likely predictions, while a high temperature increases diversity and creativity, allowing for less probable outcomes.\nTemperature adjusts the probability distribution of the next word. A higher temperature increases randomness, while a lower one makes the model more deterministic.\nPurpose: It controls the level of unpredictability in the output.\nThe temperature adjustment equation in LaTeX format is as follows:\n\\[\nP'(w_i) = \\frac{P(w_i)^{\\frac{1}{T}}}{\\sum_{j=1}^{V} P(w_j)^{\\frac{1}{T}}}\n\\]\nHere, \\(P(w_i)\\) is the original probability of the word \\(w_i\\), \\(T\\) is the temperature, \\(P'(w_i)\\) is the adjusted probability of the word, and \\(V\\) is the vocabulary size (the total number of words over which the probabilities are distributed). This equation shows how each original probability \\(P(w_i)\\) is raised to the power of the reciprocal of the temperature, and then normalized by dividing by the sum of all such adjusted probabilities to ensure that the adjusted probabilities sum to 1.\n\n0.15** (1/1.9)\n\n0.368437494723581\n\n\n\n0.15** (1/0.7)\n\n0.06652540281931184\n\n\n\nimport pandas as pd\n\n# Base probabilities for 20 words\nbase_probabilities = [\n    0.19, 0.12, 0.10, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03,\n    0.03, 0.03, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01\n]\n\n# Temperatures\nhigh_temperature = 1.9\nlow_temperature = 0.4\n\n# Adjusted probabilities with high temperature\nadjusted_probabilities_high = [p ** (1 / high_temperature) for p in base_probabilities]\n\n# Adjusted probabilities with low temperature\nadjusted_probabilities_low = [p ** (1 / low_temperature) for p in base_probabilities]\n\n# Normalizing the adjusted probabilities for high temperature\nsum_adjusted_probabilities_high = sum(adjusted_probabilities_high)\nnormalized_probabilities_high = [p / sum_adjusted_probabilities_high for p in adjusted_probabilities_high]\n\n# Normalizing the adjusted probabilities for low temperature\nsum_adjusted_probabilities_low = sum(adjusted_probabilities_low)\nnormalized_probabilities_low = [p / sum_adjusted_probabilities_low for p in adjusted_probabilities_low]\n\nwords = [f\"word{i}\" for i in range(20)]\n\n# Create a DataFrame with the words and their probabilities, adjusted for high and low temperatures\ndf = pd.DataFrame({\n    \"word\": words,\n    \"base_probability\": base_probabilities,\n    \"adjusted_probability_high=1.9\": adjusted_probabilities_high,\n    \"normalized_probabilities_high=1.9\": normalized_probabilities_high,\n    \"adjusted_probability_low=0.4\": adjusted_probabilities_low,\n    \"normalized_probabilities_low=0.4\": normalized_probabilities_low\n})\n\ndf\n\n\n\n\n\n\n\n\nword\nbase_probability\nadjusted_probability_high=1.9\nnormalized_probabilities_high=1.9\nadjusted_probability_low=0.4\nnormalized_probabilities_low=0.4\n\n\n\n\n0\nword0\n0.19\n0.417250\n0.111183\n0.015736\n0.493728\n\n\n1\nword1\n0.12\n0.327611\n0.087298\n0.004988\n0.156515\n\n\n2\nword2\n0.10\n0.297635\n0.079310\n0.003162\n0.099221\n\n\n3\nword3\n0.09\n0.281580\n0.075032\n0.002430\n0.076245\n\n\n4\nword4\n0.08\n0.264654\n0.070522\n0.001810\n0.056797\n\n\n5\nword5\n0.07\n0.246693\n0.065736\n0.001296\n0.040677\n\n\n6\nword6\n0.06\n0.227469\n0.060613\n0.000882\n0.027668\n\n\n7\nword7\n0.05\n0.206656\n0.055067\n0.000559\n0.017540\n\n\n8\nword8\n0.04\n0.183756\n0.048965\n0.000320\n0.010040\n\n\n9\nword9\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n10\nword10\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n11\nword11\n0.03\n0.157937\n0.042085\n0.000156\n0.004891\n\n\n12\nword12\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n13\nword13\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n14\nword14\n0.02\n0.127587\n0.033998\n0.000057\n0.001775\n\n\n15\nword15\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n16\nword16\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n17\nword17\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n18\nword18\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n19\nword19\n0.01\n0.088587\n0.023605\n0.000010\n0.000314\n\n\n\n\n\n\n\n\ndf[\"base_probability\"].sum()\n\n1.0\n\n\nAs we can see that the base probabilities decrease progressively from word0 to word19, starting at 0.19 and going down to 0.01. However, after the adjustment, the probabilities are closer to each other, indicating that the temperature scaling has made the less likely words more probable and the more probable words less dominant.\nFor example, word0 has its probability decreased from 0.19 to about 0.11, while word19 has its probability slightly increased from 0.01 to about 0.024. This adjustment serves to flatten the probability distribution, making the model less certain and more explorative in its word choices.\nThe adjusted probabilities are also normalized, as their sum should equal 1 to represent a valid probability distribution. This adjustment allows for a less deterministic and more varied text generation, which can be useful for generating more diverse and creative text outputs.\nThe temperature adjustment has effectively reduced the likelihood of the most probable word being selected and increased the likelihood of less probable words, thus adding variability to the text generation process.\n\n# plot the probabilities\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.plot(words, base_probabilities, label=\"Base Probabilities\")\nplt.plot(words, normalized_probabilities_high, label=\"High Temperature\")\nplt.plot(words, normalized_probabilities_low, label=\"Low Temperature\")\nplt.xticks(rotation=90)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Probability\")\nplt.legend()\nplt.show()\n\n\n\n\n\nTemperature : 0( Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=0,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out.\n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.001537835, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.00058532227, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00044044392, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-0.31134152, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' having', bytes=[32, 104, 97, 118, 105, 110, 103], logprob=-1.0659788, top_logprobs=[])]\n\n\n\nprobs = []\n\n\nimport numpy as np\n\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\nresponse.system_fingerprint\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\n\nHigh Temperature ( More Randomness)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1.6,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster. That's how machines work too, they start with learning puzzles and every time they make a mistake, they remember that and try not to make the same mistake again. They keep getting better and better! They can use what they have learned to help us, like find things on the internet or even drive cars. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nTemperature : 1 ( Default)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs)\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\nOpenAI Recommendations for Temperature\n - default is 1 - range: 0 to 2 \n\n\nTop-P (Nucleus Sampling)\nTop-p sampling, also known as nucleus sampling, is a technique used in large language models to control the diversity and quality of generated text. It involves selecting tokens from the most probable options, where the sum of their probabilities determines the selection.\nThe “top p” parameter acts as a filter, controlling how many different words or phrases the model considers when predicting the next word. The lower the value of p, the more deterministic the responses generated by the model are.\nThis method helps balance between diversity and high-probability words, ensuring the output is both diverse and contextually relevant.\n\ndf_p = df[['word', 'base_probability']].copy()\n\ndf_p['cumulative_probability'] = df_p['base_probability'].cumsum()\n\ndf_p\n\n\n\n\n\n\n\n\nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.19\n0.19\n\n\n1\nword1\n0.12\n0.31\n\n\n2\nword2\n0.10\n0.41\n\n\n3\nword3\n0.09\n0.50\n\n\n4\nword4\n0.08\n0.58\n\n\n5\nword5\n0.07\n0.65\n\n\n6\nword6\n0.06\n0.71\n\n\n7\nword7\n0.05\n0.76\n\n\n8\nword8\n0.04\n0.80\n\n\n9\nword9\n0.03\n0.83\n\n\n10\nword10\n0.03\n0.86\n\n\n11\nword11\n0.03\n0.89\n\n\n12\nword12\n0.02\n0.91\n\n\n13\nword13\n0.02\n0.93\n\n\n14\nword14\n0.02\n0.95\n\n\n15\nword15\n0.01\n0.96\n\n\n16\nword16\n0.01\n0.97\n\n\n17\nword17\n0.01\n0.98\n\n\n18\nword18\n0.01\n0.99\n\n\n19\nword19\n0.01\n1.00\n\n\n\n\n\n\n\n\ndf_p.style.apply(lambda x: ['background: yellow' if x.cumulative_probability &lt;= 0.8 else '' for i in x], axis=1)\n\n\n\n\n\n\n \nword\nbase_probability\ncumulative_probability\n\n\n\n\n0\nword0\n0.190000\n0.190000\n\n\n1\nword1\n0.120000\n0.310000\n\n\n2\nword2\n0.100000\n0.410000\n\n\n3\nword3\n0.090000\n0.500000\n\n\n4\nword4\n0.080000\n0.580000\n\n\n5\nword5\n0.070000\n0.650000\n\n\n6\nword6\n0.060000\n0.710000\n\n\n7\nword7\n0.050000\n0.760000\n\n\n8\nword8\n0.040000\n0.800000\n\n\n9\nword9\n0.030000\n0.830000\n\n\n10\nword10\n0.030000\n0.860000\n\n\n11\nword11\n0.030000\n0.890000\n\n\n12\nword12\n0.020000\n0.910000\n\n\n13\nword13\n0.020000\n0.930000\n\n\n14\nword14\n0.020000\n0.950000\n\n\n15\nword15\n0.010000\n0.960000\n\n\n16\nword16\n0.010000\n0.970000\n\n\n17\nword17\n0.010000\n0.980000\n\n\n18\nword18\n0.010000\n0.990000\n\n\n19\nword19\n0.010000\n1.000000\n\n\n\n\n\n\ndf_p[\"base_probability\"].sum()\n\n1.0\n\n\n\nHigh Top-P ( Includes more tokens to sample)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  seed=seed\n)\n\n\nprint(response.choices[0].message.content)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture. \n\nMachine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things!\n\n\n\nhighlight_openai_response(response)\n\nMachine learning is when computers learn things on their own, just like how you learn new things. Imagine you have a special toy that can remember things it sees and hears. When you show it a picture of a cat and tell it \"this is a cat,\" the toy remembers that. Then, when you show it another picture of a cat without telling it anything, the toy can recognize that it's a cat too! This is because the toy learned from the first picture.   Machine learning is like that toy, but with big computers. They can learn from lots of pictures, sounds, and information to understand things all by themselves. The more they learn, the smarter they become. They can even help us do things like finding answers to questions, predicting what might happen next, and making decisions. It's like having a really smart friend who knows so many things! \n\n\n\nresponse.choices[0].logprobs.content[:5] # first 5 tokens\n\n[ChatCompletionTokenLogprob(token='Machine', bytes=[77, 97, 99, 104, 105, 110, 101], logprob=-0.0015492603, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.0005857991, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00047642877, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' when', bytes=[32, 119, 104, 101, 110], logprob=-1.7854097, top_logprobs=[]),\n ChatCompletionTokenLogprob(token=' computers', bytes=[32, 99, 111, 109, 112, 117, 116, 101, 114, 115], logprob=-0.25018257, top_logprobs=[])]\n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\nLow Top-P ( More Deterministic)\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  seed=seed\n)\n\n\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\nprobs = []\nfor res in response.choices[0].logprobs.content:\n    probs.append(np.exp(res.logprob))\n\nplt.hist(probs);\nplt.xlabel(\"Probability\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\nOpenAI Recommendations for Top-P\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\nInteractions between Temperature and Top-P\nLet’s experiment the interactions between temperature and top-p\n\nHigh Temperature and High Top-P\nHigh Temperature and Low Top-P\nLow Temperature and High Top-P\nLow Temperature and Low Top-P\n\n\nHigh Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=1.6,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is when computer programs can learn and improve by themselves.   Imagine you have a puzzle toy with pictures on it. At first it's all mixed up and you don't know how to make it right. When you start solving it a few times, you start getting better and can finish the puzzle faster.   Machine learning works a bit like that. It's like a really smart program that learns from doing things over and over again. It gets more and more powerful, by learning from its own experiences! So just like you, the computer program gets better and better at solving the problems it faces. Isn’t that amazing?! \n\n\n\n\nHigh Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=1.5,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just the computer using math and patterns to figure things out. \n\n\n\n\nLow Temperature, High Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=1,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. It's like when you play a game and get better each time because you remember what you did before. But instead of a game, the robot friend learns from lots of information and figures out patterns and rules. Then it can use what it learned to make predictions or do tasks without being told exactly what to do. It's like having a really clever friend who can help you with all sorts of things! \n\n\n\n\nLow Temperature, Low Top-P\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  top_p=0.2,\n  temperature=0.2,\n  seed=seed\n)\nhighlight_openai_response(response)\n\nMachine learning is like having a super smart robot friend that can learn things on its own. Just like how you learn new things by practicing and trying different things, machine learning is when a computer program learns from lots of examples and gets better at doing a task. For example, if you show the robot friend lots of pictures of cats and dogs, it can learn to tell the difference between them. It's like magic, but really it's just a computer using math to learn and make decisions. \n\n\n\n\n\nimage.png\n\n\n\n\n\nFrequency Penalty\nFrequency Penalty is used to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\nIt ranges from -2.0 to 2.0, where positive values discourage repetition by penalizing tokens that occur frequently, and negative values can increase the likelihood of repetition. This helps control the diversity of the generated content and prevent verbatim repetition.\n\n\n\nimage.png\n\n\nIn the above example, we can see recommendations such as National Park appeared twice in the generated text. We can use frequency penalty to reduce the likelihood of a token being selected again if it has already appeared in the generated text.\n\nquestion = \"\"\"\n\nWrite 10 slogans for ChatGPT\n\n\"\"\"\n\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, we'll wow you!\" 6. \"ChatGPT: Making Conversations Magical!\" 7. \"Experience Smarter Chats with ChatGPT - Your virtual chat guru!\" 8. \"Elevate Your Chats with ChatGPT - Your chatbot companion!\" 9. \"ChatGPT: The Perfect Balance of Wit and Intelligence!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations made effortless!\" \n\n\n\nHigh Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with the Intelligence of ChatGPT.\" 5. \"Chat Smarter, With Confidence - Made Possible by ChatGPT!\" 6. \"Discover a New Level of Conversation Excellence with ChatGPT.\" 7. “Experience Artificial Intelligence that Feels Human – Meet chatbot G.” 8.“Make Every Interaction Count – Talk to Our Powerful AI Assistant!” 9.“Unlock Boundless Knowledge and Vivid Imagination– Say Hi to Our Intelligent AI friend!\"  10.\"Connect, Collaborate, Converse like never before - Powered by the Amazingness Of 'Yethe'\" \n\n\n\n\nLow Frequency Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT!\" 4. \"ChatGPT: Making Conversations Smarter!\" 5. \"Connect, Engage, and Learn with ChatGPT!\" 6. \"Elevate Your Conversations with ChatGPT!\" 7. \"ChatGPT: Your Virtual Conversational Superpower!\" 8. \"Experience the Future of Chat with ChatGPT!\" 9. \"ChatGPT: Making Talk as Intelligent as You!\" 10. \"ChatGPT: Your Chatbot Buddy for Every Occasion!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nPresence Penalty\nPresence Penalty is a parameter that influences the generation of new content by penalizing tokens that have already appeared in the text. It ranges from -2.0 to 2.0, where positive values discourage repetition and encourage the model to introduce new topics, while negative values do the opposite. This penalty is applied as a one-time, additive contribution to tokens that have been used at least once, helping to ensure more diverse and creative outputs\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"Get Instant Answers with ChatGPT - Chat smarter, not harder!\" 4. \"Break the Ice with ChatGPT - The Ultimate Conversation Starter!\" 5. \"ChatGPT: With every chat, knowledge expands!\" 6. \"Join the Chat Revolution - Welcome to ChatGPT!\" 7. \"Experience Chat Brilliance with ChatGPT - Seamless Conversations, Unmatched Results!\" 8. \"Chat Smarter, Talk Faster with ChatGPT!\" 9. \"ChatGPT: The Intelligent Chatbot for All Your Conversational Needs!\" 10. \"Unlock the Potential of Chat with ChatGPT - Conversations Redefined!\" \n\n\n\nHigh Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with ChatGPT's Intelligent AI.\" 5. \"ChatGPT: With You Every Step of the Conversation.\" 6. \"Unlock New Possibilities in Dialogue with ChatGPT.\" 7. \"Experience Natural Language Communication with ChatGPT.\" 8. \"Supercharge Your Conversations with ChatGPT's AI Assistant.\" 9. \"Chat Smarter, Not Harder, with ChatGPT.\" 10. \"Say Hello to Seamless Chats and Intelligent Responses with ChatGPT!\" \n\n\n\n\nLow Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-2\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Your Virtual Chatting Guru!\" 5. \"ChatGPT: Arm Your Conversations With Intelligence!\" 6. \"ChatGPT: Chatting Perfected with Artificial Intelligence!\" 7. \"ChatGPT: Your Personal Chatting Assistant with the Power of AI!\" 8. \"ChatGPT: Elevate Your Conversations to the Next Level!\" 9. \"ChatGPT: Your Smart Friend for Engaging Chats!\" 10. \"ChatGPT: Intelligent Conversations Made Effortless!\" \n\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n\n\n\nInteraction between Frequency Penalty and Presence Penalty\n\nHigh Frequency Penalty and High Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=1.8,\n  frequency_penalty=1.8\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion.\" 3. \"Get Instant Answers and Engaging Chats with ChatGPT!\" 4. \"Elevate Your Conversations with AI-Powered ChatGPT.\" 5. \"Let's Talk! With Dynamic Dialogue Made Easy by ChatGPT.\" 6. \"Discover Smarter, More Natural Chats Using ChatGPT.\" 7. \"Unlock a World of Seamless Communication with ChatGPT.\"  8 .\"Experience Human-Like Interactions using our Advanced Assistant -Chat Gpt\" 9 .\"Your Virtual Conversation Buddy – Get Talking With Chat Gpt Now ! \" 10 .\"Revolutionize Your Conversations w \n\n\n\n\nLow Frequency Penalty and Low Presence Penalty\n\n\nresponse = client.chat.completions.create(\n  model=model,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": question}\n  ],\n  logprobs=True,\n  temperature=1,\n  seed=seed,\n  presence_penalty=-0.5,\n  frequency_penalty=-0.5\n)\nhighlight_openai_response(response)\n\n1. \"Unleash the Power of Chat with ChatGPT!\" 2. \"ChatGPT: Your Trusted Conversational Companion!\" 3. \"ChatGPT: Chatting just got Smarter!\" 4. \"Connect with ChatGPT: Chatting with Intelligence!\" 5. \"ChatGPT: Revolutionizing Chatting, One Conversation at a Time!\" 6. \"ChatGPT: Your Virtual Chatting Expert!\" 7. \"ChatGPT: Chatting with Artificial Intelligence that Feels Human!\" 8. \"ChatGPT: Chatting made Easy, Chatting made Powerful!\" 9. \"ChatGPT: Chatting with the Next Level of Chatbot Technology!\" 10. \"ChatGPT: Chatting. Redefined. \" \n\n\n\n\n\nPractical Use Cases\n\nIndustry 1: Creative Writing (e.g., Novels, Short Stories)\n\nTemperature: Set to 0.8-0.9. Higher temperature encourages more creative and unexpected turns of phrase, enhancing the storytelling with originality.\nTop P (Nucleus Sampling): Set around 0.9. Allows for a good range of probable words while still fostering creativity, which is vital in creative writing.\nFrequency Penalty: Set to a moderate value (e.g., 0.5). Helps avoid excessive repetition of words/phrases, maintaining a fresh and engaging narrative.\nPresence Penalty: Set to a lower value (e.g., 0.3-0.4). Encourages some repetition of key themes or phrases, which can be a powerful tool in storytelling.\n\n\n\nIndustry 2: Customer Support (e.g., Chatbots for Service Queries)\n\nTemperature: Set lower, around 0.3-0.4. Ensures more predictable and relevant responses, crucial for accurate customer support.\nTop P (Nucleus Sampling): Set around 0.8. Balances the need for coherent, relevant responses while allowing for some variability to better match customer queries.\nFrequency Penalty: Moderate to high (e.g., 0.6-0.8). In customer support, avoiding repetitive phrases can enhance clarity and professionalism in responses.\nPresence Penalty: Moderate (e.g., 0.5). Helps ensure a variety of information is provided, which can be crucial in addressing diverse customer queries comprehensively.\n\n\nExplanation:\n\nCreative Writing: The settings are designed to maximize creativity and originality, ensuring a rich and engaging narrative.\nCustomer Support: The focus here is on accuracy, relevance, and clarity in responses, which are essential in a customer support context.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-python/messages_api.html",
    "href": "posts/anthropic-claude3-messages-api-python/messages_api.html",
    "title": "Anthropic Claude3: Messages API with Multimodal Input",
    "section": "",
    "text": "The Claude 3 family represents Anthropic’s latest, most advanced AI models, offering state-of-the-art performance, versatility, and ease of use for open-ended conversation, idea collaboration, coding, and text processing."
  },
  {
    "objectID": "posts/anthropic-claude3-messages-api-python/messages_api.html#installation",
    "href": "posts/anthropic-claude3-messages-api-python/messages_api.html#installation",
    "title": "Anthropic Claude3: Messages API with Multimodal Input",
    "section": "Installation",
    "text": "Installation\n\n# !pip install anthropic --upgrade\n\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nTrue\n\n\n\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Generative AI - Explained Intuitively",
    "section": "",
    "text": "Book Recommendations, Interesting Advices, Career Tips from Dwarkesh Patel’s Podcasts using Anthropic’s Claude 3 API\n\n\n\n\n\n\n\nai\n\n\nnlp\n\n\ndata-analysis\n\n\nvisualization\n\n\n\n\nDiscover the most recommended books and intriguing ideas from Dwarkesh Patel’s podcast guests. This project analyzes 63 podcast transcripts using Anthropic’s Claude 3 API, visualizes key metrics, and estimates the total cost based on token usage.\n\n\n\n\n\n\nApr 1, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nClaude3 + Python: Automate Real Industry Workflows Like a Pro\n\n\n\n\n\n\n\nai\n\n\nreal-estate\n\n\nproperty-appraisal\n\n\nnewsletter-generation\n\n\nstreamlit\n\n\n\n\nExplore how AI can revolutionize the real estate industry through automated property appraisals and personalized event newsletters. Learn to leverage Anthropic’s Claude model to generate comprehensive appraisals and engaging newsletters, and build an interactive Streamlit app to showcase these AI-powered functionalities.\n\n\n\n\n\n\nMar 28, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with Images\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\nimage-analysis\n\n\n\n\nAnthropic’s Claude 3 models can understand and analyze images, allowing for conversations that include both text and visuals. Supported image formats include JPEG, PNG, GIF, and WebP. Multiple images can be included in a single request for analysis. Image analysis counts towards token usage. Claude has some limitations in image understanding but provides valuable interpretations.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Function Calling Tools in Python\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nfunction-calling\n\n\npython\n\n\n\n\nFunction calling tools in Python allow extending Claude’s capabilities by integrating external functions or APIs. Define functions, create tool descriptions, construct system prompts, and process user messages to generate responses with function calls. This powerful technique enables Claude to perform tasks beyond its built-in knowledge.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with JSON Mode\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Claude AI model can generate structured JSON data by following specific techniques. By providing clear instructions and examples, developers can extract JSON from Claude’s responses using string parsing, partial responses, stop sequences, or XML-like tags. The JSON can then be easily parsed and integrated into applications or workflows.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with Streaming\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Messages API supports streaming mode for real-time conversational AI responses. Using server-sent events (SSE), the API incrementally streams message content, allowing for dynamic user experiences. SDKs simplify implementation, while raw HTTP streaming is available for custom integrations. Developers can handle various event types and gracefully process unknown events.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nAnthropic Claude3: Messages API with Multimodal Input\n\n\n\n\n\n\n\nllm\n\n\nclaude3\n\n\nmessages-api\n\n\n\n\nAnthropic’s Messages API enables creating sophisticated conversational AI experiences with text and image inputs. Customize model behavior using system prompts, fine-tune randomness with temperature, and stream responses. The API supports single queries and multi-turn conversations, making it versatile for various applications.\n\n\n\n\n\n\nMar 22, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\ncrewAI: Simulating a Classroom with CrewAI Agents\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nagents\n\n\n\n\nWe use crewAI library to develop many agents and make them work together. We build a project where we simulate a classroom with students and teachers. Teacher agent teach a topic, student agents ask questions, then teacher agents incorporate the questions into the topic and teach again.\n\n\n\n\n\n\nFeb 2, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nOpenAI ChatCompletions vs OpenAI Assistants API: A Hands-on Comparison\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nopenai_assistants_api\n\n\nchat_completions\n\n\nhandson\n\n\n\n\nAssistants API offers advanced features like conversation threading, code execution, and data retrieval, ideal for complex AI applications. In contrast, Chat Completion Models are lightweight and efficient, ideal for simple AI applications.\n\n\n\n\n\n\nJan 20, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMorning with Jarvis: Craft Your Own News Universe from Social Media and News Digests\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\nhandson\n\n\n\n\nRevolutionize your morning routine with an AI-powered tool that delivers personalized audio news briefings on your topic of interest directly to your telegram. This project uses openai assistants API, Selenium, telegram API, openai text to speech models, DuckDuckGo for search, and many more.\n\n\n\n\n\n\nJan 14, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nTransform Your Travel: How to Build a Personalised Planner with OpenAI Assistants API\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\nhandson\n\n\n\n\nIn this article, we will build a personalised travel planner using OpenAI Assistants API. We will explore multiple parallel function calling, creating multiple assistants each focuses on a specific task, and we create a thread that interacts with multiple assistants. We create a fun project that does interactive maps, a personalised travel guide with real time weather updates, and a personalised travel planner.\n\n\n\n\n\n\nJan 10, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMaster the Art of Function Calling in OpenAI Assistants API: A Comprehensive Guide for Beginners\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\nopenai_assistants_api\n\n\n\n\nDiscover how to leverage function calling in the OpenAI Assistant API with our comprehensive guide. This tutorial, suitable for both seasoned developers and beginners, covers the basics of function calling, creating an assistant, initiating a thread, and more. Learn how to identify when a message requires a function call, determine which function to call and what arguments to pass, and retrieve the response from a function call. We illustrate these concepts with a simple demo of reversing a string using a function integrated with the assistant. Enhance your AI applications with a clear, practical understanding of function calling in the OpenAI Assistant API\n\n\n\n\n\n\nJan 5, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nMoodCast: Leveraging OpenAI Parallel Function Calling for Real-Time Weather-Based Music Playlists\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\nfunction_calling\n\n\n\n\nThe blog post introduces MoodCast, a project that uses OpenAI’s parallel function calling feature to create real-time, weather-based music playlists. It integrates OpenWeather and Spotify APIs, demonstrating the power and flexibility of OpenAI’s function calling. This feature allows developers to describe a function, and the model generates a JSON output containing arguments. It doesn’t call any function itself, but generates the JSON that can be used to call a function from your code. This is a significant advancement as it allows developers to interact with AI in a more structured and systematic way, overcoming the challenges of dealing with unstructured data outputs. The blog post provides a detailed guide on how to use function calling for OpenAI’s chat completion endpoints, with MoodCast serving as a real-world example. It aims to provide valuable insights into the potential of OpenAI’s function calling feature for both seasoned developers and beginners in the field of AI\n\n\n\n\n\n\nJan 3, 2024\n\n\nArun Prakash\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding OpenAI ChatCompletion Model Parameters\n\n\n\n\n\n\n\nllm\n\n\nopenai\n\n\n\n\nDetails: Dive into the intricacies of LLM token generation with our insightful notebook. We cover key parameters like temperature, top_p, frequency_penalty, and presence_penalty, examining their value ranges and OpenAI’s defaults.We highlight the generation probability using log_probs. Our comprehensive guide includes real examples to demonstrate how these settings impact the token generation process, providing a valuable resource for developers and AI enthusiasts alike\n\n\n\n\n\n\nDec 17, 2023\n\n\nArun Prakash\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I write and teach about my learnings in large language models.\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]